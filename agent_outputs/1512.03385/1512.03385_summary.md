# Deep Residual Learning for Image Recognition

URL: http://arxiv.org/abs/1512.03385v1

発表年: 2015

著者:
Kaiming He
Xiangyu Zhang
Shaoqing Ren
Jian Sun

著者の所属機関:
Microsoft Research

## 要約

本論文は、深層畳み込みニューラルネットワークの「劣化問題」（深さの増加に伴い訓練誤差が増加する現象）に対処するため、深層残差学習フレームワークを提案しています。このフレームワークでは、層のスタックが直接目的の基底写像を学習する代わりに、残差写像を学習するように再定式化されます。これは、入力 `x` を出力に直接接続する「恒等ショートカット接続」によって実現され、追加のパラメータや計算コストを導入しません。

提案された残差ネットワーク（ResNet）は、深さの大幅な増加に伴う最適化の困難さを克服し、ImageNet分類タスクにおいて152層というこれまでに発表された中で最も深いネットワークの訓練を可能にしました。この152層ResNetは、VGGネットワークよりも低い計算複雑度で優れた精度を達成し、ILSVRC 2015分類コンペティションで1位を獲得しました。さらに、ImageNet検出、ImageNet位置特定、COCO検出、COCOセグメンテーションといった他の視覚認識タスクでもResNetは最先端の結果を達成し、その強力な汎化性能と汎用性を示しました。

## 使用された手法

本論文で提案された主要な手法は「深層残差学習（Deep Residual Learning）」フレームワークです。これは、ニューラルネットワークの複数の層が直接目的の写像 `H(x)` を近似する代わりに、残差写像 `F(x) = H(x) - x` を近似するように明示的に学習させるものです。元の写像は `F(x) + x` として再定式化されます。この再定式化は、フィードフォワードネットワークにおける「ショートカット接続」によって実現されます。ショートカット接続は、入力 `x` を積層された層の出力に追加するもので、主に恒等写像として機能し、場合によっては次元を合わせるための線形射影（1x1畳み込み）が使用されます。

## 技術の主要なポイント

*   **劣化問題の解決**: ネットワークの深さが増加するにつれて訓練誤差が上昇する「劣化問題」を効果的に解決します。
*   **残差写像の学習**: ネットワークが恒等写像からの「残差」（摂動）を学習するように設計されています。これにより、最適化が容易になります。
*   **恒等ショートカット接続**: 入力特徴量を直接層の出力に追加するショートカット接続は、追加のパラメータや計算量を導入しません。これにより、プレーンネットワークと公平な比較が可能になり、非常に深いネットワークでも効率的に訓練できます。
*   **深さによる性能向上**: 残差学習により、100層以上、さらには1000層を超える極めて深いネットワークでも訓練が可能となり、深さの増加が直接的に精度向上につながることを示しました。
*   **ボトルネックアーキテクチャ**: 計算効率を考慮し、より深いネットワークのために1x1、3x3、1x1畳み込みからなる「ボトルネック」ブロックを導入しました。これにより、計算コストを抑えつつ深さを増すことが可能になります。

## 先行研究との比較

*   **勾配消失/爆発問題への対処**: 過去の研究では正規化初期化やバッチ正規化（BN）によって勾配消失/爆発問題はほぼ解決されていましたが、本論文で提案された「劣化問題」（深層化による訓練誤差の増加）は依然として存在していました。ResNetは、この劣化問題を直接解決することで、既存の手法を補完し、真に深いネットワークの訓練を可能にしました。
*   **ハイウェイネットワークとの比較**: 同時期に提案されたハイウェイネットワークもショートカット接続を使用しますが、ゲーティング関数を持つため、データ依存のパラメータが導入され、ゲートが閉じると非残差関数を表現します。対照的に、ResNetの恒等ショートカットはパラメータフリーであり、常に情報が通過するため、ネットワークは常に残差関数を学習します。また、ハイウェイネットワークは100層を超える深さでの精度向上を示せていないのに対し、ResNetは大幅な精度向上を達成しています。
*   **既存の深層モデルとの比較**: VGG、GoogLeNet、PReLU-netなどの当時の最先端モデルと比較して、ResNetはより低い計算複雑度で同等またはそれ以上の精度を達成しました。特に、152層のResNetはVGG-19よりも少ないFLOPsで、ImageNet分類において当時最高の精度を達成しています。

## 実験方法

本論文では、様々なデータセットとモデルサイズで広範な実験が行われました。

*   **データセット**:
    *   **ImageNet 2012分類**: 1000クラス、128万枚の訓練画像、5万枚の検証画像。
    *   **CIFAR-10**: 10クラス、5万枚の訓練画像、1万枚のテスト画像。
    *   **PASCAL VOC 2007/2012**: 物体検出タスク。
    *   **MS COCO**: 物体検出およびセグメンテーションタスク。

*   **モデルアーキテクチャ**:
    *   ImageNet向けに18、34、50、101、152層のResNet（プレーンネットワークとの比較も実施）。
    *   CIFAR-10向けに20、32、44、56、110、1202層のResNet。
    *   残差ブロックの構成は、主に2層（3x3畳み込み）または「ボトルネック」設計（1x1、3x3、1x1畳み込み）の3層。

*   **訓練の詳細**:
    *   ミニバッチサイズ256（CIFAR-10は128）の確率的勾配降下法（SGD）。
    *   学習率は0.1から開始し、検証誤差がプラトーに達したときに10分の1に減衰。
    *   重み減衰は0.0001、モーメンタムは0.9。
    *   各畳み込み層の直後、活性化の前にバッチ正規化（BN）を使用。
    *   ドロップアウトは使用しない。
    *   データ増強として、画像のリサイズ、ランダムクロップ、水平反転、色増強などを使用。

*   **評価**:
    *   ImageNet分類ではtop-1およびtop-5エラー率を評価。10-cropテストや全畳み込み形式での複数スケールテストも実施。
    *   物体検出タスクでは、Faster R-CNNフレームワークを使用し、ResNet-101をバックボーンに採用。BN層は事前学習後に固定。ボックスリファインメント、グローバルコンテキスト、マルチスケールテストなどの改善も適用。
    *   物体位置特定タスクでは、Faster R-CNNの領域提案ネットワーク（RPN）および検出ネットワーク（Fast R-CNNまたはR-CNN）をクラスごとの形式で利用。

## 議論

本論文の実験結果は、深層残差学習が深層ニューラルネットワークにおける「劣化問題」を効果的に解決し、訓練を容易にすることを明確に示しました。特に、深いプレーンネットワークが訓練誤差の増加を経験するのに対し、残差ネットワークは深さの増加とともに訓練誤差を削減し、高い精度を達成しました。これは、残差写像を学習するという再定式化が最適化ランドスケープをより扱いやすくすることを示唆しています。

ImageNetでの分類タスクにおけるResNetの顕著な性能向上は、深層表現の真の力を解き放つことに成功したことを証明しています。また、物体検出や位置特定といった他の視覚認識タスクでの成功は、残差学習の原理が単一のタスクに限定されず、様々な問題にわたって効果的な汎用的な特徴表現を学習できることを裏付けています。

CIFAR-10での1202層のモデルの訓練成功は、ResNetが極端な深さでも最適化可能であることを示しましたが、110層モデルと比較してテストエラーが若干高いことから、このような超深層モデルではデータセットの規模に対する過学習の懸念が残ることも示唆されました。この結果は、さらなる正則化技術の適用が今後の研究課題となる可能性を示しています。全体として、深層残差学習は、深層学習の最適化と性能の限界を押し広げる画期的な貢献をしました。