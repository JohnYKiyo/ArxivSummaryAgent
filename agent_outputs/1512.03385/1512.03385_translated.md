# Deep Residual Learning for Image Recognition

URL: http://arxiv.org/abs/1512.03385v1

発表年: 2015

著者:
Kaiming He \qquad Xiangyu Zhang \qquad Shaoqing Ren \qquad Jian Sun , 
\large Microsoft Research \vspace{-.2em

---

\section{はじめに}
\label{sec:intro}

深層畳み込みニューラルネットワーク \cite{LeCun1989,Krizhevsky2012} は、画像分類において一連の画期的な進展をもたらしました \cite{Krizhevsky2012,Zeiler2014,Sermanet2014}。深層ネットワークは、低・中・高レベルの特徴 \cite{Zeiler2014} と分類器をエンドツーエンドの多層的な方法で自然に統合し、特徴の「レベル」は積み重ねられた層の数（深さ）によって豊かになります。
最近の証拠 \cite{Simonyan2015,Szegedy2015} によると、ネットワークの深さは決定的に重要であり、困難なImageNetデータセット \cite{Russakovsky2014} における主要な結果 \cite{Simonyan2015,Szegedy2015,He2015,Ioffe2015} はすべて、「非常に深い」 \cite{Simonyan2015} モデル、深さ16 \cite{Simonyan2015} から30 \cite{Ioffe2015} を利用しています。他の多くの非自明な視覚認識タスク \cite{Girshick2014,He2014,Girshick2015,Ren2015,Long2015} も、非常に深いモデルから多大な恩恵を受けています。

深さの重要性に動機づけられ、次のような疑問が生じます。**より良いネットワークを学習することは、単に層を積み重ねるほど簡単なのか？**
この疑問に答える上での障害は、収束を最初から妨げる悪名高い勾配消失/爆発問題 \cite{Bengio1994,Glorot2010} でした。しかし、この問題は、正規化初期化 \cite{LeCun1998,Glorot2010,Saxe2013,He2015} および中間正規化層 \cite{Ioffe2015} によって大部分が解決されており、これにより数十層のネットワークでも、バックプロパゲーション \cite{LeCun1989} を伴う確率的勾配降下法（SGD）で収束を開始できるようになりました。

\begin{figure}[t]
\begin{center}
\includegraphics[width=1.0\linewidth]{eps/teaser}
\end{center}
\vspace{-1.2em}
\caption{20層および56層の「プレーンな」ネットワークを用いたCIFAR-10における訓練誤差（左）とテスト誤差（右）。より深いネットワークはより高い訓練誤差、ひいてはテスト誤差を示す。ImageNetでの同様の現象は図~\ref{fig:imagenet}で示す。}
\label{fig:teaser}
\vspace{-1em}
\end{figure}

より深いネットワークが収束を開始できるようになったとき、**劣化**問題が露呈しました。ネットワークの深さが増すにつれて、精度が飽和し（これは驚くことではないかもしれませんが）、その後急速に低下します。意外なことに、このような劣化は**過学習に起因するものではなく**、適切に深いモデルにさらに層を追加すると、\cite{He2015a, Srivastava2015} で報告され、我々の実験によって徹底的に検証されたように、**より高い訓練誤差**につながります。図~\ref{fig:teaser}は典型的な例を示しています。

（訓練精度の）劣化は、すべてのシステムが同様に最適化しやすいわけではないことを示唆しています。より浅いアーキテクチャと、それにさらに層を追加したその深い対応物を考えてみましょう。深いモデルには**構築上**の解が存在します。それは、追加された層が**恒等**写像であり、他の層は学習済みの浅いモデルからコピーされる、というものです。この構築された解の存在は、深いモデルが浅い対応物より高い訓練誤差を生じるべきではないことを示しています。しかし、実験では、現在利用可能なソルバーが、構築された解と同等かそれ以上に良い解を見つけることができない（または、実行可能な時間内にそうすることができない）ことを示しています。

本論文では、**深層残差学習**フレームワークを導入することで劣化問題に対処します。
いくつかの積層された層が所望の基底写像を直接適合させることを期待する代わりに、これらの層が残差写像に適合するように明示的にします。形式的には、所望の基底写像を $\mathcal{H}(\mathbf{x})$ と表すと、積層された非線形層が別の写像 $\mathcal{F}(\mathbf{x}):=\mathcal{H}(\mathbf{x})-\mathbf{x}$ に適合するようにします。元の写像は $\mathcal{F}(\mathbf{x})+\mathbf{x}$ と再定式化されます。
我々は、元の参照されない写像を最適化するよりも、残差写像を最適化する方が容易であると仮説を立てます。極端な話、もし恒等写像が最適である場合、非線形層のスタックによって恒等写像に適合させるよりも、残差をゼロに近づける方が容易であるでしょう。

$\mathcal{F}(\mathbf{x})+\mathbf{x}$ の定式化は、「ショートカット接続」（図~\ref{fig:block}）を持つフィードフォワードニューラルネットワークによって実現できます。ショートカット接続 \cite{Bishop1995,Ripley1996,Venables1999} は、1つまたは複数の層をスキップするものです。我々のケースでは、ショートカット接続は単に**恒等**写像を実行し、その出力は積層された層の出力に追加されます（図~\ref{fig:block}）。恒等ショートカット接続は、追加のパラメータも計算複雑度も加えません。ネットワーク全体は依然として、SGDとバックプロパゲーションによってエンドツーエンドで訓練可能であり、ソルバーを修正することなく、一般的なライブラリ（例：Caffe \cite{Jia2014}）を使用して容易に実装できます。

\begin{figure}[t]
\centering
\hspace{48pt}
\includegraphics[width=0.9\linewidth]{eps/block}
\vspace{-.5em}
\caption{残差学習: 基本ブロック。}
\label{fig:block}
\vspace{-1em}
\end{figure}

我々は、劣化問題を示し、我々の手法を評価するために、ImageNet \cite{Russakovsky2014} で包括的な実験を行います。
我々は次のことを示します。1) 我々の極めて深い残差ネットワークは最適化が容易であるのに対し、深さが増すにつれて、対応する「プレーンな」ネットワーク（単に層を積み重ねたもの）はより高い訓練誤差を示すこと。2) 我々の深層残差ネットワークは、大幅に深さを増やすことによる精度向上を容易に享受でき、以前のネットワークよりも実質的に優れた結果を生み出すこと。

CIFAR-10セット \cite{Krizhevsky2009} でも同様の現象が示されており、最適化の困難さと我々の手法の効果が特定のデータセットに限定されるものではないことを示唆しています。我々は、このデータセットで100層を超えるモデル、さらには1000層を超えるモデルを成功裏に訓練した結果を示します。

ImageNet分類データセット \cite{Russakovsky2014} において、我々は極めて深い残差ネットワークによって優れた結果を得ました。
我々の152層の残差ネットワークは、ImageNetでこれまでに発表された中で最も深いネットワークでありながら、VGGネットワーク \cite{Simonyan2015} よりも低い複雑度を持っています。我々のアンサンブルは、ImageNet**テスト**セットで**3.57\%**のトップ5エラーを達成し、**ILSVRC 2015分類コンペティションで1位を獲得しました**。極めて深い表現は、他の認識タスクでも優れた汎化性能を示し、さらにILSVRC & COCO 2015コンペティションにおいて、**ImageNet検出、ImageNet位置特定、COCO検出、COCOセグメンテーションで1位を獲得**しました。この強い証拠は、残差学習の原理が汎用的であることを示しており、他の視覚問題および非視覚問題にも適用可能であると期待しています。

\section{関連研究}

\noindent\textbf{残差表現}
画像認識において、VLAD \cite{Jegou2012} は辞書に対する残差ベクトルによって符号化する表現であり、Fisher Vector \cite{Perronnin2007} はVLADの確率的バージョン \cite{Jegou2012} として定式化できます。
これらはどちらも画像検索および分類 \cite{Chatfield2011,Vedaldi2008} における強力な浅い表現です。
ベクトル量子化では、残差ベクトルを符号化する方が元のベクトルを符号化するよりも効果的であることが示されています \cite{Jegou2011}。

低レベルビジョンやコンピュータグラフィックスにおいて、偏微分方程式（PDE）を解くために広く用いられているマルチグリッド法 \cite{Briggs2000} は、システムを複数のスケールでのサブ問題として再定式化し、各サブ問題は粗いスケールと細かいスケール間の残差解を担当します。マルチグリッド法の代替として、階層的基底事前調整 \cite{Szeliski1990,Szeliski2006} があり、これは2つのスケール間の残差ベクトルを表す変数に依存します。これらのソルバーは、解の残差的性質を認識していない標準的なソルバーよりもはるかに速く収束することが示されています \cite{Briggs2000,Szeliski1990,Szeliski2006}。これらの方法は、適切な再定式化や事前調整が最適化を単純化しうることを示唆しています。

\noindent\textbf{ショートカット接続}
ショートカット接続 \cite{Bishop1995,Ripley1996,Venables1999} につながる実践と理論は、長年にわたって研究されてきました。
多層パーセプトロン（MLP）の訓練における初期の実践は、ネットワーク入力から出力へ接続される線形層を追加することでした \cite{Ripley1996,Venables1999}。\cite{Szegedy2015,Lee2014} では、勾配消失/爆発に対処するため、いくつかの D中間層が補助分類器に直接接続されています。\cite{Schraudolph1998,Schraudolph1998a,Raiko2012,Vatanen2013} の論文では、ショートカット接続によって実装される、層の応答、勾配、伝播誤差をセンタリングするための手法が提案されています。\cite{Szegedy2015} では、「Inception」層がショートカット分岐といくつかのより深い分岐で構成されています。

我々の研究と同時期に、「ハイウェイネットワーク」 \cite{Srivastava2015,Srivastava2015a} はゲーティング関数 \cite{Hochreiter1997} を伴うショートカット接続を提示しています。これらのゲートはデータ依存であり、パラメータを持つ点で、我々のパラメータフリーな恒等ショートカットとは対照的です。ゲート付きショートカットが「閉じる」（ゼロに近づく）場合、ハイウェイネットワークの層は**非残差**関数を表します。対照的に、我々の定式化は常に残差関数を学習します。我々の恒等ショートカットは決して閉じず、すべての情報が常に通過し、追加の残差関数が学習されます。さらに、ハイウェイネットワークは、極端に深さが増した場合（例：100層以上）に精度向上を示していません。

\section{深層残差学習}
## 残差学習
\label{sec:motivation}

$\mathcal{H}(\ve{x})$を、いくつかの積み重ねられた層（必ずしもネットワーク全体ではない）によって適合させるべき基底写像とみなし、$\ve{x}$をこれらの層の最初の入力とします。もし複数の非線形層が漸近的に複雑な関数を近似できると仮説を立てるならば\footnote{この仮説は、しかしながら、未解決の問題である。\cite{Montufar2014}を参照。}、それは、それらが漸近的に残差関数、すなわち$\mathcal{H}(\ve{x})-\ve{x}$（入力と出力が同じ次元であると仮定）を近似できると仮説を立てることと同等です。したがって、積み重ねられた層が$\mathcal{H}(\ve{x})$を近似することを期待するのではなく、これらの層に明示的に残差関数$\mathcal{F}(\ve{x}):=\mathcal{H}(\ve{x})-\ve{x}$を近似させます。元の関数はしたがって$\mathcal{F}(\ve{x})+\ve{x}$となります。どちらの形式も漸近的に望ましい関数を近似できるはずですが（仮説として）、学習の容易さは異なるかもしれません。

この再定式化は、劣化問題（Fig.~\ref{fig:teaser}、左）に関する直感に反する現象によって動機付けられています。序論で議論したように、追加された層が恒等写像として構築できる場合、より深いモデルは浅いモデルよりも訓練誤差が大きくならないはずです。劣化問題は、ソルバーが複数の非線形層によって恒等写像を近似するのに困難を抱えている可能性を示唆しています。残差学習の再定式化を用いると、もし恒等写像が最適であるならば、ソルバーは単純に複数の非線形層の重みをゼロに近づけて恒等写像に近似させることができます。

実際の場合、恒等写像が最適である可能性は低いですが、私たちの再定式化は問題の事前条件付けに役立つかもしれません。もし最適な関数がゼロ写像よりも恒等写像に近い場合、ソルバーが関数を新しいものとして学習するよりも、恒等写像を参照して摂動を見つける方が容易であるはずです。我々は実験（Fig.~\ref{fig:std}）によって、学習された残差関数が一般に小さい応答を持つことを示しており、これは恒等写像が妥当な事前条件付けを提供する可能性を示唆しています。

## ショートカットによる恒等写像

我々は残差学習を数層おきに適用します。ビルディングブロックはFig.~\ref{fig:block}に示されています。本論文では、形式的に、ビルディングブロックを以下のように定義します。

$$
\ve{y}= \mathcal{F}(\ve{x}, \{W_{i}\}) + \ve{x}.
\label{eq:identity}
$$

ここで、$\ve{x}$と$\ve{y}$は考慮されている層の入力ベクトルと出力ベクトルです。関数$\mathcal{F}(\ve{x}, \{W_{i}\})$は学習される残差写像を表します。Fig.~\ref{fig:block}の2層の例では、$\mathcal{F}=W_{2}\sigma(W_{1}\ve{x})$であり、$\sigma$はReLU \cite{Nair2010}を表し、表記を簡略化するためにバイアスは省略されています。演算$\mathcal{F}+\ve{x}$はショートカット接続と要素ごとの加算によって実行されます。我々は加算後に2番目の非線形性（すなわち$\sigma(\ve{y})$、Fig.~\ref{fig:block}を参照）を採用します。

式(\ref{eq:identity})におけるショートカット接続は、追加のパラメータも計算量も導入しません。これは実用上魅力的であるだけでなく、プレーンネットワークと残差ネットワークの比較において重要です。パラメータ数、深さ、幅、計算コスト（ごくわずかな要素ごとの加算を除く）が同時に同じであるプレーン/残差ネットワークを公平に比較できます。

式(\ref{eq:identity})において、$\ve{x}$と$\mathcal{F}$の次元は等しくなければなりません。もしそうでない場合（例：入力/出力チャンネルの変更時）、ショートカット接続によって線形射影$W_{s}$を実行し、次元を一致させることができます。

$$
\ve{y}= \mathcal{F}(\ve{x}, \{W_{i}\}) + W_{s}\ve{x}.
\label{eq:transform}
$$

式(\ref{eq:identity})で正方行列$W_{s}$を使用することも可能です。しかし、実験によって、恒等写像が劣化問題に対処するのに十分であり、経済的であることを示します。したがって、$W_{s}$は次元を一致させる場合にのみ使用されます。

残差関数$\mathcal{F}$の形式は柔軟です。本論文の実験では、$\mathcal{F}$は2層または3層の関数（Fig.~\ref{fig:block_deeper}）を含みますが、より多くの層も可能です。しかし、もし$\mathcal{F}$が単一層のみを持つ場合、式(\ref{eq:identity})は線形層$\ve{y}=W_1\ve{x}+\ve{x}$に類似しており、この場合、利点は観察されていません。

上記の表記は簡略化のために全結合層に関するものですが、畳み込み層にも適用可能であることに注意してください。関数$\mathcal{F}(\ve{x}, \{W_{i}\})$は複数の畳み込み層を表すことができます。要素ごとの加算は、2つの特徴マップ上でチャンネルごとに実行されます。

*図1: ImageNetのネットワークアーキテクチャ例。**左**: 参照としてのVGG-19モデル \cite{Simonyan2015} (196億FLOPs)。**中央**: 34のパラメータ層を持つプレーンネットワーク (36億FLOPs)。**右**: 34のパラメータ層を持つ残差ネットワーク (36億FLOPs)。点線のショートカットは次元を増加させます。**表\ref{tab:arch}**には詳細とその他のバリアントが示されています。*
## ネットワークアーキテクチャ

様々なプレーン/残差ネットワークをテストし、一貫した現象を観察しました。議論のための具体例として、ImageNet向けの2つのモデルを以下に記述します。

### プレーンネットワーク

私たちのプレーンなベースライン（図\ref{fig:arch}中央）は、主にVGGネット\cite{Simonyan2015}（図\ref{fig:arch}左）の哲学に触発されています。
畳み込み層は、ほとんどが$3\times3$のフィルタを持ち、2つのシンプルな設計規則に従います。(i) 同じ出力特徴マップサイズの場合、層は同じ数のフィルタを持ちます。(ii) 特徴マップサイズが半分になる場合、各層の時間計算量を維持するためにフィルタ数が2倍になります。ダウンサンプリングは、ストライド2の畳み込み層によって直接実行されます。
ネットワークは、グローバル平均プーリング層と、ソフトマックスを備えた1000個の全結合層で終了します。図\ref{fig:arch}（中央）における重み付き層の総数は34です。

特筆すべきは、私たちのモデルがVGGネット\cite{Simonyan2015}（図\ref{fig:arch}左）よりも*少ない*フィルタと*低い*複雑性を持つことです。私たちの34層ベースラインは36億FLOPs（乗加算）であり、これはVGG-19（196億FLOPs）のわずか18%です。

### 残差ネットワーク

上記のプレーンネットワークに基づき、ショートカット接続（図\ref{fig:arch}右）を挿入することで、ネットワークを対応する残差バージョンに変換します。
恒等ショートカット（式(\ref{eq:identity})）は、入力と出力が同じ次元である場合（図\ref{fig:arch}の実線ショートカット）に直接使用できます。
次元が増加する場合（図\ref{fig:arch}の点線ショートカット）は、2つの選択肢を検討します。
(A) ショートカットは引き続き恒等マッピングを実行し、次元増加のために余分なゼロエントリをパディングします。この選択肢は追加のパラメータを導入しません。
(B) 式(\ref{eq:transform})の射影ショートカットを使用して次元を合わせます（$1\times1$畳み込みによって実行）。
どちらの選択肢でも、ショートカットが2つの異なるサイズの特徴マップを横断する場合、ストライド2で実行されます。

| layer name | output size | 18-layer | 34-layer | 50-layer | 101-layer | 152-layer |
|:---|:---|:---|:---|:---|:---|:---|
| conv1 | $112\times112$ | \multicolumn{5}{c|}{$7\times7$, 64, stride 2} |
| conv2\_x | $56\times56$ | \multicolumn{5}{c|}{$3\times3$ max pool, stride 2} |
| | | [[$3\times3$, 64], [$3\times3$, 64]] x2 | [[$3\times3$, 64], [$3\times3$, 64]] x3 | [[$1\times1$, 64], [$3\times3$, 64], [$1\times1$, 256]] x3 | [[$1\times1$, 64], [$3\times3$, 64], [$1\times1$, 256]] x3 | [[$1\times1$, 64], [$3\times3$, 64], [$1\times1$, 256]] x3 |
| conv3\_x | $28\times28$ | [[$3\times3$, 128], [$3\times3$, 128]] x2 | [[$3\times3$, 128], [$3\times3$, 128]] x4 | [[$1\times1$, 128], [$3\times3$, 128], [$1\times1$, 512]] x4 | [[$1\times1$, 128], [$3\times3$, 128], [$1\times1$, 512]] x4 | [[$1\times1$, 128], [$3\times3$, 128], [$1\times1$, 512]] x8 |
| conv4\_x | $14\times14$ | [[$3\times3$, 256], [$3\times3$, 256]] x2 | [[$3\times3$, 256], [$3\times3$, 256]] x6 | [[$1\times1$, 256], [$3\times3$, 256], [$1\times1$, 1024]] x6 | [[$1\times1$, 256], [$3\times3$, 256], [$1\times1$, 1024]] x23 | [[$1\times1$, 256], [$3\times3$, 256], [$1\times1$, 1024]] x36 |
| conv5\_x | $7\times7$ | [[$3\times3$, 512], [$3\times3$, 512]] x2 | [[$3\times3$, 512], [$3\times3$, 512]] x3 | [[$1\times1$, 512], [$3\times3$, 512], [$1\times1$, 2048]] x3 | [[$1\times1$, 512], [$3\times3$, 512], [$1\times1$, 2048]] x3 | [[$1\times1$, 512], [$3\times3$, 512], [$1\times1$, 2048]] x3 |
| | $1\times1$ | \multicolumn{5}{c|}{average pool, 1000-d fc, softmax} |
| \multicolumn{2}{c|}{FLOPs} | $1.8\times10^9$ | $3.6\times10^9$ | $3.8\times10^9$ | $7.6\times10^9$ | $11.3\times10^9$ |
*表: ImageNetのアーキテクチャ。ビルディングブロックは括弧内に示され（図\ref{fig:block_deeper}も参照）、スタックされたブロックの数が記述されています。ダウンサンプリングは、conv3\_1、conv4\_1、およびconv5\_1によってストライド2で実行されます。*

*図: **ImageNet**での学習。細い曲線は学習誤差を示し、太い曲線は中央クロップの検証誤差を示します。左：18層および34層のプレーンネットワーク。右：18層および34層のResNet。このプロットでは、残差ネットワークはプレーンな対応物と比較して追加のパラメータを持ちません。*

## 実装
ImageNet向けの私たちの実装は、\cite{Krizhevsky2012,Simonyan2015}の慣行に従っています。画像は、スケール増強\cite{Simonyan2015}のために、短い辺が$[256, 480]$の範囲でランダムにサンプリングされてリサイズされます。$224\times224$のクロップは、画像またはその水平反転からランダムにサンプリングされ、ピクセルごとの平均が減算されます\cite{Krizhevsky2012}。\cite{Krizhevsky2012}の標準的な色増強が使用されます。
私たちは、各畳み込みの直後、かつ活性化の前に、バッチ正規化（BN）\cite{Ioffe2015}を採用しています\cite{Ioffe2015}。
私たちは\cite{He2015}のように重みを初期化し、すべてのプレーン/残差ネットワークをゼロから訓練します。
ミニバッチサイズ256のSGDを使用します。学習率は0.1から開始し、誤差がプラトーに達したときに10で除算され、モデルは最大$60\times10^4$イテレーションまで訓練されます。重み減衰は0.0001、モメンタムは0.9を使用します。\cite{Ioffe2012}の慣行に従い、ドロップアウト\cite{Hinton2012}は使用しません。

テストでは、比較研究のために標準的な10-クロップテスト\cite{Krizhevsky2012}を採用しています。
最良の結果を得るために、\cite{Simonyan2015,He2015}のように全畳み込み形式を採用し、複数スケールでのスコアを平均します（短い辺が$\{224, 256, 384, 480, 640\}$となるように画像がリサイズされます）。

# 実験
## 3.3. ImageNet分類
\label{sec:imagenet}

我々は、1000クラスからなるImageNet 2012分類データセット \cite{Russakovsky2014} で我々の手法を評価する。モデルは128万枚の訓練画像で訓練され、5万枚の検証画像で評価される。また、テストサーバーによって報告される10万枚のテスト画像で最終結果も得られる。我々はtop-1およびtop-5エラー率の両方を評価する。

**プレーンネットワーク**
まず、18層および34層のプレーンネットを評価する。34層のプレーンネットは図\ref{fig:arch}（中央）に示されている。18層のプレーンネットも同様の形式である。詳細なアーキテクチャについては表\ref{tab:arch}を参照のこと。

表\ref{tab:plain_vs_shortcut}の結果は、より深い34層のプレーンネットが、より浅い18層のプレーンネットよりも高い検証エラーを示すことを示している。その理由を明らかにするため、図\ref{fig:imagenet}（左）で、訓練過程におけるそれらの訓練/検証エラーを比較している。我々は性能劣化問題（degradation problem）を観測した。18層のプレーンネットワークの解空間が34層のネットワークのそれの部分空間であるにもかかわらず、34層のプレーンネットは訓練過程全体を通してより高い*訓練*エラーを示している。

| | plain | ResNet |
|:---|:---:|:---:|
| 18 layers | 27.94 | 27.88 |
| 34 layers | 28.54 | **25.03** |
*表: ImageNet検証セットにおけるTop-1エラー（%、10-cropテスト）。ここでResNetはプレーンネットワークと比べて追加のパラメータを持たない。図\ref{fig:imagenet}は訓練過程を示す。*
\label{tab:plain_vs_shortcut}

我々は、この最適化の困難さは勾配消失によって引き起こされる可能性は*低い*と主張する。これらのプレーンネットワークはBN \cite{Ioffe2015} を用いて訓練されており、これにより順伝播される信号がゼロでない分散を持つことが保証される。我々はまた、逆伝播される勾配がBNによって健全なノルムを示すことを確認した。したがって、順伝播信号も逆伝播信号も消失しない。
実際、34層のプレーンネットは依然として競争力のある精度を達成しており（表\ref{tab:10crop}）、ソルバーがある程度機能していることを示唆している。我々は、深いプレーンネットが指数関数的に低い収束率を持つ可能性があり、それが訓練誤差の削減に影響を与えていると推測する\footnote{より多くの訓練反復（3倍）を試したが、依然として性能劣化問題が観測された。このことは、この問題が単に反復回数を増やすだけでは対処できないことを示唆している。}。
このような最適化の困難さの理由は、今後研究されるだろう。

**残差ネットワーク（ResNet）**
次に、18層および34層の残差ネット（*ResNet*）を評価する。ベースラインアーキテクチャは上記のプレーンネットと同じだが、図\ref{fig:arch}（右）のように、3$\times$3フィルタの各ペアにショートカット接続が追加されている。最初の比較（表\ref{tab:plain_vs_shortcut}および図\ref{fig:imagenet}右）では、すべてのショートカットに恒等写像を、次元増加にはゼロパディング（オプションA）を使用している。そのため、これらはプレーンネットワークと比較して*追加のパラメータを持たない*。

表\ref{tab:plain_vs_shortcut}と図\ref{fig:imagenet}から3つの主要な観察がある。まず、残差学習では状況が逆転し、34層のResNetは18層のResNetよりも優れている（2.8%向上）。さらに重要なことに、34層のResNetは著しく低い訓練誤差を示し、検証データへの汎化が可能である。これは、性能劣化問題がこの設定でうまく対処され、深さの増加から精度向上を達成できたことを示している。

第二に、プレーンネットワークと比較して、34層のResNetはTop-1エラーを3.5%削減している（表\ref{tab:plain_vs_shortcut}）。これは、訓練誤差がうまく削減された結果である（図\ref{fig:imagenet}右対左）。この比較は、極めて深いシステムにおける残差学習の有効性を検証している。

最後に、18層のプレーン/残差ネットは同程度の精度であることがわかるが（表\ref{tab:plain_vs_shortcut}）、18層のResNetはより速く収束する（図\ref{fig:imagenet}右対左）。
ネットワークが「過度に深く」ない場合（ここでは18層）、現在のSGDソルバーはプレーンネットに対しても良好な解を見つけることができる。この場合、ResNetは初期段階でより速い収束を提供することで、最適化を容易にする。

| model | top-1 err. | top-5 err. |
|:---|:---:|:---:|
| VGG-16 \cite{Simonyan2015} | 28.07 | 9.33 |
| GoogLeNet \cite{Szegedy2015} | - | 9.15 |
| PReLU-net \cite{He2015} | 24.27 | 7.38 |
| --- | --- | --- |
| plain-34 | 28.54 | 10.02 |
| ResNet-34 A | 25.03 | 7.76 |
| ResNet-34 B | 24.52 | 7.46 |
| ResNet-34 C | 24.19 | 7.40 |
| --- | --- | --- |
| ResNet-50 | 22.85 | 6.71 |
| ResNet-101 | 21.75 | 6.05 |
| ResNet-152 | **21.43** | **5.71** |
*表: ImageNet検証セットにおけるエラー率（%、**10-crop**テスト）。VGG-16は我々のテストに基づく。ResNet-50/101/152は次元増加にのみ射影を使用するオプションBである。*
\label{tab:10crop}

| method | top-1 err. | top-5 err. |
|:---|:---:|:---:|
| VGG \cite{Simonyan2015} (ILSVRC'14) | - | 8.43$^{\dag}$ |
| GoogLeNet \cite{Szegedy2015} (ILSVRC'14) | - | 7.89 |
| --- | --- | --- |
| VGG \cite{Simonyan2015} (v5) | 24.4 | 7.1 |
| PReLU-net \cite{He2015} | 21.59 | 5.71 |
| BN-inception \cite{Ioffe2015} | 21.99 | 5.81 |
| --- | --- | --- |
| ResNet-34 B | 21.84 | 5.71 |
| ResNet-34 C | 21.53 | 5.60 |
| ResNet-50 | 20.74 | 5.25 |
| ResNet-101 | 19.87 | 4.60 |
| ResNet-152 | **19.38** | **4.49** |
*表: ImageNet検証セットにおける**シングルモデル**結果のエラー率（%）（$^{\dag}$はテストセットで報告されたもの）。*
\label{tab:single}

| method | top-5 err. (**test**) |
|:---|:---:|
| VGG \cite{Simonyan2015} (ILSVRC'14) | 7.32 |
| GoogLeNet \cite{Szegedy2015} (ILSVRC'14) | 6.66 |
| --- | --- |
| VGG \cite{Simonyan2015} (v5) | 6.8 |
| PReLU-net \cite{He2015} | 4.94 |
| BN-inception \cite{Ioffe2015} | 4.82 |
| --- | --- |
| **ResNet (ILSVRC'15)** | **3.57** |
*表: **アンサンブル**のエラー率（%）。Top-5エラーはImageNetテストセットで、テストサーバーによって報告された。*
\label{tab:ensemble}

**恒等ショートカットと射影ショートカット**
パラメータフリーの恒等ショートカットが訓練に役立つことを示した。次に、射影ショートカット（式(\ref{eq:transform})）を調査する。
表\ref{tab:10crop}では、3つのオプションを比較している。(A) 次元増加にゼロパディングショートカットを使用し、すべてのショートカットがパラメータフリーである（表\ref{tab:plain_vs_shortcut}および図\ref{fig:imagenet}右と同じ）。(B) 次元増加に射影ショートカットを使用し、他のショートカットは恒等である。(C) すべてのショートカットが射影である。

表\ref{tab:10crop}は、これら3つのオプションすべてがプレーンネットワークよりも著しく優れていることを示している。
BはAよりもわずかに優れている。これは、Aにおけるゼロパディングされた次元には残差学習が実際に行われていないためだと我々は主張する。CはBよりもわずかに優れており、これは多くの（13個の）射影ショートカットによって導入された追加パラメータに起因すると我々は考えている。しかし、A/B/C間の小さな違いは、性能劣化問題に対処するために射影ショートカットが本質的ではないことを示している。そのため、メモリ/時間計算量とモデルサイズを削減するために、本論文の残りの部分ではオプションCを使用しない。恒等ショートカットは、後で導入されるボトルネックアーキテクチャの複雑さを増やさないために特に重要である。

![block_deeper](eps/block_deeper)
*図: ImageNetのためのより深い残差関数$\mathcal{F}$。左：ResNet-34のための図\ref{fig:arch}にあるような構築ブロック（56$\times$56特徴マップ上）。右：「ボトルネック」構築ブロック（ResNet-50/101/152用）。*
\label{fig:block_deeper}

**より深いボトルネックアーキテクチャ**
次に、ImageNet用のより深いネットワークについて説明する。我々が許容できる訓練時間を考慮し、構築ブロックを*ボトルネック*設計に変更した\footnote{より深い*非*ボトルネックResNet（例：図\ref{fig:block_deeper}左）も、深さの増加によって精度が向上する（CIFAR-10で示されているように）が、ボトルネックResNetほど経済的ではない。したがって、ボトルネック設計の使用は主に実用的な考慮事項によるものである。また、プレーンネットの性能劣化問題はボトルネック設計でも見られることに注意する。}。
各残差関数$\mathcal{F}$について、2層ではなく3層のスタックを使用する（図\ref{fig:block_deeper}）。3層は1$\times$1、3$\times$3、および1$\times$1畳み込みであり、1$\times$1層は次元を減らして（復元して）増やす役割を担い、3$\times$3層をより小さな入出力次元を持つボトルネックにする。
図\ref{fig:block_deeper}は例を示しており、両方の設計で同様の時間計算量を持つ。

パラメータフリーの恒等ショートカットは、ボトルネックアーキテクチャにとって特に重要である。図\ref{fig:block_deeper}（右）の恒等ショートカットを射影に置き換えると、ショートカットが2つの高次元の端に接続されているため、時間計算量とモデルサイズが倍増することが示される。したがって、恒等ショートカットはボトルネック設計に対してより効率的なモデルにつながる。

**50層ResNet:** 34層ネットの各2層ブロックをこの3層ボトルネックブロックに置き換え、50層ResNetを構築する（表\ref{tab:arch}）。次元増加にはオプションBを使用する。
このモデルは38億FLOPsを持つ。

**101層および152層ResNet:** より多くの3層ブロックを使用することで、101層および152層のResNetを構築する（表\ref{tab:arch}）。
注目すべきことに、深さが著しく増加しているにもかかわらず、152層ResNet（113億FLOPs）はVGG-16/19ネット（153億/196億FLOPs）よりも*低い複雑度*を持つ。

50/101/152層のResNetは、34層のそれらよりも著しい差で精度が高い（表\ref{tab:10crop}および\ref{tab:single}）。性能劣化問題は観測されず、深さの大幅な増加からかなりの精度向上を享受している。深さの利点は、すべての評価指標で確認される（表\ref{tab:10crop}および\ref{tab:single}）。

![cifar](eps/cifar)
*図: **CIFAR-10**での訓練。破線は訓練誤差、太線はテスト誤差を示す。**左**：プレーンネットワーク。plain-110の誤差は60%より高いため表示されていない。**中央**：ResNet。**右**：110層および1202層のResNet。*
\label{fig:cifar}

**最新技術との比較**
表\ref{tab:single}で、以前の最高のシングルモデル結果と比較している。
我々のベースラインである34層ResNetは、非常に競争力のある精度を達成している。
我々の152層ResNetは、シングルモデルでTop-5検証エラーが4.49%である。このシングルモデルの結果は、以前のすべてのアンサンブル結果を上回っている（表\ref{tab:ensemble}）。
我々は、異なる深さの6つのモデルを組み合わせてアンサンブルを形成した（提出時には2つの152層モデルのみ）。これにより、テストセットで**3.57%**のTop-5エラーを達成した（表\ref{tab:ensemble}）。*このエントリはILSVRC 2015で1位を獲得した。*
## CIFAR-10と解析

CIFAR-10データセット \cite{Krizhevsky2009} でさらなる研究を実施しました。このデータセットは、10クラスにわたる5万枚の訓練画像と1万枚のテスト画像から構成されています。訓練セットで訓練し、テストセットで評価した実験結果を示します。
私たちの焦点は、極めて深いネットワークの振る舞いを調べることであり、最先端の結果を追求することではありません。そのため、意図的に以下のような単純なアーキテクチャを使用しました。

プレーン/残差アーキテクチャは、図\ref{fig:arch} (中央/右) の形式に従います。
ネットワーク入力は32$\times$32画像で、ピクセルごとの平均が差し引かれています。最初の層は3$\times$3の畳み込みです。次に、特徴マップサイズがそれぞれ$\{32, 16, 8\}$の3$\times$3畳み込み層を$6n$層積み重ねています。各特徴マップサイズには$2n$層が割り当てられています。フィルタの数はそれぞれ$\{16, 32, 64\}$です。サブサンプリングはストライド2の畳み込みによって行われます。ネットワークはグローバル平均プーリング、10方向全結合層、およびソフトマックスで終了します。合計で$6n+2$個の積み重ねられた重み付き層があります。以下の表にアーキテクチャをまとめます。

| 出力マップサイズ | 32$\times$32 | 16$\times$16 | 8$\times$8 |
|---|---|---|---|
| 層数 | 1+$2n$ | $2n$ | $2n$ |
| フィルタ数 | 16 | 32 | 64 |

ショートカット接続を使用する場合、それらは3$\times$3層のペアに接続されます（合計$3n$個のショートカット）。このデータセットでは、すべての場合において同一性ショートカット（すなわち、オプションA）を使用するため、私たちの残差モデルはプレーンモデルとまったく同じ深さ、幅、およびパラメータ数を持っています。

| \multicolumn{3}{c|}{手法} | エラー率 (%) |
|---|---|---|---|
| \multicolumn{3}{c|}{Maxout \cite{Goodfellow2013}} | 9.38 |
| \multicolumn{3}{c|}{NIN \cite{Lin2013}} | 8.81 |
| \multicolumn{3}{c|}{DSN \cite{Lee2014}} | 8.22 |
| | 層数 | パラメータ数 | |
| FitNet \cite{Romero2015} | 19 | 2.5M | 8.39 |
| Highway \cite{Srivastava2015,Srivastava2015a} | 19 | 2.3M | 7.54 (7.72$\pm$0.16) |
| Highway \cite{Srivastava2015,Srivastava2015a} | 32 | 1.25M | 8.80 |
| ResNet | 20 | 0.27M | 8.75 |
| ResNet | 32 | 0.46M | 7.51 |
| ResNet | 44 | 0.66M | 7.17 |
| ResNet | 56 | 0.85M | 6.97 |
| ResNet | 110 | 1.7M | **6.43** (6.61$\pm$0.16) |
| ResNet | 1202 | 19.4M | 7.93 |

*表: **CIFAR-10**テストセットにおける分類エラー。すべての手法はデータ拡張を使用しています。ResNet-110については、\cite{Srivastava2015a}と同様に5回実行し、「best (mean$\pm$std)」を示しています。*

重み減衰を0.0001、モーメンタムを0.9に設定し、\cite{He2015}の重み初期化とBN \cite{Ioffe2015}を採用しましたが、ドロップアウトは使用しませんでした。これらのモデルは、128のミニバッチサイズで2つのGPU上で訓練されます。学習率は0.1で開始し、32kおよび48kイテレーションで10分の1に分割し、64kイテレーションで訓練を終了します。これは45k/5kの訓練/検証分割で決定されました。訓練のための単純なデータ拡張は\cite{Lee2014}に従います。各辺に4ピクセルをパディングし、パディングされた画像またはその水平反転から32$\times$32の画像をランダムにサンプリングします。テストでは、元の32$\times$32画像の単一ビューのみを評価します。

$n=\{3,5,7,9\}$を比較し、それぞれ20、32、44、56層のネットワークになります。
図\ref{fig:cifar} (左) は、プレーンネットワークの振る舞いを示しています。深いプレーンネットワークは深さの増加によって影響を受け、より深くするにつれて訓練エラーが高くなります。この現象はImageNet (図\ref{fig:imagenet}, 左) やMNIST (Srivastava et al. \cite{Srivastava2015}を参照) のそれと類似しており、このような最適化の困難さが根本的な問題であることを示唆しています。

図\ref{fig:cifar} (中央) はResNetの振る舞いを示しています。ImageNetの場合 (図\ref{fig:imagenet}, 右) と同様に、私たちのResNetは最適化の困難さを克服し、深さが増すにつれて精度が向上することを示しています。

さらに、110層のResNetとなる$n=18$を調査しました。この場合、初期学習率0.1が収束を開始するにはわずかに大きすぎることがわかりました\footnote{初期学習率0.1でも、数エポック後に収束（エラー率90%未満）を開始し、最終的には同様の精度に達します。}。そこで、訓練エラーが80%を下回るまで（約400イテレーション）、ウォームアップとして0.01を使用し、その後0.1に戻して訓練を続行しました。残りの学習スケジュールは以前と同様です。この110層ネットワークは良好に収束します (図\ref{fig:cifar}, 中央)。FitNet \cite{Romero2015}やHighway \cite{Srivastava2015}のような他の深くて薄いネットワークよりもパラメータが**少ない**にもかかわらず (表\ref{tab:cifar})、最先端の結果の一つです (6.43%, 表\ref{tab:cifar})。

*図: CIFAR-10における層応答の標準偏差 (std)。応答は、BNの後で非線形性の前（ReLU/加算）における各3$\times$3層の出力です。**上**: 層は元の順序で示されています。**下**: 応答は降順にランク付けされています。*

**層応答の解析**
図\ref{fig:std}は、層応答の標準偏差 (std) を示しています。応答は、BNの後で他の非線形性（ReLU/加算）の前における各3$\times$3層の出力です。ResNetの場合、この解析は残差関数の応答強度を明らかにします。
図\ref{fig:std}は、ResNetが一般的にプレーンな対応物よりも小さい応答を持つことを示しています。これらの結果は、残差関数が非残差関数よりも一般的にゼロに近いという私たちの基本的な動機 (セクション\ref{sec:motivation}) を支持しています。
また、図\ref{fig:std}におけるResNet-20、56、110の比較から明らかなように、より深いResNetは応答の大きさが小さいことにも気づきます。層が多い場合、ResNetの個々の層は信号をより少なく修正する傾向があります。

**1000層超の探索**
1000層を超える積極的に深いモデルを探索します。$n=200$を設定し、1202層のネットワークを作成し、上記のように訓練しました。私たちの手法は**最適化の困難さ**を示さず、この$10^3$層ネットワークは訓練エラーが0.1%未満を達成することができます (図\ref{fig:cifar}, 右)。テストエラーもかなり良好です (7.93%, 表\ref{tab:cifar})。

しかし、このような積極的に深いモデルにはまだ未解決の問題があります。
この1202層ネットワークのテスト結果は、私たちの110層ネットワークのそれよりも悪いですが、両者とも同様の訓練エラーを持っています。これは過学習によるものだと私たちは主張します。
1202層ネットワークは、この小さなデータセットに対して不必要に大きい（19.4M）可能性があります。このデータセットで最高の結果を得るためには、maxout \cite{Goodfellow2013} やドロップアウト \cite{Hinton2012} のような強力な正則化が適用されています (\cite{Goodfellow2013,Lin2013,Lee2014,Romero2015})。
本論文では、maxout/ドロップアウトは使用せず、設計上、深くて薄いアーキテクチャを通じて単純に正則化を課し、最適化の困難さに焦点を当てることを妨げないようにしました。しかし、より強力な正則化と組み合わせることで結果が改善される可能性があり、これは将来の研究で検討します。
## 2.3 PASCALおよびMS COCOにおける物体検出

| training data | 07+12 | 07++12 |
|---|---|---|
| test data | VOC 07 test | VOC 12 test |
| VGG-16 | 73.2 | 70.4 |
| ResNet-101 | **76.4** | **73.8** |
*表: **ベースライン**のFaster R-CNNを用いたPASCAL VOC 2007/2012テストセットにおける物体検出mAP (%)。より良い結果については表~\ref{tab:voc07_all}および~\ref{tab:voc12_all}も参照。*

| metric | ~~~mAP@.5~~~ | mAP@[.5, .95] |
|---|---|---|
| VGG-16 | 41.5 | 21.2 |
| ResNet-101 | **48.4** | **27.2** |
*表: **ベースライン**のFaster R-CNNを用いたCOCOバリデーションセットにおける物体検出mAP (%)。より良い結果については表~\ref{tab:detection_coco_improve}も参照。*

我々の手法は、他の認識タスクにおいても良好な汎化性能を示す。表~\ref{tab:detection_voc}および~\ref{tab:detection_coco}は、PASCAL VOC 2007および2012 \cite{Everingham2010}、そしてCOCO \cite{Lin2014}における物体検出のベースライン結果を示している。検出手法として*Faster R-CNN* \cite{Ren2015}を採用する。ここでは、VGG-16 \cite{Simonyan2015}をResNet-101に置き換えることによる改善に関心がある。両モデルを用いた検出実装（付録を参照）は同じであるため、向上はより優れたネットワークにのみ帰することができる。特に注目すべきは、挑戦的なCOCOデータセットにおいて、COCOの標準指標（mAP@[.5, .95]）で6.0%の増加、すなわち28%の相対的な改善を達成したことである。この向上は、学習された表現にのみ起因する。

深層残差ネットワークに基づき、我々はILSVRC & COCO 2015コンペティションのいくつかのトラック（ImageNet検出、ImageNet位置特定、COCO検出、COCOセグメンテーション）で1位を獲得した。詳細は付録に記載されている。

---

\newpage

## 付録
## A. 物体検出のベースライン

このセクションでは、ベースラインのFaster R-CNN \cite{Ren2015}システムに基づく我々の検出手法を紹介する。モデルはImageNet分類モデルによって初期化され、その後物体検出データでファインチューニングされる。我々はILSVRC & COCO 2015検出コンペティション当時、ResNet-50/101で実験を行った。

\cite{Ren2015}で用いられたVGG-16とは異なり、我々のResNetは隠れた全結合層を持たない。この問題に対処するため、我々は「畳み込み特徴マップ上のネットワーク」（NoC）\cite{Ren2015a}のアイデアを採用した。画像上でのストライドが16ピクセル以下の層（すなわち、conv1、conv2\_x、conv3\_x、およびconv4\_x、ResNet-101では合計91の畳み込み層；表~\ref{tab:arch}）を用いて、全画像共有畳み込み特徴マップを計算する。これらの層をVGG-16における13の畳み込み層に類似するものと見なし、そうすることで、ResNetとVGG-16の両方が同じ総ストライド（16ピクセル）の畳み込み特徴マップを持つことになる。これらの層は、領域提案ネットワーク（RPN、300個の提案を生成）\cite{Ren2015}とFast R-CNN検出ネットワーク\cite{Girshick2015}によって共有される。RoIプーリング\cite{Girshick2015}はconv5_1の前に行われる。このRoIプーリングされた特徴量に対して、conv5_x以降の全ての層が各領域に採用され、VGG-16の全結合層の役割を果たす。最終的な分類層は、2つの姉妹層（分類とボックス回帰\cite{Girshick2015}）に置き換えられる。

BN層の使用に関しては、事前学習後、ImageNet学習セットで各層のBN統計（平均と分散）を計算する。その後、物体検出のためのファインチューニング中、BN層は固定される。そのため、BN層は一定のオフセットとスケールを持つ線形活性化となり、BN統計はファインチューニングによって更新されない。我々は主にFaster R-CNNの学習におけるメモリ消費を削減するためにBN層を固定している。

**PASCAL VOC**

\cite{Girshick2015,Ren2015}に従い、PASCAL VOC 2007の*テスト*セットについては、VOC 2007の5k枚の*学習+検証*画像とVOC 2012の16k枚の*学習+検証*画像を学習に使用した（「07+12」）。PASCAL VOC 2012の*テスト*セットについては、VOC 2007の10k枚の*学習+検証*+*テスト*画像とVOC 2012の16k枚の*学習+検証*画像を学習に使用した（「07++12」）。Faster R-CNNの学習のためのハイパーパラメータは\cite{Ren2015}と同じである。表~\ref{tab:detection_voc}に結果を示す。ResNet-101はVGG-16と比較してmAPを3%以上改善している。この向上は、ResNetによって学習された改善された特徴にのみ起因する。

**MS COCO**

MS COCOデータセット\cite{Lin2014}は80の物体カテゴリを含む。我々はPASCAL VOC指標（mAP @ IoU = 0.5）と標準COCO指標（mAP @ IoU = .5:.05:.95）を評価した。学習には学習セットの80k枚の画像を、評価にはバリデーションセットの40k枚の画像を使用した。COCOのための我々の検出システムはPASCAL VOCのためのものと同様である。我々は8-GPU実装でCOCOモデルを学習し、そのためRPNステップでは8枚の画像（すなわちGPUあたり1枚）のミニバッチサイズを、Fast R-CNNステップでは16枚の画像のミニバッチサイズを持つ。RPNステップとFast R-CNNステップは両方とも、学習率0.001で240kイテレーション、その後学習率0.0001で80kイテレーション学習される。

表~\ref{tab:detection_coco}にMS COCOバリデーションセットでの結果を示す。ResNet-101はVGG-16と比較してmAP@[.5, .95]で6%の増加を達成しており、これは28%の相対的な改善であり、より優れたネットワークによって学習された特徴のみが寄与している。注目すべきことに、mAP@[.5, .95]の絶対的な増加（6.0%）はmAP@.5の増加（6.9%）とほぼ同程度である。これは、より深いネットワークが認識と位置特定の両方を改善できることを示唆している。
# 物体検出の改善

完全を期すため、競技会での改善点を報告します。これらの改善は深層特徴量に基づいており、残差学習の恩恵を受けるはずです。

| 訓練データ | \multicolumn{2}{c|}{COCO train} | \multicolumn{2}{c}{COCO trainval} |
|---|---|---|---|---|
| テストデータ | \multicolumn{2}{c|}{COCO val} | \multicolumn{2}{c}{COCO test-dev} |
| mAP | @.5 | @[.5, .95] | @.5 | @[.5, .95] |
| baseline Faster R-CNN (VGG-16) | 41.5 | 21.2 | | |
| baseline Faster R-CNN (ResNet-101) | 48.4 | 27.2 | | |
| ~+box refinement | 49.9 | 29.9 | | |
| ~+context | 51.1 | 30.0 | 53.3 | 32.2 |
| ~+multi-scale testing | 53.8 | 32.5 | **55.7** | **34.9** |
| ensemble | | | **59.0** | **37.4** |

*表1: Faster R-CNNとResNet-101を用いたMS COCOでの物体検出の改善点。*

| システム | ネットワーク | データ | mAP | areo | bike | bird | boat | bottle | bus | car | cat | chair | cow | table | dog | horse | mbike | person | plant | sheep | sofa | train | tv |
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
| baseline | VGG-16 | 07+12 | 73.2 | 76.5 | 79.0 | 70.9 | 65.5 | 52.1 | 83.1 | 84.7 | 86.4 | 52.0 | 81.9 | 65.7 | 84.8 | 84.6 | 77.5 | 76.7 | 38.8 | 73.6 | 73.9 | 83.0 | 72.6 |
| baseline | ResNet-101 | 07+12 | 76.4 | 79.8 | 80.7 | 76.2 | 68.3 | 55.9 | 85.1 | 85.3 | **89.8** | 56.7 | 87.8 | 69.4 | 88.3 | 88.9 | 80.9 | 78.4 | 41.7 | 78.6 | 79.8 | 85.3 | 72.0 |
| baseline+++ | ResNet-101 | COCO+07+12 | **85.6** | **90.0** | **89.6** | **87.8** | **80.8** | **76.1** | **89.9** | **89.9** | 89.6 | **75.5** | **90.0** | **80.7** | **89.6** | **90.3** | **89.1** | **88.7** | **65.4** | **88.1** | **85.6** | **89.0** | **86.8** |

*表2: PASCAL VOC 2007テストセットでの検出結果。ベースラインはFaster R-CNNシステム。「baseline+++」システムは、表1のボックスリファインメント、コンテキスト、マルチスケールテストを含む。*

| システム | ネットワーク | データ | mAP | areo | bike | bird | boat | bottle | bus | car | cat | chair | cow | table | dog | horse | mbike | person | plant | sheep | sofa | train | tv |
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
| baseline | VGG-16 | 07++12 | 70.4 | 84.9 | 79.8 | 74.3 | 53.9 | 49.8 | 77.5 | 75.9 | 88.5 | 45.6 | 77.1 | 55.3 | 86.9 | 81.7 | 80.9 | 79.6 | 40.1 | 72.6 | 60.9 | 81.2 | 61.5 |
| baseline | ResNet-101 | 07++12 | 73.8 | 86.5 | 81.6 | 77.2 | 58.0 | 51.0 | 78.6 | 76.6 | 93.2 | 48.6 | 80.4 | 59.0 | 92.1 | 85.3 | 84.8 | 80.7 | 48.1 | 77.3 | 66.5 | 84.7 | 65.6 |
| baseline+++ | ResNet-101 | COCO+07++12 | **83.8** | **92.1** | **88.4** | **84.8** | **75.9** | **71.4** | **86.3** | **87.8** | **94.2** | **66.8** | **89.4** | **69.2** | **93.9** | **91.9** | **90.9** | **89.6** | **67.9** | **88.2** | **76.8** | **90.3** | **80.0** |

*表3: PASCAL VOC 2012テストセットでの検出結果（[http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=4](http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=4)）。ベースラインはFaster R-CNNシステム。「baseline+++」システムは、表1のボックスリファインメント、コンテキスト、マルチスケールテストを含む。*

**MS COCO**

*ボックスリファインメント。* 我々のボックスリファインメントは、一部[Gidaris2015]の反復的な位置特定に従っています。Faster R-CNNでは、最終出力は提案ボックスとは異なる回帰されたボックスです。そのため、推論では、回帰されたボックスから新しい特徴量をプールし、新しい分類スコアと新しい回帰されたボックスを取得します。これらの300個の新しい予測を元の300個の予測と結合します。予測されたボックスの結合集合に対して、[Girshick2014]に従いIoUしきい値0.3を用いた非最大抑制（NMS）を適用し、その後[Gidaris2015]に従いボックス投票を行います。ボックスリファインメントはmAPを約2ポイント改善します（表1）。

*グローバルコンテキスト。* Fast R-CNNステップでグローバルコンテキストを結合します。全画像畳み込み特徴マップが与えられた場合、グローバル空間ピラミッドプーリング[He2014]（「シングルレベル」ピラミッドを使用）によって特徴量をプールします。これは、画像全体のバウンディングボックスをRoIとして使用する「RoI」プーリングとして実装できます。このプールされた特徴量は、RoI後層に供給されてグローバルコンテキスト特徴量を取得します。このグローバル特徴量は、元の領域ごとの特徴量と連結され、その後、兄弟関係の分類層とボックス回帰層に続きます。この新しい構造はエンドツーエンドで訓練されます。グローバルコンテキストはmAP@.5を約1ポイント改善します（表1）。

*マルチスケールテスト。* 上記の全ての結果は、[Ren2015]と同様にシングルスケール訓練/テストによって得られており、画像の短辺は$s=600$ピクセルです。マルチスケール訓練/テストは、[He2014, Girshick2015]では特徴ピラミッドからスケールを選択する方法で、[Ren2015a]ではMaxout層を使用する方法で開発されてきました。現在の実装では、[Ren2015a]に従ってマルチスケール*テスト*を行っています。時間の制約上、マルチスケール訓練は行っていません。さらに、マルチスケールテストはFast R-CNNステップのみで行っており（RPNステップではまだ行っていません）。訓練済みモデルを用いて、画像の短辺が$s\in\{200, 400, 600, 800, 1000\}$である画像ピラミッド上で畳み込み特徴マップを計算します。[Ren2015a]に従って、ピラミッドから2つの隣接するスケールを選択します。RoIプーリングとそれに続く層は、これら2つのスケールの特徴マップに対して実行され[Ren2015a]、[Ren2015a]と同様にMaxoutによって統合されます。マルチスケールテストはmAPを2ポイント以上改善します（表1）。

*検証データの使用。* 次に、訓練に8万+4万の訓練検証セットを使用し、評価に2万のテスト開発セットを使用します。テスト開発セットには公開されている正解データがなく、結果は評価サーバーによって報告されます。この設定では、mAP@.5は55.7%、mAP@[.5, .95]は34.9%となります（表1）。これが我々の単一モデルの結果です。

*アンサンブル。* Faster R-CNNでは、システムは領域提案と物体分類器の両方を学習するように設計されているため、アンサンブルを用いて両方のタスクを向上させることができます。我々は領域提案のためにアンサンブルを使用し、提案の結合集合は領域ごとの分類器のアンサンブルによって処理されます。表1は、3つのネットワークのアンサンブルに基づく我々の結果を示しています。テスト開発セットでのmAPは59.0%および37.4%です。*この結果は、COCO 2015の検出タスクで1位を獲得しました。*

**PASCAL VOC**

上記のモデルに基づいてPASCAL VOCデータセットを再検討します。COCOデータセット上の単一モデル（表1の55.7% mAP@.5）を用いて、このモデルをPASCAL VOCセットでファインチューニングします。ボックスリファインメント、コンテキスト、マルチスケールテストの改善も採用します。これにより、PASCAL VOC 2007で85.6% mAP（表2）、PASCAL VOC 2012で83.8% mAPを達成します（表3）<sup><small>[http://host.robots.ox.ac.uk:8080/anonymous/3OJ4OJ.html](http://host.robots.ox.ac.uk:8080/anonymous/3OJ4OJ.html)、2015-11-26提出。</small></sup>。PASCAL VOC 2012の結果は、以前の最先端の結果[Gidaris2015]よりも10ポイント高くなっています。

**ImageNet検出**

| | val2 | test |
|---|---|---|
| GoogLeNet [Szegedy2015] (ILSVRC'14) | - | 43.9 |
| our single model (ILSVRC'15) | 60.5 | 58.8 |
| our ensemble (ILSVRC'15) | **63.6** | **62.1** |

*表4: ImageNet検出データセットでの我々の結果（mAP, %）。我々の検出システムは、ResNet-101を使用し、表1の改善を含むFaster R-CNN [Ren2015]である。*

ImageNet検出（DET）タスクは200の物体カテゴリを含みます。精度はmAP@.5で評価されます。ImageNet DET用の我々の物体検出アルゴリズムは、表1のMS COCO用と同じです。ネットワークは1000クラスのImageNet分類セットで事前訓練され、DETデータでファインチューニングされます。我々は検証セットを[Girshick2014]に従って2つの部分（val1/val2）に分割します。DET訓練セットとval1セットを使用して検出モデルをファインチューニングします。val2セットは検証に使用されます。他のILSVRC 2015データは使用しません。ResNet-101を用いた我々の単一モデルは58.8% mAPを、3つのモデルのアンサンブルはDETテストセットで62.1% mAPを達成しました（表4）。*この結果は、ILSVRC 2015のImageNet検出タスクで1位を獲得し*、2位を**8.5ポイント**（絶対値）上回っています。
## ImageNet物体位置特定
\label{sec:appendix_localization}

| LOC 手法 | LOC ネットワーク | テスト方法 | GT クラスでのLOC誤差 | 分類ネットワーク | 予測されたCLSでのトップ5LOC誤差 |
|---|---|---|---|---|---|
| VGG's \cite{Simonyan2015} | VGG-16 | 1-crop | 33.1 \cite{Simonyan2015} | | |
| RPN | ResNet-101 | 1-crop | 13.3 | | |
| RPN | ResNet-101 | dense | 11.7 | | |
| RPN | ResNet-101 | dense | | ResNet-101 | 14.4 |
| RPN+RCNN | ResNet-101 | dense | | ResNet-101 | **10.6** |
| RPN+RCNN | ensemble | dense | | ensemble | **8.9** |
*表: ImageNet検証データセットにおける物体位置特定誤差（%）。「GT クラスでのLOC誤差」(\cite{Simonyan2015})の列では、正解クラスが使用されています。「テスト方法」の列において、「1-crop」は224$\times$224ピクセルの中心クロップによるテストを、「dense」は密な（全結合畳み込み）およびマルチスケールテストを示します。*

ImageNet物体位置特定（LOC）タスク\cite{Russakovsky2014}は、物体を分類し、その位置を特定することを要求します。\cite{Sermanet2014,Simonyan2015}に倣い、画像レベルの分類器がまず画像のクラスラベルを予測するために採用され、位置特定アルゴリズムは予測されたクラスに基づいてバウンディングボックスを予測することのみを考慮すると仮定します。各クラスのバウンディングボックス回帰器を学習する「クラスごとの回帰」（PCR）戦略\cite{Sermanet2014,Simonyan2015}を採用しています。ImageNet分類のためにネットワークを事前学習し、その後、位置特定のためにファインチューニングを行いました。提供された1000クラスのImageNetトレーニングセットでネットワークをトレーニングしています。

我々の位置特定アルゴリズムは、いくつかの変更を加えた\cite{Ren2015}のRPNフレームワークに基づいています。\cite{Ren2015}で用いられているカテゴリ非依存の方法とは異なり、位置特定のための我々のRPNは、*クラスごと*の形式で設計されています。このRPNは、\cite{Ren2015}と同様に、二値分類（*cls*）およびボックス回帰（*reg*）のための2つの兄弟1$\times$1畳み込み層で構成されています。*cls*層と*reg*層は両方とも、\cite{Ren2015}とは対照的に、*クラスごと*の形式になっています。具体的には、*cls*層は1000次元の出力を持ち、各次元はオブジェクトクラスであるかどうかを予測するための*二値ロジスティック回帰*です。*reg*層は1000クラスのボックス回帰器からなる1000$\times$4次元の出力を持ちます。\cite{Ren2015}と同様に、我々のバウンディングボックス回帰は、各位置における複数の変換不変の「アンカー」ボックスを参照して行われます。

ImageNet分類のトレーニング（セクション\ref{sec:impl}）と同様に、データ拡張のために224$\times$224のクロップをランダムにサンプリングします。ファインチューニングには256画像のミニバッチサイズを使用します。負のサンプルが支配的になるのを避けるため、各画像から8つのアンカーをランダムにサンプリングし、サンプリングされた正と負のアンカーの比率は1:1に設定されています\cite{Ren2015}。テスト時には、ネットワークは画像に対して全結合畳み込み的に適用されます。

| method | top-5 localization err |
|---|---|
| | val | test |
|---|---|---|
| OverFeat \cite{Sermanet2014} (ILSVRC'13) | 30.0 | 29.9 |
| GoogLeNet \cite{Szegedy2015} (ILSVRC'14) | - | 26.7 |
| VGG \cite{Simonyan2015} (ILSVRC'14) | 26.9 | 25.3 |
|---|---|---|
| ours (ILSVRC'15) | **8.9** | **9.0** |
*表: 最先端手法とのImageNetデータセットにおける物体位置特定誤差（%）の比較。*

表\ref{tab:localization}は、位置特定の結果を比較しています。\cite{Simonyan2015}に倣い、まず分類予測として正解クラスを使用する「オラクル」テストを実行します。VGGの論文\cite{Simonyan2015}では、正解クラスを使用して中心クロップ誤差が33.1%と報告されています（表\ref{tab:localization}）。同じ設定で、ResNet-101ネットワークを使用した我々のRPN手法は、中心クロップ誤差を13.3%に大幅に削減しました。この比較は、我々のフレームワークの優れた性能を示しています。

密な（全結合畳み込み）およびマルチスケールテストでは、我々のResNet-101は正解クラスを使用して11.7%の誤差を達成しました。ResNet-101をクラス予測に使用した場合（トップ5分類誤差4.6%、表\ref{tab:single}）、トップ5位置特定誤差は14.4%でした。

上記の結果は、Faster R-CNN\cite{Ren2015}の*プロポーザルネットワーク*（RPN）のみに基づいています。Faster R-CNNの*検出ネットワーク*（Fast R-CNN\cite{Girshick2015}）を使用して結果を改善することも可能ですが、このデータセットでは、通常、1つの画像に1つの支配的なオブジェクトが含まれており、提案領域が互いに大きく重なり、したがって非常に類似したRoIプーリング特徴を持つことに気づきました。その結果、Fast R-CNN\cite{Girshick2015}の画像中心のトレーニングは、確率的トレーニングには望ましくない可能性のある小さなバリエーションのサンプルを生成します。これに動機付けられ、現在の実験では、Fast R-CNNの代わりにRoI中心のオリジナルのR-CNN\cite{Girshick2014}を使用しています。

我々のR-CNNの実装は以下の通りです。上記のようにトレーニングされたクラスごとのRPNをトレーニング画像に適用し、正解クラスのバウンディングボックスを予測します。これらの予測されたボックスは、クラス依存のプロポーザルの役割を果たします。各トレーニング画像について、最もスコアの高い200のプロポーザルをトレーニングサンプルとして抽出し、R-CNN分類器をトレーニングします。画像領域はプロポーザルから切り取られ、224$\times$224ピクセルにワープされ、R-CNN\cite{Girshick2014}と同様に分類ネットワークに入力されます。このネットワークの出力は、*cls*と*reg*のための2つの兄弟fc層で構成され、これもまたクラスごとの形式です。

このR-CNNネットワークは、RoI中心の方法でミニバッチサイズ256を使用してトレーニングセットでファインチューニングされます。テスト時には、RPNが予測された各クラスに対して最もスコアの高い200のプロポーザルを生成し、R-CNNネットワークがこれらのプロポーザルのスコアとボックス位置を更新するために使用されます。

この方法は、トップ5位置特定誤差を10.6%に削減します（表\ref{tab:localization}）。これは検証セットにおける我々の単一モデルの結果です。分類と位置特定の両方のためにネットワークのアンサンブルを使用することで、テストセットにおいてトップ5位置特定誤差9.0%を達成しました。この数値はILSVRC 2014の結果（表\ref{tab:localization_all}）を大幅に上回り、誤差を相対的に64%削減しています。*この結果は、ILSVRC 2015のImageNet位置特定タスクで1位を獲得しました。*
