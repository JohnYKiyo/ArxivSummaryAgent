# DeepSeek vs. ChatGPT vs. Claude: A Comparative Study for Scientific Computing and Scientific Machine Learning Tasks

URL: http://arxiv.org/abs/2502.17764v2

発表年: 2025

著者:
Qile Jiang, Zhiwei Gao, George Em Karniadakis

著者の所属機関:
ブラウン大学 Crunch Group

## 要約

本論文は、DeepSeek（DeepSeek V3, DeepSeek R1）、OpenAI（ChatGPT 4o, ChatGPT o3-mini-high）、Anthropic（Claude 3.7 Sonnet, Claude 3.7 Sonnet with extended thinking）からリリースされた大規模言語モデル（LLM）の性能を、科学計算および科学機械学習における多様なタスクにおいて評価・比較しています。研究の目的は、数値積分、有限差分法（FDM）、有限要素法（FEM）などの高度な数学的推論を必要とする従来の数値解析タスク、および画像認識、物理情報ニューラルネットワーク（PINNs）、Deep Operator Networks（DeepONet）などの科学機械学習タスクにおいて、各モデルが適切な手法やアーキテクチャを選択し、正確に実装できるかを評価することでした。

結果として、DeepSeek R1、ChatGPT o3-mini-high、および拡張思考付きClaude 3.7 Sonnetといった推論に最適化されたモデルは、問題の性質を認識し、適切な意思決定を行う点で一貫して優れた性能を示しました。これらのモデルの選択は、人間科学者のアプローチと類似していました。対照的に、汎用モデルであるDeepSeek V3とChatGPT 4oは、問題の特定の特性やユーザーからの指示を考慮できない場合があり、不正確なソリューションを生成することがありました。

本研究は、科学研究におけるLLMの利用の現実性の高まりと、LLM開発者間の競争激化を浮き彫りにしました。同時に、これらの最先端LLMにも依然として限界があることを露呈しており、これは対象分野に不慣れな人間研究者を混乱させる可能性のある曖昧または不正確な応答、あるいはコードのバグによって示されています。結論として、科学的問題解決のためのLLMには継続的な改善が必要であり、今後の研究では、より複雑な実世界の計算上の課題に対してLLMを評価し、研究者がLLMアシスタントを効果的かつ責任を持って使用するための情報を提供すべきであると提言しています。

## レビュー/サーベイ項目

本論文で比較評価された科学計算および科学機械学習タスクは以下の通りです。

1.  **従来の数値計算法**
    *   スティッフ常微分方程式（Robertson ODE）の数値解法能力
    *   L字型領域におけるPoisson方程式に対する有限差分法の実装能力
    *   振動梁方程式に対する有限要素法の実装能力（非同次境界条件）
    *   特異点を持つ積分に対する求積法の実装能力
2.  **科学的機械学習**
    *   MNIST数字の予測のためのCNN実装能力
    *   L字型領域におけるPoisson方程式の物理情報ニューラルネットワーク（PINNs）による解法能力
    *   逆微分演算子学習のためのDeep Operator Network (DeepONet) 実装能力
    *   Caputo分数階微分オペレーター学習のためのDeep Operator Network (DeepONet) 実装能力

## 比較

以下に、各レビュー/サーベイ項目におけるLLMの比較をまとめます。

| 項目 | DeepSeek V3 | DeepSeek R1 | ChatGPT 4o | ChatGPT o3-mini-high | Claude 3.7 Sonnet | Claude 3.7 Sonnet extended thinking |
|:---|:---|:---|:---|:---|:---|:---|
| **スティッフ常微分方程式** | RK4 (失敗) | 後退オイラー法 (**優良**) | RK4 (失敗) | 適応的後退オイラー法 (良好) | 適応的RK4 (良好) | 後退オイラー法 (**最良**) |
| | (N/A) | 推論時間: 249.0s | (N/A) | 推論時間: 88.0s | (N/A) | 推論時間: 115.0s |
| **Poisson方程式 (FDM)** | 反復法 (201%誤差, 時間長) | FDM (203%誤差, 符号・スケール誤り) | FDM (203%誤差, 符号誤り) | FDM (207%誤差, 符号誤り, 推論速) | FDM (**4.54%誤差, 正しい**) | FDM (202%誤差, 符号誤り) |
| | (N/A) | 推論時間: 476.0s | (N/A) | 推論時間: 32.0s | (N/A) | 推論時間: 125.0s |
| **振動梁方程式 (FEM)** | Hermite (276300%誤差) | Hermite (15.3%誤差) | Hermite (205%誤差) | Hermite (19.4%誤差, 推論速) | Hermite (957%誤差) | Hermite (**13.7%誤差, 最良**) |
| | (N/A) | 推論時間: 790.0s | (N/A) | 推論時間: 31.0s | (N/A) | 推論時間: 9.0s |
| **積分 (求積法)** | Scipy直接 (N/A) | Gauss-Legendre (**高精度**) | Gauss-Legendre (**高精度**) | Gauss-Legendre (**高精度, 推論速**) | Gauss-Legendre (**計算機精度**) | Gauss-Legendre (**計算機精度**) |
| | (N/A) | 推論時間: 584.0s | (N/A) | 推論時間: 74.0s | (N/A) | 推論時間: 37.0s |
| **MNIST予測 (CNN)** | 高精度 (98.96%) | 高精度 (99.11%, 早期停止) | **最高精度 (99.31%)** | 高精度 (98.84%, 最速推論) | 高精度 (98.98%, 早期停止) | 高精度 (99.14%, 早期停止) |
| | (N/A) | 推論時間: 129.0s | (N/A) | 推論時間: 8.0s | (N/A) | 推論時間: 38.0s |
| **Poisson方程式 (PINNs)** | 929%誤差 | 54.7%誤差 | 169%誤差 | 5.31%誤差 (**良好, 最速推論**) | **4.25%誤差 (最良)** | 322%誤差 |
| | (N/A) | 推論時間: 417.0s | (N/A) | 推論時間: 15.0s | (N/A) | 推論時間: 38.0s |
| **逆微分DeepONet** | 失敗 (49.4%~51.6%誤差, バグ有) | **最良 (0.0008%~5.7%誤差)** | 良好 (0.05%~6.1%誤差, バグ有) | 良好 (0.06%~6.2%誤差, 最速推論) | 比較的低精度 (0.35%~180.41%誤差, バグ有) | 比較的低精度 (0.22%~7.04%誤差, バグ有) |
| | (N/A) | 推論時間: 214.0s | (N/A) | 推論時間: 11.0s | (N/A) | 推論時間: 79.0s |
| **Caputo分数階DeepONet** | 177.19%誤差 (固定α, バグ有) | 26.82%誤差 (バグ有) | 19.49%誤差 (バグ有) | 18.41%誤差 (バグ有, 最速推論) | **5.59%誤差 (最良, バグ有, 非効率)** | 16.24%誤差 (固定α, バグ有) |
| | (N/A) | 推論時間: 426.0s | (N/A) | 推論時間: 23.0s | (N/A) | 推論時間: 109.0s |

**全体的な比較のまとめ:**
*   **推論能力**: DeepSeek R1、ChatGPT o3-mini-high、Claude 3.7 Sonnet extended thinkingといった推論に最適化されたモデルは、問題の性質（例: ODEのスティッフ性）を認識し、適切な数値手法やデータ生成戦略を選択する点で、汎用モデルよりも一貫して優れていました。
*   **コード生成の正確性**: ほとんどのモデルは実行可能なコードを生成しましたが、複雑な問題や特定のライブラリ（JAXの`grad`、Keras Functional APIの誤用）に関する詳細な知識が必要な場合、バグや非効率な実装が見られました。特にCaputo分数階微分オペレーターの学習では、DeepONetの入力定式化や積分範囲の誤りが複数のモデルで見られました。
*   **ハイパーパラメータ選択と汎化**: DeepONetのタスクでは、Claudeモデルが高度な訓練技術（Swish活性化、正則化、学習率スケジューリング、ドロップアウト）を提案しましたが、必ずしも最高の性能に繋がらず、最適な性能には人間の介入とハイパーパラメータチューニングの必要性を示唆しました。また、固定された$\alpha$値で訓練されたモデル（DeepSeek V3、Claude 3.7 Sonnet extended thinking）は、未知の$\alpha$値への汎化能力が低いことが示されました。
*   **推論時間**: 推論モデルの中で、ChatGPT o3-mini-highは一般的に最も速い推論時間を示し、その性能と効率のバランスが優れていました。

## 議論

本研究の結果は、DeepSeek、ChatGPT、ClaudeのLLMファミリーが科学計算および科学機械学習タスクにおいて顕著な進歩を遂げていることを明確に示しています。特に、DeepSeek R1、ChatGPT o3-mini-high、Claude 3.7 Sonnet extended thinkingといった推論に最適化されたモデルは、問題の深い理解に基づいた意思決定能力において、汎用モデルを大きく上回ります。これは、人間科学者が問題を分析し、適切な解決策を選択するアプローチと類似しており、LLMが単なる情報検索ツールから、より高度な推論に基づいたタスクを実行できるエージェントへと進化していることを示唆しています。

しかしながら、本研究はこれらの最先端LLMの現在の限界も浮き彫りにしました。
1.  **堅牢性の欠如**: いくつかのモデルは、特定のドメイン固有の知識やライブラリの癖（例: JAXの`grad`関数の誤用、DeepONetの入力テンソル定式化の誤り）に関して依然としてバグを生成しました。これらのバグは、対象分野に不慣れな研究者を混乱させ、信頼性の問題を引き起こす可能性があります。
2.  **最適なハイパーパラメータ選択の課題**: DeepONetの実験では、LLMが高度な訓練戦略を提案したにもかかわらず、必ずしも最適な性能を達成せず、人間の専門家による介入とハイパーパラメータチューニングが依然として不可欠であることが示されました。これは、LLMがコードを生成できても、そのコードが最適な効率や精度で実行されることを保証するわけではないという点で、重要な考慮事項です。
3.  **指示の解釈と汎化**: 意図的に曖昧にされたプロンプトや特定の条件（例: 任意の分数階次数）において、一部のモデルは意図を完全に解釈できず、結果として汎化能力が低いソリューションを生成しました（例: 固定された$\alpha$でのDeepONet訓練）。

これらの発見は、科学研究におけるLLMの採用が現実味を帯びている一方で、その信頼性と正確性を確保するためには継続的な改善が必要であることを強調しています。特に、高リスクな科学的および工学的な問題解決においては、精度、論理的一貫性、厳密な推論が不可欠であり、LLMの幻覚的な推論や自己矛盾といった基本的な限界を克服する必要があります。

今後の研究課題としては、以下の点が挙げられます。
*   **より複雑な実世界課題での評価**: 現在のベンチマークは個別のタスクに焦点を当てていますが、将来的には、プロジェクトの異なる段階で一連の意思決定が必要とされる、より複雑で多段階な計算上の課題に対してLLMを評価する必要があります。
*   **プロンプトエンジニアリングの最適化**: LLMの性能を最大化するための効果的なプロンプトの設計と、ユーザーがドメイン固有の知識をLLMに効果的に伝達する方法に関する研究が必要です。
*   **可視化と解釈可能性**: LLMがなぜ特定のアプローチを選択したのか、その推論プロセスをより透過的にすることで、研究者がLLMアシスタントをいつ、どのように効果的かつ責任を持って日常業務で使用するかについて、より情報に基づいた意思決定ができるようになります。

LLM開発者間の競争が激化する中、科学コミュニティは、これらの強力なツールが研究と学習において最大限の可能性を発揮できるよう、その能力と限界を継続的に評価し、理解していく必要があります。