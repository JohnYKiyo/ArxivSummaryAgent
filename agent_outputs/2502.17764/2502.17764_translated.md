# DeepSeek vs. ChatGPT vs. Claude: A Comparative Study for Scientific Computing and Scientific Machine Learning Tasks

URL: http://arxiv.org/abs/2502.17764v2

発表年: 2025

著者:
Qile Jiang, Zhiwei Gao, George Em Karniadakis

---

# はじめに

ChatGPT \cite{openai_gpt_4o_2024, openai_o3_mini_2025, openai_o3_mini_system_card_2024}、Claude \cite{anthropicclaude3.7sonnet}、そして最も最近ではDeepSeek \cite{deepseekai2024deepseekv3technicalreport} のような大規模言語モデル（LLM）は、トランスフォーマーアーキテクチャ \cite{waswani2017attention} に基づく汎用人工知能（AI）チャットボットであり、インターネット上の膨大なデータで学習され、ユーザーの要求に基づいて会話を行うことを学習しています。多くの応用の中でも、LLMを科学研究、特にコーディング、数学、問題解決に活用することへの関心が高まっています。この関心は、LLM開発における近年の急速な進歩を推進してきました。例えば、2025年1月31日、OpenAIはChatGPT o3-mini \cite{openai_o3_mini_2025} をリリースしました。これは科学、数学、コーディングにおいて特に強みを発揮するとされる最新の推論モデルです。これは、DeepSeekが数学、コーディング、推論タスクに特化した独自の推論モデルDeepSeek-R1 \cite{deepseekai2025deepseekr1incentivizingreasoningcapability} を発表したわずか数日後のことでした。最も最近では、2025年2月24日、AnthropicもClaude 3.7 Sonnet with extended thinking modeを発表し、数学、物理学、指示に従う能力、コーディングにおける性能を向上させています \cite{anthropicclaude3.7sonnet}。
これらのモデルは、ChatGPT-4o \cite{openai_gpt_4o_2024}、DeepSeek V3 \cite{deepseekai2024deepseekv3technicalreport}、Claude 3.5 Sonnet \cite{anthropicclaude3.5sonnet} といった以前の進歩の上に構築されており、科学分野における性能最適化を目指すLLM開発者間の新たな競争段階を示しています。

LLMはすでに、科学研究の様々な分野で潜在能力を示しています。情報合成 \cite{antu2023using, li2024chatcite} やコーディングアシスタント \cite{nam2024using, liu2024exploring, chew2023llm} としてだけでなく、材料科学 \cite{zhang2024honeycomb, hong2023chatgpt, cheng2023challenges}、遺伝学 \cite{chatterjee2023can, mcgrath2024comparative}、医用画像処理 \cite{srivastav2023chatgpt, hu2024advancing, yang2023impact}、計算流体力学 \cite{chen2024metaopenfoam, sawada2011llm, herzog2002llm} を含む複雑なドメイン固有の問題を解決するためにも利用されています。科学的ワークフローへのLLMの統合は、その役割を単なる情報検索ツールから、推論に基づいたタスクを実行して人間の研究者を支援・補完できる自動化されたエージェントへと拡大させました。しかし、これらの有望な応用にもかかわらず、LLMは依然として基本的な限界を示すことがあり、科学研究や計算におけるその信頼性について懸念を引き起こしています \cite{hadi2023survey, rossi2024problems, rane2023contribution, pal2024ai, kunz2024properties}。特に、複雑な科学的問題を解決するように求められた場合、幻覚的な推論 \cite{li2023deceptive}、低い数学的認知能力 \cite{evans2024evaluating}、さらには自己矛盾 \cite{mundler2023self} を生じさせることがあります。流暢さや一貫性が主要な評価基準となる対話型AIタスクとは異なり、科学的および工学的な問題は、精度、論理的一貫性、厳密な推論を要求します。したがって、LLMの限界は、高リスクなアプリケーションには不向きであるという結論に至っています。

これらの課題を踏まえ、研究者たちはLLMの科学的および計算タスクにおける能力を評価するための実験を設計してきました。例えば、数学的推論 \cite{liu2024mathbench, chernyshev2024u}、科学レビュー \cite{wu2023gpt, cai2024sciassess}、工学文書作成 \cite{doris2025designqa} におけるLLMのスキルをベンチマークしています。一般的な言語モデルのベンチマークのみに頼るのではなく、ドメイン固有のモデルテストと評価は、LLMの正しさだけでなく、推論の深さ、信頼性、研究レベルの科学的問題への一般化能力を評価するために不可欠です。

LLM開発者間の競争が激化する中、本研究では、計算数学および科学的機械学習におけるモデルの比較テストを実施します。DeepSeek、ChatGPT、ClaudeのLLMファミリーから、推論モデルと非推論モデルの両方に対して、意図的にトリッキーな問題を定式化し、提示します。まず、数値積分、有限差分法（FDM）、有限要素法（FEM）を含む数値解析におけるLLMの能力をテストします。機械学習手法は、従来の数値手法の代替として人気を集めているため \cite{thiyagalingam2022scientific, karniadakis2021physics}、画像認識、物理情報ニューラルネットワーク（PINN）を用いた物理情報学習 \cite{raissi2019physics}、Deep Operator Network (DeepONet) \cite{deeponet} のような演算子学習手法を含む科学的機械学習タスクにおけるLLMの性能も評価します。様々なベンチマーク問題におけるモデルの性能と推論の意思決定を比較することで、本研究はこれらの人気のあるLLMが計算数学においてどの程度の性能を発揮するか、また、研究や学習においてそれらを採用する際のリスクと利点について洞察を提供します。

# 実験

本セクションでは、DeepSeek、OpenAI、Anthropicによって開発された6つの異なるLLMを、数値アルゴリズムと科学的機械学習における様々な困難なベンチマーク問題でテストし、評価します。検討対象となるモデルは以下の通りです。

1.  DeepSeek V3 \cite{deepseekai2024deepseekv3technicalreport}: DeepSeekによって開発された汎用モデルで、複数のドメインをカバーする広範なデータセットで学習されています。科学タスクに特化してはいないものの、その学習には数学的および工学関連のデータへの広範な露出が含まれています。
2.  DeepSeek R1 \cite{deepseekai2025deepseekr1incentivizingreasoningcapability}: DeepSeekによって、数学やコーディングを含む推論タスクのために特別に設計されたモデルです。DeepSeek V3と比較して、R1は論理的一貫性と構造化された問題解決を改善するために、追加の強化学習戦略を用いてファインチューニングされています。OpenAIの推論モデルへの直接的な競合と位置づけられています。
3.  ChatGPT 4o \cite{openai_gpt_4o_2024}: OpenAIの現在の主力モデルで、テキスト、コード、画像処理を含む汎用推論とマルチモーダルな能力のために設計されています。最適化されたトランスフォーマーアーキテクチャを採用し、コーディング、数学、論理推論における性能を維持しつつ、効率性の向上とレイテンシーの削減に焦点を当てています。
4.  ChatGPT o3-mini-high \cite{openai_o3_mini_2025}: ChatGPT o3-mini-highは、OpenAIのo3-miniモデルのバリアントであり、コーディング、数学、科学における集中的な推論を必要とするタスクのために最適化されています。「High」は高知能を意味します。そのサイズが小さいにもかかわらず、o3-mini-highは高度な推論技術を採用することで、より大規模なモデルに匹敵する性能を提供するとされています。
5.  Claude 3.7 Sonnet \cite{anthropicclaude3.7sonnet}: Anthropicの高性能モデルで、汎用性の高いテキスト処理、コード生成、分析タスクのために設計されています。文脈理解能力を強化した最適化されたトランスフォーマーアーキテクチャを採用しており、創造的な執筆、プログラミング、知識集約型アプリケーションを含む様々なドメインで信頼性の高い性能を提供するとされています。市場初の「ハイブリッド推論モデル」と謳っています。
6.  Claude 3.7 Sonnet extended thinking \cite{anthropicclaude3.7sonnet}: AnthropicのSonnetモデルの強化版で、より深い分析的思考を可能にする追加の推論層を備えています。この拡張バージョンは、複雑な問題のより徹底的な評価を可能にする特殊な処理モードを組み込んでおり、多段階推論、数学的問題解決、論理的演繹を必要とするタスクの性能を向上させながら、ベースモデルの汎用性を維持します。

公平性を確保するため、すべてのチャットメモリとユーザーのパーソナライズ設定は無効化されています。これにより、モデルが以前のコンテキストから利益を得ることを防ぎ、各クエリが独立して扱われることを保証します。さらに、LLMの応答時間は実際の評価速度ではなくサーバーの遅延に影響される可能性があるため、非推論モデル（ハイブリッド推論のClaude 3.7 Sonnetを含む）の応答時間は比較も報告も行いません。代わりに、本論文では推論LLMの自己報告による推論時間のみを提示します。評価の焦点は、生成されたソリューションの品質、そして推論モデルについてはその推論プロセスと意思決定にあります。モデルの性能を差別化するため、選択されたテスト問題はトリッキーですが、LLMがそのソリューションで使用する方法とパラメータについて独自の決定を下す十分な柔軟性も残されています。ほとんどの問題は高度で、通常は博士号レベルであり、計算数学の深い理解と最新の研究進展への精通が求められます。テストされるコーディング言語は、科学的機械学習コミュニティで頻繁に使用されるフレームワークであるPythonのTensorFlow \cite{tensorflow2015-whitepaper} とJax \cite{jax2018github} が選択されています。

本セクションは2つの部分に分かれています。最初の部分では、応用数学における従来の数値解析、特に有限差分法や有限要素法などの常微分方程式および偏微分方程式（PDE）の解法におけるモデルの知識をテストするための実験を行います。2番目の部分では、MNISTデータセットからの数字の学習や、異なる問題に対するPINNとDeepONetの実装を含む科学的機械学習タスクでモデルをテストします。
## 従来の数値計算法

本節では、従来の数値計算法における様々な問題や微分方程式の解法に取り組む、検討対象の6つのLLMを紹介します。それらが生成した解の性能を比較し、LLMが下した決定について議論します。

### スティッフ常微分方程式の数値解

ロバートソン問題（\autoref{Robertson ODE}）は、H. H. ロバートソンによる化学反応を記述する、スティッフな常微分方程式系のよく知られた例です \cite{robertson1966solution}:

$$
\frac{dx}{dt} = -0.04x + 10^4 yz, \\
\frac{dy}{dt} = 0.04x - 10^4 yz - 3 \times 10^7 y^2, \\
\frac{dz}{dt} = 3 \times 10^7 y^2.
$$

この問題は、初期条件 $x=1, y=z=0$ のもとで、3つの化学種 $x(t), y(t), z(t)$ の時間経過に伴う濃度をモデル化しています。これらの反応は、特に $y(t)$ において、非常に異なる時間スケールを持ちます。このようなスティッフな常微分方程式を陽的積分法で解くと、極めて小さなステップサイズを用いない限り、不安定な挙動につながります。陰的ルンゲ＝クッタ法や後退差分公式（BDF）のような陰的メソッドは、通常、これらの問題を解くのに適しています。

LLMがこの非常にスティッフなシステムを解くために適切な数値スキームを実装できるかを評価するため、以下のプロンプトを与えました:

```
次の常微分方程式系をPythonでゼロから適切な数値計算法を実装して解いてください。
$$
\frac{dx}{dt} = -0.04x + 10^4 yz, \quad
\frac{dy}{dt} = 0.04x - 10^4 yz - 3 \times 10^7 y^2,\quad
\frac{dz}{dt} = 3 \times 10^7 y^2. \quad
$$
時間区間 $t \in [0, 500]$、初期条件 $x=1, y=z=0$ で。
```

LLMの応答は\autoref{tab:ODE_responses}にまとめられ、計算された解は\autoref{fig:ODE_solution}にプロットされています。参考として、この常微分方程式系は\texttt{scipy}で5次のラダウIIA族陰的ルンゲ＝クッタ法（ラダウ法）を用いて解かれています \cite{hairer1991ii}。

| モデル | 推論時間 (s) | メソッド | ステップサイズ | $L_2$ 誤差 ($x$) | $L_2$ 誤差 ($y$) | $L_2$ 誤差 ($z$) |
|---|---|---|---|---|---|---|
| DeepSeek V3 | N/A | RK4 | 0.01 | N/A | N/A | N/A |
| DeepSeek R1 | 249.0 | 後退オイラー法 | 0.1 | **$7.86 \times 10^{-6} \%$** | **$7.61 \times 10^{-5} \%$** | **$1.96 \times 10^{-4} \%$** |
| ChatGPT 4o | N/A | RK4 | 0.1 | N/A | N/A | N/A |
| ChatGPT o3-mini-high | 88.0 | 適応的後退オイラー法 | 適応的 ($10^{-6}$ 初期) | $3.93 \times 10^{-6} \%$ | $9.40 \times 10^{-4} \%$ | $0.14 \%$ |
| Claude 3.7 Sonnet | N/A | 適応的RK4 | 適応的 ($10^{-4}$ 初期) | **$1.24 \times 10^{-6} \%$** | $0.05 \%$ | $4.89 \times 10^{-4} \%$ |
| Claude 3.7 Sonnet 拡張思考 | 115.0 | 後退オイラー法 | 0.1 | $7.74\times 10^{-6} \%$ | **$7.53 \times 10^{-5} \%$** | **$1.94 \times 10^{-4} \%$** |
*表: 各LLMがロバートソン常微分方程式系を解くために選択した数値計算法とパラメータ。誤差はLLMの解と、\texttt{scipy}のラダウ法実装による参照解との相対差を表す。*

![ODE_solution.png](figures/ODE_solution.png)
*図: 各LLMが選択した数値スキームを用いて計算されたロバートソン常微分方程式の解。参考として、この常微分方程式系は\texttt{scipy}でラダウ法を用いて解かれている。視認性を高めるため、解が収束するプロットでは$y$種の濃度が$10^4$倍にスケールされている。*

すべての非推論モデルは4次ルンゲ＝クッタ（RK4）スキームを実装しました。DeepSeek V3とChatGPT 4oのバージョンは比較的大きなステップサイズを選択し、問題を解くことに失敗し、指数関数的に増加する解を生成しました。対照的に、ハイブリッド推論のClaude 3.7 Sonnetは、ステップサイズ$\Delta t$の1つの完全なステップと2つの半ステップ（それぞれサイズ$\Delta t /2$）を比較して局所打ち切り誤差を推定する適応的時間ステップRK4スキームを実装しました。推定誤差が規定された許容誤差を下回ればステップは受け入れられ、そうでない場合は拒否されて新たな（より小さな）時間ステップが計算されます。Claude 3.7 Sonnetの適応的手法は、他の2つの非推論モデルよりもはるかに優れた精度を示しましたが、$y$種の誤差は依然として見られました。一方、すべての完全推論モデルは後退オイラー法を実装しました。特に、ChatGPT o3-mini-highは同様の適応的時間ステップ法を用いました。全体として、拡張思考版のClaude 3.7 Sonnetが最良の結果を達成しました。ChatGPT o3-mini-highは最短の推論時間で満足のいく解を生成しました。

注目すべきは、DeepSeek R1、ChatGPT o3-mini-high、および拡張思考版のClaude 3.7 Sonnetという3つの推論モデルすべてが、常微分方程式系のスティッフ性を認識し、陰的メソッドを選択したのに対し、すべての非推論モデルはそれができなかった点です。推論プロセス中に、DeepSeek R1は次のように報告しました:

```
「時間区間が500まであり、方程式には1e4や3e7のようなかなり大きな係数を持つ項があることを考慮すると、これはスティッフなシステムである可能性がある。もしシステムがスティッフであれば、後退オイラー法のような陰的メソッド、またはスティッフなシステム用に設計されたソルバー（ローゼンブロック法など）を使用する方が良いだろう。」
```

ChatGPT o3-mini-highは次のように報告しました:

```
「スティッフであるため、オイラー法やRK4のような陽的メソッドはうまく機能しないだろう。陰的オイラー法のような陰的メソッド、または適応的ルンゲ＝クッタ法のような修正された陽的メソッドが必要になると思う。」
```

同様に、拡張思考版のClaude 3.7 Sonnetは次のように報告しました:

```
「これは非常に異なる係数に特徴づけられるスティッフな常微分方程式系である...スティッフな問題のために特別に設計された後退差分公式（BDF）メソッドを実装する。」
```

この実験は、推論モデルが適切な実装方法を選択する前にまず問題を分析できる点で、人間科学者のアプローチに似ており、非推論LLMに対する推論LLMの優れた性能を実証しています。
### Poisson方程式に対する有限差分法

本実験では、DeepSeek、ChatGPT、およびClaudeモデルが偏微分方程式の有限差分法を実装する能力を検証します。以下のPoisson方程式を考察します\cite{buzbee1970direct}:

$$
\left\{ \begin{array}{l}
      -\Delta u = f, \quad x \in \Omega  \\
      u|_{\partial \Omega} = 0,
\end{array}
\right.
$$

ここで$\Omega = [-1,1]^{2}/[0,1]^{2}$をL字型領域とします。右辺関数は$f(x, y) = 1$と設定します。特に、LLMが非標準的な領域上の問題を解けるかをテストすることに関心があります。以下の質問を全てのLLMに提示しました:

`Python`をコーディング言語として、L字型領域$[-1,1]^{2}/[0, 1]^{2}$における2D Poisson方程式を、ゼロ境界条件および右辺$f(x,y) = 1$を用いて有限差分法で解いてください。

ChatGPTを除き、他の全てのモデルはエラーのない実行可能なコードを提供しました。特筆すべきは、DeepSeekが最も高度な反復法を用いて問題を解決したのに対し、他のモデルは離散化と線形システムの解法に従来の有限差分法に依存した点です。予測された解は図にプロットされています。

*図: Poisson方程式に対して異なるモデルによって与えられた予測解。*

各LLMが使用した結果と手法は表に記載されています。全6モデルの中で、唯一正しい結果はClaude 3.7 Sonnetによって与えられました。DeepSeek V3の実装は、反復法を使用しているため、結果を得るのに非常に長いCPU時間を要しました。DeepSeek-R1は解の符号を間違えただけでなく、スケールも誤っており、性能が低下しました。正しいClaude 3.7 Sonnetを除く他の全てのモデルは、解の符号のみを間違えました。さらに、3つの推論モデルの中で、ChatGPT o3-mini-highはDeepSeek R1および拡張推論を用いたClaude 3.7 Sonnetよりもはるかに速く応答しました。

*表: Poisson方程式の解法における異なるモデルの性能の概要。*

| | 推論時間(s) | 手法 | グリッド | CPU時間 (s) | $L_2$誤差 |
|---|---|---|---|---|---|
| DeepSeek V3 | N/A | 反復法 | $50 \times 50$ | 9.5 | 201% |
| DeepSeek R1 | 476.0 | FDM | $50 \times 50$ | 0.6 | 203% |
| ChatGPT 4o | N/A | FDM | $50 \times 50$ | 0.6 | 203% |
| ChatGPT o3-mini-high | 32.0 | FDM | $41 \times 41$ | 0.5 | 207% |
| Claude 3.7 Sonnet | N/A | FDM | $50 \times 50$ | 0.6 | **4.54%** |
| Claude 3.7 Sonnet extended thinking | 125.0 | FDM | $60 \times 60$ | 0.7 | 202% |

### 振動梁方程式に対する有限要素法

本実験では、以下の梁方程式を考察します\cite{eliasson2016kam}:

$$
EI \frac{d^4 u}{dx^4} = \pi^4 x \sin \pi x - 4\pi^3 \cos \pi x, \quad 0 \leq x \leq L,
$$

対応する非同次境界条件は以下の通りです:

$$
u(0) = 0, \quad u''(0) = 2\pi,
$$
$$
u(L) = 0, \quad u''(L) = -2\pi.
$$

ここで、$EI = 1N/m^{2}$は定数の曲げ剛性です。簡略化のため、$L = 1$と設定します。図にプロットされた真の解は、常微分方程式を解くことによって得られ、次式で与えられます:

$$
u(x) = x\sin(\pi x).
$$

*図: 梁方程式の真の解。*

検討中の全てのLLMには以下の質問が提示されました:

有限要素法をゼロから使用して、梁方程式を解いてください。

$$
\left\{\begin{array}{l}
    \frac{d^4 u}{dx^4} = \pi^4 x \sin \pi x - 4\pi^3 \cos \pi x, \quad 0 \leq x \leq 1,\\
    u(0) = 0, \quad u''(0) = 2\pi,\\
    u(1) = 0, \quad u''(1) = -2\pi.
\end{array}\right.
$$

コーディング言語は`Python`です。

結果および実装の詳細は表に記載されています。各LLMによって予測された解は図にプロットされています。我々の結果は、どのLLMも有限要素法を正確に適用して非常に高精度な解を得ることができなかったことを示しています。

*表: 梁方程式の解法における異なるモデルの性能の概要。*

| | 推論時間 (s) | 基底 | グリッド | $L_2$誤差 |
|---|---|---|---|---|
| DeepSeek V3 | N/A | Hermite | 100 | 276300% |
| DeepSeek R1 | 790.0 | Hermite | 10 | 15.3% |
| ChatGPT 4o | N/A | Hermite | 50 | 205% |
| ChatGPT o3-mini-high | 31.0 | Hermite | 100 | 19.4% |
| Claude 3.7 Sonnet | N/A | Hermite | 100 | 957% |
| Claude 3.7 Sonnet extended thinking | 9.0 | Hermite | 20 | **13.7%** |

全てのLLMがHermite基底関数を用いて解を近似していることが観察されました。さらに、これらは弱形式が導出され、その後Galerkin法が適用できることを認識しています。しかし、全てが弱形式を導出するために間違ったテスト空間を選択しており、それが最終的な誤った結果につながっています。これらのモデルの中で、非推論モデルは推論モデルよりもはるかに性能が悪く、著しく大きな$L_2$誤差を示しています。対照的に、他の実験結果と一致して、推論モデルは問題をより効果的に解決し、Claude 3.7 Sonnet extended thinkingが最小の$L_2$誤差を達成しました。推論モデル間の応答時間では、ChatGPT o3-mini-highとClaude 3.7 Sonnet with extended thinkingはDeepSeek R1よりもはるかに速く応答しました。

さらに、Claudeによる実装は、異なる数の基底関数を用いた手法の収束率をさらにテストするものです。Claude Sonnetモデルは、数学的な問題に対してより技術的に人間科学者のように推論し、どの手法が優れているかを検証するために包括的な結果を与えることが判明しました。

*図: 梁方程式に対する異なるLLMからの予測解。*
### 積分に対する求積法
次に、特異点を持つ積分の数値計算において、LLMが求積法を正確に適用する能力を評価します。以下の積分を考えます。

$$
    I = \int_{0}^{1}\frac{e^{-x}}{x^{\frac{2}{3}}}dx.
$$

すべてのモデルに提示された質問は以下の通りです。

`特異点を持つ積分 $\int_{0}^{1}\frac{e^{-x}}{x^{\frac{2}{3}}}dx$ を、Pythonでスクラッチから求積法を用いて計算してください。`

すべてのLLMはエラーのない実装を提供しましたが、異なるモデルのアプローチは大きく異なりました。DeepSeek V3は`scipy.integrate`モジュールを直接使用して積分を計算しましたが、他のモデルは最初に変換を適用して特異点を除去しました。具体的には、$x = t^{3}$と設定すると、以下が得られます。

$$
    I = \int_{0}^{1} e^{-t^3} \cdot \frac{3t^2}{(t^3)^{2/3}} dt
= \int_{0}^{1} 3e^{-t^3} t^{-2+2} dt
= 3 \int_{0}^{1} e^{-t^3} dt.
$$

この変換を適用した後、ほとんどのLLMはガウス求積法を用いて積分を近似しました。特に、Claudeモデルは、台形公式、シンプソンの法則、直接ガウス求積法、および前述の変数変換を含む、より広範な積分手法を調査して収束率を評価しました。図1に示すように、変数変換はこれらのアプローチの中で最速の収束を達成し、それらの性能の徹底的な比較を提供しました。

さらに、Claude 3.7 Sonnet（拡張推論付き）の場合では、変数変換に続いていくつかの求積法（ガウス求積法、適応シンプソンの法則、ロンバーグ積分）がテストされ、異なる数値積分戦略の有効性に関する追加の洞察が提供されました。選択された方法とその関連誤差の詳細な要約は、表1に記載されています。

![Convergence rate of different methods tested for integration.](figures/comparison.pdf)
*図1: 積分計算のためにテストされた異なる手法の収束率。*

| | 推論時間 (s) | 手法 | ノード数 | $L_{2}$誤差 |
|:---|:---|:---|:---|:---|
| DeepSeek V3 | N/A | Scipy | N/A | N/A |
| DeepSeek R1 | 584.0 | Gauss-Legendre | 10 | 3.74e-12 |
| ChatGPT 4o | N/A | Gauss-Legendre | 20 | 5.15e-13 |
| ChatGPT o3-mini-high | 74.0 | Gauss-Legendre | 50 | 5.21e-14 |
| Claude 3.7 Sonnet | N/A | Gauss-Legendre | 1000 | 計算機精度 |
| Claude 3.7 Sonnet extended thinking | 37.0 | Gauss-Legendre | 1000 | 計算機精度 |

*表1: 積分計算における異なるモデルの性能の要約。*

全体として、DeepSeek V3を除いて、すべてのモデルは比較的に高い性能を達成し、ユーザーのリクエストに正確に従うことができました。これらは特異点を特定し、求積法を使用する前に変換を正しく適用することができました。Claudeモデルは異なる手法のより包括的な比較を提供し、このような科学計算タスクの分析においてより洗練されています。

## 科学的機械学習

このセクションでは、画像認識、物理情報付き機械学習、および演算子学習法における様々な科学的機械学習タスクでLLMをテストします。

### MNIST数字の予測

科学や工学の多くの問題では、画像データの分析と分類が必要です。MNISTデータセット \cite{deng2012mnist} は、画像認識モデルを評価するための確立されたベンチマークであるため、テスト問題として選択されました。この実験のすべてのLLMには、以下のプロンプトが与えられました。

`MNISTデータセットを学習するためのCNNをTensorFlowで実装してください。高い精度と計算効率の両方を目標とするために、適切なアーキテクチャとハイパーパラメータを選択してください。`

目標は、LLMがどのようにして高い精度を達成することと計算コストを節約することの間のトレードオフをバランスさせる意思決定を行うかを評価することです。生成された応答は表2に要約されています。すべてのテストはQuadro RTX 6000 GPUで実施されました。

| モデル | 推論時間 (s) | アーキテクチャ | エポック数 | 時間 (s) | テスト精度 | 早期停止 |
|:---|:---|:---|:---|:---|:---|:---|
| DeekSeek V3 | N/A | Convolution(32)<br>MaxPooling<br>Convolution(64)<br>MaxPooling<br>Convolution(64)<br>Dense(64)<br>Dense(10) | 5 | 21.30 | 98.96% | N/A |
| DeepSeek R1 | 129.0 | Convolution(32)<br>MaxPooling<br>Convolution(64)<br>MaxPooling<br>Dense(128)<br>Dropout(0.5)<br>Dense(10) | 20 | 21.23 | 99.11% | はい |
| ChatGPT 4o | N/A | Convolution(32)<br>MaxPooling<br>Convolution(64)<br>MaxPooling<br>Dropout(0.5)<br>Dense(128)<br>Dense(10) | 10 | 21.85 | **99.31%** | N/A |
| ChatGPT o3-mini-high | 8.0 | Convolution(32)<br>Convolution(64)<br>MaxPooling<br>Dense(128)<br>Dense(10) | 10 | 21.18 | 98.84% | N/A |
| Claude 3.7 Sonnet | N/A | Convolution(32)<br>MaxPooling<br>Convolution(64)<br>MaxPooling<br>Dense(64)<br>Dropout(0.5)<br>Dense(10) | 10 | 21.30 | 98.98% | はい |
| Claude 3.7 Sonnet extended thinking | 38.0 | Convolution(32)<br>MaxPooling<br>Convolution(64)<br>MaxPooling<br>Dense(64)<br>Dropout(0.5)<br>Dense(10) | 10 | 21.33 | 99.14% | はい |

*表2: MNISTデータセット学習のためにDeekSeek、ChatGPT、Claudeによって生成されたモデルの比較。「Convolution($n$)」は$n$チャネルの2D畳み込み層を意味し、「Dense($n$)」は$n$個のニューロンを持つ全結合層を意味し、「Dropout($p$)」は確率$p$のドロップアウトを意味する。*

結果は、この比較的に標準的で単純な問題に対して、すべてのモデルが同等の訓練時間と高いテスト精度を達成できることを示しています。ClaudeモデルとDeepSeek R1の両方は早期停止基準を実装しており、これは過学習を防ぐために検証損失の変化に応じてモデルの訓練を早期に停止する可能性があります。推論モデルの中で、ChatGPT o3-mini-mini-highが最速の推論時間を示しました。
### 物理情報ニューラルネットワーク

このセクションでは、ニューラルネットワークの力で偏微分方程式（PDEs）を解くために使用されるフレームワークである物理情報ニューラルネットワーク（PINNs）~\cite{raissi2019physics} を用いてPDEsを解くLLMの性能をテストします。解くべきポアソン方程式は次のように与えられます。

$$
\begin{split}
    -\Delta u(x,y) = 1, \quad (x, y)\in [-1,1]^{2}/[0,1]^{2}
\end{split}
$$

ゼロのディリクレ境界条件を伴います。すべてのモデルに与えられた質問は次の通りです。

`JAXをコーディング言語として使用し、L字型領域 $[-1,1]^{2}/[0, 1]^{2}$でゼロ境界条件と右辺 $f(x,y) = 1$ を持つ2Dポアソン方程式をPINNsで解きなさい。`

すべてのモデルがエラーのあるコードを生成しました。問題は、JAXの`grad`関数を使用して入力に対する出力の勾配を計算することにありました。`grad`はスカラー出力関数にのみ有効であるため、誤って使用するとエラーを引き起こす可能性があります。これを修正した後、すべてのコードがスムーズに動作しました。異なるモデルによって与えられたコードの性能は、表 \ref{tab:PINNs} にまとめられています。

| | 推論時間 (s) | ネットワーク | 訓練データ | エポック | 訓練時間 (s) | 活性化関数 | $L_{2}$誤差 |
|:---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| DeepSeek V3 | N/A | [2, 20, 20, 20, 1] | 1000 | 5000 | 7.90 | Tanh | 929% |
| DeepSeek R1 | 417.0 | [2, 50, 50, 50,50, 1] | 512 | 10000 | 13.80 | Tanh | 54.7% |
| ChatGPT 4o | N/A | [2, 64, 64, 64, 64, 1] | 5000 | 5000 | 15.23 | Tanh | 169% |
| ChatGPT o3-mini-high | 15.0 | [2, 64, 64, 64, 1] | 200 (毎エポック) | 5000 | 1740.00 | Tanh | 5.31% |
| Claude 3.7 Sonnet | N/A | [2, 32, 32, 32, 32,1] | 2000 | 10000 | 12.10 | Tanh | **4.25%** |
| Claude 3.7 Sonnet extended thinking | 38.0 | [2, 32, 32, 32, 1] | 5000 | 1000 | 19.00 | Tanh | 322% |

*表: ポアソン方程式を解く6つのPINNモデルのネットワークアーキテクチャ、ハイパーパラメータ、および$L_2$予測誤差。[2,20,20,20,1]というアーキテクチャは、入力次元2、出力次元1、および各々20個のニューロンを持つ3つの隠れ層を持つ全結合ニューラルネットワークを表す。*

*図: L字型領域におけるポアソン方程式の解を、異なるLLMによって生成されたPINNから予測されたもの。*

表 \ref{tab:PINNs} にまとめられた結果に基づくと、完全推論モデルであるChatGPT o3-mini-highとハイブリッド推論モデルであるClaude 3.7 Sonnetは、他のモデルと比較して正確な予測を提供し、著しく低い$L_2$誤差を達成することができました。これらの結果は、L字型領域におけるポアソン方程式を解く際に、推論モデルが解の複雑な振る舞いをより正確に捉えるだけでなく、問題領域における非自明な変更により柔軟に適応することを示しています。

通常、元の問題領域内で学習する非推論モデルとは対照的に、DeepSeek R1も適切な境界点を生成することで、L字型境界を認識し適応する能力を示しています。この適応戦略は、モデルに推論能力を組み込むことによってもたらされる汎化性能と応答性の向上を強調しています。

さらに注目すべき観察は、推論時間の違いです。表 \ref{tab:PINNs} に示されているように、DeepSeek R1が417秒というかなりの推論時間を必要とする一方で、他の2つの推論ベースモデルははるかに高速に応答します。ChatGPT o3-mini-highの推論時間はわずか15秒、Claude 3.7 Sonnet extended thinkingは38秒です。

さらに、ChatGPT o3-mini-highは、主に毎エポックで新しいサンプルを生成する必要があるため、1000秒以上の訓練時間を必要としますが、それが達成する優れた精度は、追加の計算努力を正当化します。全体として、表 \ref{tab:PINNs} の結果は、推論LLMによって生成されたPINNが問題領域の複雑さに対してより柔軟な応答を提供し、非推論モデルを大幅に上回るという説得力のある証拠を提供します。
### 逆微分演算子学習のためのDeepONet

Deep Operator Network (DeepONet) [deeponet] は、オペレーターに対する普遍近似定理 [chen_universal_thm_neural_operator] に基づき、データを用いて関数空間間のマッピングを学習するように設計されたニューラルオペレーターです。ドメイン $D \subset \mathbb{R}^n$ で定義された入力関数 $u: x \mapsto u(x)$ と、ドメイン $\Omega \subset \mathbb{R}^m$ で定義された出力関数 $v: y \mapsto v(y)$ が与えられたとき、目標とするのは次のオペレーターを近似することです。

$$
\mathcal{G}: \mathcal{U} \ni u \mapsto v \in \mathcal{V}.
$$

DeepONetのアーキテクチャは、座標 $y \in \Omega$ を入力とするトランクネットワークと、$m$個の任意のセンサー位置 $\{x_1, x_2, \dots, x_m\}$でサンプリングされた入力関数 $u$ の離散化バージョンを入力とするブランチネットワークの2つのコンポーネントで構成されています。DeepONetの出力は、$v(y) = \sum_{i = 1}^r b_i(\boldsymbol{u}) t_i(y) + b_0 \approx \mathcal{G}(u)(y) $として与えられます。ここで、$b_i$と$t_i$はそれぞれブランチネットワークとトランクネットワークの出力であり、$b_0$は学習可能なバイアス項です。

![DeepONet_diagram.png](figures/DeepONet_diagram.png)
*図1: DeepONetアーキテクチャ：ブランチネットワークは入力関数 $u$ をエンコードし、トランクネットワークは出力関数 $v$ が評価される座標 $y$ をエンコードします。*

オペレーター学習におけるLLMの知識を最初にテストするため、私たちは $[0,1]$ のドメインで一般的な逆微分オペレーター $G(u): u(x) \mapsto s(x) = \int_0^x u(\tau) d\tau$ を学習するタスクを検討します。すべての6つのLLMは、以下のプロンプトで尋ねられました。

`Implement a Deep Operator Network (DeepONet) in Tensorflow to learn the anti-derivative operator. Choose appropriate architecture and hyperparameters to aim for both high accuracy and low computational cost. Make sure that the model can generalize to a wide variety of functions.`

入力関数空間の選択は、プロンプトで意図的に曖昧にされています。したがって、LLMは関数空間から戦略的にサンプリングし、DeepONetの訓練のターゲットとして使用するために、これらの関数の逆微分を生成する必要があります。モデルのデータ生成タスクに対する応答は大きく異なります。

1.  DeepSeek V3: 入力関数は、`numpy`で一様乱数として単純に点ごとに生成されます。その後、関数は`numpy`の累積和 (`cumsum`) を使用して数値的に積分されます。
2.  DeepSeek R1: 入力関数は、以下の4つのタイプからランダムに生成されます。
    1.  次数6の多項式 $u(x) = c_0 + c_1x + \cdots c_6 x^6$ で、ランダムな係数は $[-2,2]$ の範囲で選ばれます。
    2.  三角関数 $u(x) = A \sin(\omega x) + B \cos (\omega x)$ で、$A, B$ は $[-2,2]$ からランダムに選ばれ、$\omega$ は $[1,5]$ からランダムに選ばれます。
    3.  指数関数 $u(x) = A \exp(Bx)$ で、$A, B$ は $[-1,1]$ からランダムに選ばれます。
    4.  1、2、3の混合である $u(x) = c_1 x^2 + c_2 \sin(\omega x) + c_3 \exp(x)$ で、$c_i$ は $[-1,1]$ からランダムに選ばれ、$\omega$ は $[1,5]$ から選ばれます。すべての逆微分は解析的に計算されます。
3.  ChatGPT 4o: 入力関数は、定数項を含まない次数5の多項式 $u(x) = c_1x + \cdots c_5 x^5$ として生成され、係数 $c_1$ は $[-1,1]$ からランダムに選ばれます。逆微分は解析的に計算されます。
4.  ChatGPT o3-mini-high: 入力関数は、3つのモードを持つフーリエ級数 $u(x) = \sum_{i=1}^3 A_i \sin(2\pi i x) + B_i \cos(2 \pi i x)$ として生成され、$A_i, B_i$ は $[-1,1]$ からランダムに選ばれます。逆微分は`scipy.integrate.cumtrapz`を用いた累積台形則により数値的に計算されます。
5.  Claude 3.7 Sonnet: DeepSeek R1と同様に、入力関数は以下のいずれかとして生成されます。
    1.  フーリエ級数 $u(x) = \sum_{i=1}^N A_i \sin(2\pi i x) + B_i \cos(2 \pi i x)$ で、$A, B$ は $[-1,1]$ からランダムに選ばれ、$N$ は $\{2,3,4,5,6\}$ からランダムに選ばれます。
    2.  次数 $d$ が $\{2,3,4,5\}$ からランダムに選ばれ、ランダムな係数が $[-1,1]$ から選ばれる多項式。
    3.  三角関数 $u(x) = A \sin(B x) + C \cos(2x)$ で、$A, B, C$ は $[0.5, 2]$ からランダムに選ばれます。すべての逆微分は解析的に計算されます。
6.  Claude 3.7 Sonnet with extended thinking: 同様に、入力関数は以下のいずれかとして生成されます。
    1.  次数 $d$ が $\{0, 1, 2,3,4,5\}$ からランダムに選ばれ、ランダムな係数が $[-2,2]$ から選ばれる多項式。
    2.  サイン関数 $u(x) = A \sin(B x)$ で、$A, B$ は $[0.5, 3]$ からランダムに選ばれます。
    3.  指数関数 $u(x) = A \exp(Bx)$ で、$A, B$ は $[0.5,2]$ からランダムに選ばれます。
    4.  混合関数 $u(x) = A \sin( x) + B x^2$ で、$A, B$ は $[0.5,2]$ からランダムに選ばれます。
    5.  ガウス関数 $u(x) = a \exp\left(-\left(\frac{x - \mu}{\sigma}\right)^2\right)$ で、$a \sim \text{Unif}[1, 3]$、$\mu \sim \text{Unif}[-0.5, 0.5]$、$\sigma \sim \text{Unif}[0.2, 0.5]$ です。ガウス関数の逆微分は`scipy.integrate.quad`を使用して数値的に計算されます。
    6.  有理関数 $u(x) = \frac{A}{1 + B x^2}$ で、$a, b$ は $[0.5,2]$ からランダムに選ばれます。ガウス関数以外の関数の逆微分は解析的に計算されます。

Claude 3.7 Sonnet with extended thinkingは、最も複雑で多様な関数タイプからなる訓練データセットを生成することが観察されました。驚くべきことに、どのモデルも、オリジナルのDeepONet論文 [deeponet] で使用されている戦略であるガウス過程 (GRF) を用いて訓練関数を生成することを検討しませんでした。

訓練を進めるにあたり、LLMが生成したコードのいくつかのバグは手動で修正されました。経験的に、繰り返しの実験を通じて、Claudeが生成したコードには、他のモデルと比較して、この特定のタスクにおいて非自明なバグが多く含まれていることが分かりました。いくつかの主要なバグは以下の通りです。

1.  DeepSeek V3のコードには、ブランチネットワークとトランクネットワークの出力間のドット積でテンソル次元の不一致によるエラーがあり、手動で修正されました。
2.  ChatGPT 4oのコードは、トランクネットワークの入力次元を1（従属変数の次元）ではなく100（評価点の数）に誤って設定していました。正しい次元が手動で設定され、それに合わせてテンソルの形状が修正されました。
3.  Claude 3.7 Sonnetは、`KerasTensor`がKeras操作ではなくTensorFlow関数 (`tf.reshape`) に渡されるというバグを繰り返し出力しました。これはKerasのFunctional APIのルールに違反していました。このバグは、関数をカスタムKerasレイヤーでラップすることで修正されました。
4.  Claude 3.7 Sonnet with extended thinkingは、Claude 3.7 Sonnetと同じ間違いを犯しました。

モデルのアーキテクチャと訓練結果は、表1にまとめられています。両方のClaudeモデルは、より伝統的なReLu活性化関数ではなく、$\text{Swish}(x) = x \cdot \frac{1}{1 + e^{-x}}$ と定義されるSwish活性化関数の使用を採用しており、滑らかさや非単調性などの利点を挙げてその選択を正当化しています。また、Claudeモデルは、$L^2$重み正則化、学習率スケジューリング、ドロップアウト訓練などの高度な訓練技術も使用しました。

| モデル | 推論時間 (s) | バグなし ? | ブランチネット | トランクネット | データ数 | 活性化関数 | バッチサイズ | エポック数 | 早期停止 ? |
|---|---|---|---|---|---|---|---|---|---|
| DeepSeek V3 | N/A | No | [100, 128, 128, 128] | [1, 128, 128, 128] | 10,000 | ReLu | 32 | 100 | No |
| DeepSeek R1 | 214.0 | Yes | [100,100,100,50] | [1,100,100,50] | 5,000 | ReLu | 32 | 200 | Yes |
| ChatGPT 4o | N/A | No | [100, 64, 64, 64, 64] | [1, 64, 64, 64, 64] | 10,000 | ReLu | 32 | 100 | No |
| ChatGPT o3-mini-high | 11.0 | Yes | [100,100,100,100] | [1,100,100,100] | 1,000 | ReLu | 64 | 50 | No |
| Claude 3.7 Sonnet | N/A | No | [100, 64, 128, 64, 32] | [1, 32, 64, 32, 32] | 800 | Swish | 64 | 50 | Yes |
| Claude 3.7 Sonnet extended thinking | 79.0 | No | [100, 256, 128, 64, 50] | [1, 64, 64, 50] | 2,000 | Swish | 128 | 150 | Yes |
*表1: 逆微分演算子を学習するDeepONetモデルのネットワークアーキテクチャ、ハイパーパラメータ、および $L_2$ 予測誤差。ネットワークアーキテクチャ表記は、表[tab:PINNs]と同じ規則に従います。*

モデルは異なるデータセットで訓練されているため、その性能を評価するために普遍的で一般的なテストセットを構築しました。テストセットは、長さスケールが $0.05, 0.1, 0.2, 0.5$ のガウス過程 (GRF) によって生成された関数で構成されています。データの例は図2に示されています。各モデルの結果は表2に示されています。長さスケールが小さい関数は、ほとんどのモデルにとって予測がより困難です。DeepSeek R1が最良の結果を示し、DeepSeek V3はすべての長さスケールで意味のある予測をすることに失敗しました。Claudeが生成したDeepONetsのテスト性能が低いのは、訓練データではなくハイパーパラメータの選択によるものであることに注意してください。Claude 3.7 Sonnet with extended thinkingと同じデータを使用し、正則化器、学習率スケジューラ、ドロップアウト層を削除し、ReLU活性化関数に切り替え、ChatGPT o3-mini-highに合わせて各層のニューロン数を100に増やしました。これらの変更により、簡略化されたモデルは両方のChatGPTモデルに匹敵する性能を示しました。これは、Claudeが良い戦略を生成する一方で、その実装が最適な性能を得るためには依然として人間の介入とハイパーパラメータチューニングを必要とすることを示しています。

![Derivative_plots.png](figures/Derivative_plots.png)
*図2: 逆微分演算子を学習するDeepONetのテストデータ。異なる長さスケールのガウス過程 (GRF) で生成されています。*

| モデル | 長さスケール $0.5$ | 長さスケール $0.2$ | 長さスケール $0.1$ | 長さスケール $0.05$ |
|---|---|---|---|---|
| DeepSeek V3 | 49.4% | 50.6% | 51.6% | 47.5% |
| DeepSeek R1 | **0.0008**% | **0.2**% | **1.9**% | **5.7**% |
| ChatGPT 4o | 0.05% | 1.0% | 3.4% | 6.1% |
| ChatGPT o3-mini-high | 0.06% | 1.0% | 3.5% | 6.2% |
| Claude 3.7 Sonnet | 0.35% | 4.17% | 12.69% | 180.41% |
| Claude 3.7 Sonnet extended thinking | 0.22% | 2.05% | 5.0% | 7.04% |
*表2: 異なる長さスケールのGRFから生成されたテストデータセットにおけるDeepONetモデルの相対 $L_2$ 誤差。多様な訓練データとエラーのない実装を持つDeepSeek R1が最良の結果を達成しています。Claudeモデルは高度なドロップアウト技術、正則化、学習率スケジューリング、Swish活性化を使用しましたが、これらがない場合、モデルはより良い性能を発揮し、ChatGPTの結果に匹敵したでしょう。*
### DeepONetによるカプート分数階微分オペレーターの学習

より高度なテスト問題として、任意の分数階次数を持つカプート分数階微分オペレーターの学習タスクを提示します。1次元カプート分数階微分オペレーター$G(u)(y,\alpha)$は次のように定義されます。

$$
G(u)(y,\alpha) : \; u(x) \mapsto s(y,\alpha) = \frac{1}{\Gamma(1-\alpha)} \int_{0}^{y} (y-\tau)^{-\alpha} u'(\tau) d\tau, \\
y \in [0,1], \, \alpha \in (0,1)
$$

ここで、$\alpha$は任意の分数階次数、$u'$は$u$の1階微分を示します。

すべてのLLMには、以下のプロンプトが与えられました。

`Implement a Deep Operator Network (DeepONet) in Tensorflow to learn the 1D Caputo fractional \\ derivative operator $G(u)(y,\alpha)$, which is defined as`
`$$`
`G(u)(y,\alpha) : u(x) \mapsto s(y,\alpha) = \frac{1}{\Gamma(1-\alpha)} \int_{0}^{y} (y-\tau)^{-\alpha} u'(\tau) d\tau, \\`
`y \in [0,1], \, \alpha \in (0,1)`
`$$`
`where $\alpha$ is an arbitrary fractional order, and $u'$ denotes the first derivative of $u$. Function $u$ is sampled from a Gaussian Random Field with a length scale of 0.2.`

このテストでは入力関数空間が指定されていますが、LLMは自身の訓練データセットとテストデータセットを生成する責任があります。データ生成のためには、入力関数を数値的に微分および積分する必要があります。各LLMが微分と積分に使用した方法は、表1にまとめられています。ほとんどのモデルが有効な数値スキームを実装した一方で、ChatGPT 4oとClaude 3.7 Sonnetは両方とも積分ステップで同様の誤りを犯しました。具体的には、正しい区間$[0,y]$で積分を計算する代わりに、誤って$[0,1]$で計算しました。これにより、$(y-\tau)^{-\alpha}$の項が$y=\tau$で特異点を持つため、ゼロ除算エラーが発生しました。このバグは手動で修正され、積分には台形則が採用されました。

| モデル | $u'$の微分 | 積分 |
|---|---|---|
| DeepSeek V3 | 1次有限差分 | 台形則 (`numpy`) |
| DeepSeek R1 | 1次有限差分 | 左リーマン和 (ゼロから実装) |
| ChatGPT 4o | 1次有限差分 | 誤った境界 |
| ChatGPT o3-mini-high | 中心差分 | 台形則 (`numpy`) |
| Claude 3.7 Sonnet | 中心差分 | 誤った境界 |
| Claude 3.7 Sonnet extended thinking | 中心差分 | 台形則 (`numpy`) |

*表1: 訓練・テストデータ生成のために各LLMが1次元カプート分数階微分を計算するために使用した手法。*

我々は特に、LLMが分数階次数$\alpha$をDeepONetに正しくエンコードする方法を知っているかに関心がありました。なぜなら、分数階次数$\alpha$は他のDeepONetアプリケーションには通常現れず、この特定のタスクにおけるLLMの知識は限られている可能性があるからです。元のDeepONet論文[deeponet]では、次数$\alpha$は評価座標$y$とともにトランクネットワークに入力されます。注目すべきことに、6つのLLMすべてが$\alpha$をトランクに正しく配置しました。しかし、繰り返しの実験において、すべてのDeepSeekおよびChatGPTモデルは、入力テンソルを定式化する際に一貫して同じ誤りを犯しました。具体的には、各評価点$y$を異なる$\alpha$と誤ってペアリングし、入力を次のように構成しました。

$$
\text{Trunk net input} = \begin{bmatrix} 
y_1 & \alpha_1 \\ 
y_2 & \alpha_2 \\ 
\vdots & \vdots \\ 
y_N & \alpha_N 
\end{bmatrix}
$$

しかし、各分数階微分次数$\alpha$に対して、出力関数が計算される複数の評価点$\{y_1, y_2, \ldots, y_n\}$が存在するべきです。$(y_i, \alpha_i)$の異なるペアを使用すると、分数階微分を$\alpha_i$ごとに単一の点$y_i$で評価することになり、DeepONetが区間$[0,1]$全体での微分表現の完全な学習を妨げます。結果として、DeepSeekまたはChatGPTが生成したオリジナルの実装（人間の介入なし）で訓練されたDeepONetは、テスト時に150%を超える$l^2$相対誤差を生じました。このような誤った定式化での比較は意味のある洞察を提供しないため、DeepSeekとChatGPTのコードを手動で修正し、トランクネットワークへの空間入力$y$が、区間$[0.1, 0.9]$からランダムに選択された分数階次数$\alpha$ごとに100個の異なる点で評価されるようにしました。

両方のClaudeモデルは、すべての実験でトランクネットワークの入力を正しく定式化しました。しかし、これらはネットワークに渡す前に、ブランチネットワークとトランクネットワークの入力テンソルを最初の次元に合わせて一貫してタイリングしました。これにより、2つのブランチを通過した後、それらのドット積を直接計算できるようになりましたが、`einsum`やTensorFlowの行列乗算でドット積を簡単に実装できるため、このタイリングは不必要でコストがかかるものでした。過剰なタイリングは非常に大きなテンソルサイズにつながり、訓練を遅らせました。

さらに、DeepSeek V3は、ユーザーが$\alpha \in (0,1)$を任意と指定したにもかかわらず、固定された分数階次数$\alpha = 0.5$のみを使用してDeepONetを誤って訓練しました。同様に、拡張思考を持つClaude 3.7 Sonnetは、すべての900の訓練関数に対して5つの固定された分数階次数、$\alpha = 0.17, 0.25, 0.34, 0.65, 0.73$を使用し、合計で4500の訓練サンプルサイズとなりました。訓練データで分数階次数を固定すると、DeepONetがテスト中に未知の分数階次数に汎化する能力が低下しました。正しいアプローチは、各訓練サンプルに対して$\alpha$をランダムにサンプリングすることです。しかし、これらの間違いはLLMの意思決定の一部であるため、手動で修正されませんでした。

最後に、すべてのDeepONetを長さスケール0.2のGRF生成関数とランダムな次数$\alpha \in [0.1, 0.9]$で訓練およびテストしました。結果、モデルのアーキテクチャ、およびハイパーパラメータは、表2に報告されています。

| モデル | 推論時間 (s) | バグなし？ | ブランチネットワーク | トランクネットワーク | エポック数 | 訓練データ数 | 活性化関数 | 訓練時間 (s) | テスト $L_2$誤差 |
|---|---|---|---|---|---|---|---|---|---|
| DeepSeek V3 | N/A | いいえ | [100, 128, 128, 128] | [2, 128, 128, 128] | 100 | 1000 | ReLU | 11.87 | 177.19% |
| DeepSeek R1 | 426.0 | いいえ | [100, 128, 128, 128] | [2, 128, 128, 128] | 50 | 1000 | ReLU | 6.58 | 26.82% |
| ChatGPT 4o | N/A | いいえ | [100, 50, 50, 50, 100] | [2, 50, 50, 50, 100] | 100 | 1000 | ReLU | 13.54 | 19.49% |
| ChatGPT o3-mini-high | 23.0 | いいえ | [100, 128, 128, 100] | [2, 128, 128, 100] | 100 | 1000 | ReLU | 10.91 | 18.41% |
| Claude 3.7 Sonnet | N/A | いいえ | [100, 128, 128, 40] | [2, 128, 128, 40] | 200 | 900 | ReLU | 41.74 | **5.59**% |
| Claude 3.7 Sonnet extended thinking | 109.0 | いいえ | [100, 128, 128, 128, 50] | [2, 128, 128, 128, 50] | 50 | 4500 | ReLU | 1943.14 | 16.24% |

*表2: 1次元カプート分数階微分を学習するDeepONetモデルのネットワークアーキテクチャ、ハイパーパラメータ、および$L_2$予測誤差。表記は表PINNsに従う。この表に報告されているテスト$L_2$誤差は、元のコードのバグを手動で修正した後の修正を反映している。Claude 3.7 Sonnetが最良の結果を達成したが、コード内の非効率なテンソル操作により遅い。DeepSeek V3および拡張思考を持つClaude 3.7 Sonnetの性能は、異なる訓練サンプルで固定された分数階次数$\alpha$を使用したことにより妨げられている。*

この表に報告されているテスト$L_2$誤差は、元のコードのバグを手動で修正した後の修正を反映しています。DeepSeek V3のテスト誤差は非常に高く、これは単一の分数階次数で訓練されたため、汎化に失敗していることを示しています。拡張思考を持つClaude 3.7 Sonnetも同様の間違いを犯していますが、そのより大きなサンプルサイズと5つの異なる$\alpha$の選択により、より良い性能を達成しています。全体として、ハイブリッド推論モデルであるClaude 3.7 Sonnetが最良の結果を達成しましたが、コード内の非効率なテンソル操作により遅いです。さらに、以前の実験結果と同様に、ほとんどのモデルは100エポック以下でしか訓練されておらず、適切な収束には不十分です。実際、我々の実験中では、エポック数を単純に1000に増やすだけで、全く同じモデルで相対誤差が1桁台に減少しました。
# 要約

本研究では、DeepSeek（DeepSeek V3、DeepSeek R1）、OpenAI（ChatGPT 4o、ChatGPT o3-mini-high）、Anthropic（Claude 3.7 Sonnet、Claude 3.7 Sonnet with extended thinking）から最近リリースされた大規模言語モデルの性能を、科学計算および科学機械学習における多様なタスクについて評価・比較しました。私たちは、数値積分、有限差分法（FDM）、有限要素法（FEM）などの高度な数学的推論とドメイン固有の知識を必要とする困難な問題、および画像認識、物理情報ニューラルネットワーク（PINNs）、Deep Operator Networks（DeepONet）などの科学機械学習タスクを設計しました。私たちの焦点は、モデルが適切な数値手法またはニューラルネットワークアーキテクチャを選択し、それらをPythonで正確に実装する能力を評価することにありました。

結果として、推論に最適化されたモデルであるDeepSeek R1、ChatGPT o3-mini-high、および拡張思考付きClaudeは、問題の性質を認識し、それに応じて意思決定を行う点で一貫して優れた性能を示しました。実際、それらの選択の多くは、科学計算と科学機械学習の両方において私たちがこれらの問題を解決する際に行うであろう選択と同様でした。対照的に、汎用モデルであるDeepSeek V3とChatGPT 4oは、問題の特定の特性（剛性など）やユーザーからの指示（ゼロからの実装など）を考慮できない場合があり、結果として不正確なソリューションを生成しました。

本研究は、科学研究におけるLLMの使用の現実性の高まり、およびDeepSeek、OpenAI、Anthropic間の競争の激化を浮き彫りにしています。これは、すべての先行開発者が数学、コーディング、科学計算のタスクのためにモデルを改良し続けているためです。私たちの発見はまた、これらの最先端LLMの限界も露呈しました。これは、対象分野に不慣れな人間研究者を混乱させる可能性のある、曖昧または不正確な応答によって示されています。私たちの発見は、科学的問題解決のためのLLMの継続的な改善の必要性を強調しています。将来の研究では、追加のベンチマーク方法を探求し、プロジェクトの異なる段階で一連の意思決定が必要とされる、より複雑な実世界の計算上の課題に対してLLMを評価する必要があります。そうすることで、研究者はLLMアシスタントをいつ、どのように効果的かつ責任を持って日常業務で使用するかについて、より情報に基づいた意思決定を行うことができます。

# 謝辞

本研究は、ONR Vannevar Bush Faculty Fellowship（N00014-22-1-2795）の支援を受けました。ブラウン大学のCrunch Groupのメンバーの皆様からのご提案とご洞察に感謝いたします。
