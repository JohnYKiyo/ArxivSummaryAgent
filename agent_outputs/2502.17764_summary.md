# DeepSeek vs. ChatGPT vs. Claude: A Comparative Study for Scientific Computing and Scientific Machine Learning Tasks

URL: http://arxiv.org/abs/2502.17764v2

発表年: 2025

著者:
Qile Jiang, Zhiwei Gao, George Em Karniadakis

著者の所属機関:
Brown University's Crunch Group

## 要約

本論文は、最近公開された大規模言語モデル（LLM）である DeepSeek（DeepSeek V3, DeepSeek R1）、OpenAI（ChatGPT 4o, ChatGPT o3-mini-high）、Anthropic（Claude 3.7 Sonnet, Claude 3.7 Sonnet with extended thinking）の性能を、科学計算および科学機械学習タスクにおいて比較評価することを目的としています。研究者らは、数値積分、有限差分法（FDM）、有限要素法（FEM）などの高度な数学的推論とドメイン固有の知識を必要とする問題、および画像認識、物理情報ニューラルネットワーク（PINN）、深層作用素ネットワーク（DeepONet）などの科学機械学習タスクを含む、意図的に巧妙なベンチマーク問題を設計しました。

評価の結果、DeepSeek R1、ChatGPT o3-mini-high、Claude 3.7 Sonnet extended thinking といった推論最適化モデルが、問題の性質を認識し、適切な数値手法やニューラルネットワークアーキテクチャを選択し、それらを Python で正しく実装する能力において一貫して優れた性能を示しました。これらのモデルの多くは、人間の科学者が問題を解決する際に行う選択と類似した意思決定を行いました。対照的に、汎用モデルである DeepSeek V3 および ChatGPT 4o は、問題の特定の特性（例：ODE のスティッフ性）やユーザーからの指示（例：ゼロからの実装）を考慮しないことがあり、その結果、不正確な解を生成しました。

本研究は、科学研究における LLM 活用の実用性の高まりと、LLM 開発者間の激しい競争を浮き彫りにする一方で、最先端の LLM がなお根深い限界（例：あいまいな、または不正確な応答、特定の条件下でのコードのバグ）を示すことも明らかにしました。これらの限界は、対象分野に不慣れな人間の研究者を混乱させる可能性があります。結論として、本論文は、科学的問題解決のための LLM の継続的な改善の必要性を強調し、今後の研究課題として追加のベンチマーク手法の検討や、より複雑な現実世界の計算課題における LLM の評価を提案しています。

## レビュー/サーベイ項目

本論文で評価されたレビュー/サーベイ項目は、以下の科学計算および科学機械学習タスクです。

- **従来の数値計算法 (Traditional Numerical Methods)**

  - **スティッフ ODE の数値解法 (Numerical Solution of Stiff ODEs)**
    - ロバートソン方程式を題材に、スティッフ性を認識し、適切な陰解法（例：後退オイラー法）を選択できるか。
  - **ポアソン方程式の有限差分法 (Finite Difference Method for Poisson Equation)**
    - L 字型領域のような非標準領域における 2D ポアソン方程式を、ゼロ境界条件と定数右辺のもとで FDM を用いて解けるか。
  - **振動梁方程式の有限要素法 (Finite Element Method for Oscillating Beam Equation)**
    - 高次の常微分方程式である梁方程式を、非同次境界条件のもとで FEM を用いて解けるか。弱形式の導出とテスト空間の選択の正確性。
  - **積分に対する求積法 (Quadrature for Integrals)**
    - 特異点を持つ積分を、適切な変数変換と求積法（例：ガウス求積法）を用いて計算できるか。

- **科学機械学習 (Scientific Machine Learning)**
  - **MNIST 数字予測 (MNIST Digit Prediction)**
    - 標準的な画像認識タスクにおいて、計算効率と高精度を両立する CNN を TensorFlow で実装できるか。
  - **物理情報ニューラルネットワーク (Physics-Informed Neural Networks - PINNs)**
    - L 字型領域における 2D ポアソン方程式を、JAX を用いて PINN で解けるか。特に、非標準領域でのデータ生成と勾配計算の正確性。
  - **原始関数演算子を学習するための DeepONet (DeepONet for Learning Anti-derivative Operator)**
    - 1 次元の原始関数演算子を DeepONet で学習できるか。特に、入力関数空間の選択と多様なデータセットの生成能力。
  - **Caputo 分数微分演算子を学習するための DeepONet (DeepONet for Learning Caputo Fractional Derivative Operator)**
    - 1 次元 Caputo 分数微分演算子（分数次数$\alpha$を含む）を DeepONet で学習できるか。特に、入力$\alpha$の DeepONet へのエンコード方法と、特異点を含む関数の数値微分・積分処理。

## 比較

論文では、以下の 6 つの LLM が比較されました。

- **DeepSeek V3**: 汎用モデル
- **DeepSeek R1**: 推論特化モデル
- **ChatGPT 4o**: 汎用モデル
- **ChatGPT o3-mini-high**: 推論特化モデル
- **Claude 3.7 Sonnet**: ハイブリッド推論モデル
- **Claude 3.7 Sonnet extended thinking**: 推論拡張モデル

以下に、各レビュー/サーベイ項目におけるモデルの比較をまとめます。

**1. スティッフ ODE の数値解法（ロバートソン方程式）**

| モデル                              | 推論時間 (秒) | 手法                             | 時間刻み                | $L_2$誤差 ($x$)              | $L_2$誤差 ($y$)              | $L_2$誤差 ($z$)               |
| ----------------------------------- | ------------- | -------------------------------- | ----------------------- | ---------------------------- | ---------------------------- | ----------------------------- |
| DeepSeek V3                         | N/A           | RK4                              | 0.01                    | N/A                          | N/A                          | N/A                           |
| DeepSeek R1                         | 249.0         | 後退オイラー法                   | 0.1                     | **$7.86 \times 10^{-6} \%$** | **$7.61 \times 10^{-5} \%$** | **$1.96 \times 10^{-4} \%$**  |
| ChatGPT 4o                          | N/A           | RK4                              | 0.1                     | N/A                          | N/A                          | N/A                           |
| ChatGPT o3-mini-high                | 88.0          | 適応的時間刻み付き後退オイラー法 | 適応的 ($10^{-6}$ 初期) | $3.93 \times 10^{-6} \%$     | $9.40 \times 10^{-4} \%$     | $0.14 \%$                     |
| Claude 3.7 Sonnet                   | N/A           | 適応的時間刻み付き RK4           | 適応的 ($10^{-4}$ 初期) | **$1.24 \times 10^{-6} \%$** | $0.05 \%$                    | $4.89 \times 10^{-4} \%$      |
| Claude 3.7 Sonnet extended thinking | 115.0         | 後退オイラー法                   | 0.1                     | $7.74\times 10^{-6} \%$      | **$7.53 \times 10^{-5} \%$** | \*\*$1.94 \times 10^{-4}} \%$ |

_比較サマリ_: 推論機能を持つ DeepSeek R1、ChatGPT o3-mini-high、Claude 3.7 Sonnet extended thinking は、ODE のスティッフ性を認識し、陰解法（後退オイラー法）を選択した。非推論モデルは RK4 を選択し、問題解決に失敗した。Claude 3.7 Sonnet extended thinking が最良の結果を達成。ChatGPT o3-mini-high は最短の推論時間で満足のいく解を出力した。

**2. ポアソン方程式の有限差分法**

|                                     | 推論時間 (s) | 方法   | グリッド      | CPU 時間 (s) | $L_2$誤差 |
| :---------------------------------- | :----------- | :----- | :------------ | :----------- | :-------- |
| DeepSeek V3                         | N/A          | 反復法 | $50\times 50$ | 9.5          | 201%      |
| DeepSeek R1                         | 476.0        | FDM    | $50\times 50$ | 0.6          | 203%      |
| ChatGPT 4o                          | N/A          | FDM    | $50\times 50$ | 0.6          | 203%      |
| ChatGPT o3-mini-high                | 32.0         | FDM    | $41\times 41$ | 0.5          | 207%      |
| Claude 3.7 Sonnet                   | N/A          | FDM    | $50\times 50$ | 0.6          | **4.54%** |
| Claude 3.7 Sonnet extended thinking | 125.0        | FDM    | $60\times 60$ | 0.7          | 202%      |

_比較サマリ_: Claude 3.7 Sonnet のみが正しい結果を示し、最小の$L_2$誤差を達成した。DeepSeek R1、ChatGPT 4o、ChatGPT o3-mini-high、Claude 3.7 Sonnet extended thinking は解の符号を誤った。DeepSeek V3 は反復法を用いて CPU 時間を要し、誤差も大きかった。推論モデルの中では、ChatGPT o3-mini-high が最も速く応答した。

**3. 振動梁方程式の有限要素法**

|                                     | 推論時間 (s) | 基底       | グリッド | $L_2$誤差 |
| :---------------------------------- | :----------- | :--------- | :------- | :-------- |
| DeepSeek V3                         | N/A          | エルミート | 100      | 276300%   |
| DeepSeek R1                         | 790.0        | エルミート | 10       | 15.3%     |
| ChatGPT 4o                          | N/A          | エルミート | 50       | 205%      |
| ChatGPT o3-mini-high                | 31.0         | エルミート | 100      | 19.4%     |
| Claude 3.7 Sonnet                   | N/A          | エルミート | 100      | 957%      |
| Claude 3.7 Sonnet extended thinking | 9.0          | エルミート | 20       | **13.7%** |

_比較サマリ_: どの LLM も FEM を正確に適用して非常に正確な解を得ることはできなかった。すべてのモデルがエルミート基底関数とガラーキン法を認識したが、弱形式の導出におけるテスト空間の選択を誤った。推論モデルは非推論モデルよりはるかに性能が優れており、Claude 3.7 Sonnet extended thinking が最小の$L_2$誤差を達成した。ChatGPT o3-mini-high と Claude 3.7 Sonnet extended thinking は DeepSeek R1 よりはるかに速く応答した。

**4. 積分に対する求積法（特異点を持つ積分）**

|                                     | 推論時間 (秒) | 手法           | ノード数 | $L_2$誤差 |
| ----------------------------------- | ------------- | -------------- | -------- | --------- |
| DeepSeek V3                         | N/A           | Scipy          | N/A      | N/A       |
| DeepSeek R1                         | 584.0         | Gauss-Legendre | 10       | 3.74e-12  |
| ChatGPT 4o                          | N/A           | Gauss-Legendre | 20       | 5.15e-13  |
| ChatGPT o3-mini-high                | 74.0          | Gauss-Legendre | 50       | 5.21e-14  |
| Claude 3.7 Sonnet                   | N/A           | Gauss-Legendre | 1000     | 機械精度  |
| Claude 3.7 Sonnet extended thinking | 37.0          | Gauss-Legendre | 1000     | 機械精度  |

_比較サマリ_: DeepSeek V3 を除くすべてのモデルが、特異点を正しく特定し、求積法を使用する前に適切な変数変換を適用し、同等の高い性能を達成した。Claude モデルは、異なる手法（台形公式、シンプソン公式、ガウス求積法、変数変換）の収束率を比較するなど、より包括的な分析を提供した。

**5. MNIST 数字予測**

| モデル                              | 推論時間 (秒) | アーキテクチャ              | エポック数 | 時間 (秒) | テスト精度 | 早期停止 |
| ----------------------------------- | ------------- | --------------------------- | ---------- | --------- | ---------- | -------- |
| DeekSeek V3                         | N/A           | CNN (3 層)                  | 5          | 21.30     | 98.96%     | N/A      |
| DeepSeek R1                         | 129.0         | CNN (2 層 + ドロップアウト) | 20         | 21.23     | 99.11%     | はい     |
| ChatGPT 4o                          | N/A           | CNN (2 層 + ドロップアウト) | 10         | 21.85     | **99.31%** | N/A      |
| ChatGPT o3-mini-high                | 8.0           | CNN (2 層)                  | 10         | 21.18     | 98.84%     | N/A      |
| Claude 3.7 Sonnet                   | N/A           | CNN (2 層 + ドロップアウト) | 10         | 21.30     | 98.98%     | はい     |
| Claude 3.7 Sonnet extended thinking | 38.0          | CNN (2 層 + ドロップアウト) | 10         | 21.33     | 99.14%     | はい     |

_比較サマリ_: すべてのモデルが同等の訓練時間と高いテスト精度を達成できた。Claude モデルと DeepSeek R1 は早期停止基準を実装した。推論モデルの中で、ChatGPT o3-mini-high が最も速い推論時間を示した。

**6. 物理情報ニューラルネットワーク (PINN)（ポアソン方程式）**

|                                     | 推論時間 (s) | ネットワーク           | 学習データ       | エポック | 学習時間 (s) | 活性化関数 | $L_{2}$ 誤差 |
| ----------------------------------- | ------------ | ---------------------- | ---------------- | -------- | ------------ | ---------- | ------------ |
| DeepSeek V3                         | N/A          | [2, 20, 20, 20, 1]     | 1000             | 5000     | 7.90         | Tanh       | 929%         |
| DeepSeek R1                         | 417.0        | [2, 50, 50, 50, 50, 1] | 512              | 10000    | 13.80        | Tanh       | 54.7%        |
| ChatGPT 4o                          | N/A          | [2, 64, 64, 64, 64, 1] | 5000             | 5000     | 15.23        | Tanh       | 169%         |
| ChatGPT o3-mini-high                | 15.0         | [2, 64, 64, 64, 1]     | 200 (毎エポック) | 5000     | 1740.00      | Tanh       | 5.31%        |
| Claude 3.7 Sonnet                   | N/A          | [2, 32, 32, 32, 32,1]  | 2000             | 10000    | 12.10        | Tanh       | **4.25%**    |
| Claude 3.7 Sonnet extended thinking | 38.0         | [2, 32, 32, 32, 1]     | 5000             | 1000     | 19.00        | Tanh       | 322%         |

_比較サマリ_: 全モデルがエラーのあるコードを生成したが（JAX の`grad`関数の誤用）、修正後に ChatGPT o3-mini-high と Claude 3.7 Sonnet が低い$L_2$誤差で良好な予測を提供した。Claude 3.7 Sonnet が最も低誤差を達成。DeepSeek R1 も L 字型境界を認識し適応する能力を示した。推論時間では、ChatGPT o3-mini-high と Claude 3.7 Sonnet extended thinking が DeepSeek R1 よりはるかに高速だった。

**7. 原始関数演算子を学習するための DeepONet**

| モデル                              | 推論時間 (s) | バグなし？ | ブランチネットワーク    | トランクネットワーク | データ数 | 活性化関数 | バッチサイズ | エポック数 | 早期停止？ |
| ----------------------------------- | ------------ | ---------- | ----------------------- | -------------------- | -------- | ---------- | ------------ | ---------- | ---------- |
| DeekSeek V3                         | N/A          | No         | [100, 128, 128, 128]    | [1, 128, 128, 128]   | 10,000   | ReLu       | 32           | 100        | No         |
| DeepSeek R1                         | 214.0        | Yes        | [100,100,100,50]        | [1,100,100,50]       | 5,000    | ReLu       | 32           | 200        | Yes        |
| ChatGPT 4o                          | N/A          | No         | [100, 64, 64, 64, 64]   | [1, 64, 64, 64, 64]  | 10,000   | ReLu       | 32           | 100        | No         |
| ChatGPT o3-mini-high                | 11.0         | Yes        | [100,100,100,100]       | [1,100,100,100]      | 1,000    | ReLu       | 64           | 50         | No         |
| Claude 3.7 Sonnet                   | N/A          | No         | [100, 64, 128, 64, 32]  | [1, 32, 64, 32, 32]  | 800      | Swish      | 64           | 50         | Yes        |
| Claude 3.7 Sonnet extended thinking | 79.0         | No         | [100, 256, 128, 64, 50] | [1, 64, 64, 50]      | 2,000    | Swish      | 128          | 150        | Yes        |

_テスト$L_2$誤差（異なる長さスケール GRF データセット）_
| モデル | 長さスケール $0.5$ | 長さスケール $0.2$ | 長さスケール $0.1$ | 長さスケール $0.05$ |
|---|---|---|---|---|
| DeekSeek V3 | 49.4% | 50.6% | 51.6% | 47.5% |
| DeepSeek R1 | **0.0008**% | **0.2**% | **1.9**% | **5.7**% |
| ChatGPT 4o | 0.05% | 1.0% | 3.4% | 6.1% |
| ChatGPT o3-mini-high | 0.06% | 1.0% | 3.5% | 6.2% |
| Claude 3.7 Sonnet | 0.35% | 4.17% | 12.69% | 180.41% |
| Claude 3.7 Sonnet extended thinking | 0.22% | 2.05% | 5.0% | 7.04% |
_比較サマリ_: LLM はガウス過程（GRF）でトレーニング関数を生成することを検討しなかった。DeepSeek V3、ChatGPT 4o、Claude 3.7 Sonnet、Claude 3.7 Sonnet extended thinking は TensorFlow のテンソル次元や Keras 関数型 API のバグを生成し、手動修正が必要だった。DeepSeek R1 が最も優れた汎化性能を示した。Claude モデルは Swish 活性化関数や高度なトレーニング手法を採用したが、最適ではないハイパーパラメータによりテスト性能が劣化した。簡素化された Claude モデルは ChatGPT モデルに匹敵する性能を示した。

**8. Caputo 分数微分演算子を学習するための DeepONet**

_データ生成手法_
| モデル | $u'$の微分 | 積分 |
| :---------------------------- | :--------------------------- | :---------------------------------- |
| DeepSeek V3 | 1 次有限差分 | 台形則 (\texttt{numpy}) |
| DeepSeek R1 | 1 次有限差分 | 左リーマン和 (ゼロから実装) |
| ChatGPT 4o | 1 次有限差分 | 不正確な範囲 |
| ChatGPT o3-mini-high | 中心差分 | 台形則 (\texttt{numpy}) |
| Claude 3.7 Sonnet | 中心差分 | 不正確な範囲 |
| Claude 3.7 Sonnet extended thinking | 中心差分 | 台形則 (\texttt{numpy}) |

_モデル性能_
| モデル | 推論時間 (秒) | バグなし？ | ブランチネットワーク | トランクネットワーク | エポック数 | 訓練データ数 | 活性化関数 | 訓練時間 (秒) | テスト$L_2$誤差 |
| :------------------------------------- | :---------- | :--------- | :-------------------------- | :--------------------------- | :------- | :--------- | :--------- | :---------- | :------------ |
| DeepSeek V3 | N/A | いいえ | [100, 128, 128, 128] | [2, 128, 128, 128] | 100 | 1000 | ReLu | 11.87 | 177.19% |
| DeepSeek R1 | 426.0 | いいえ | [100, 128, 128, 128] | [2, 128, 128, 128] | 50 | 1000 | ReLu | 6.58 | 26.82% |
| ChatGPT 4o | N/A | いいえ | [100, 50, 50, 50, 100] | [2, 50, 50, 50, 100] | 100 | 1000 | ReLu | 13.54 | 19.49% |
| ChatGPT o3-mini-high | 23.0 | いいえ | [100, 128, 128, 100] | [2, 128, 128, 100] | 100 | 1000 | ReLu | 10.91 | 18.41% |
| Claude 3.7 Sonnet | N/A | いいえ | [100, 128, 128, 40] | [2, 128, 128, 40] | 200 | 900 | ReLu | 41.74 | **5.59**% |
| Claude 3.7 Sonnet extended thinking | 109.0 | いいえ | [100, 128, 128, 128, 50] | [2, 128, 128, 128, 50] | 50 | 4500 | ReLu | 1943.14 | 16.24% |
_比較サマリ_: ChatGPT 4o と Claude 3.7 Sonnet は積分範囲の誤りというバグを生成。DeepSeek と ChatGPT モデルはトランクネットワークへの入力テンソルの定式化で誤り（各評価点に異なる$\alpha$をペアリング）があったため、手動修正が必要だった。Claude モデルはテンソルタイル化の非効率性が見られた。DeepSeek V3 と Claude 3.7 Sonnet extended thinking は固定された分数次数$\alpha$で訓練したため汎化性能が低下。 Claude 3.7 Sonnet が最良の結果を達成したが、コード内の非効率性により訓練時間が長かった。

## 議論

本研究は、DeepSeek、ChatGPT、Claude といった主要な大規模言語モデルが科学計算および科学機械学習タスクにおいて示す、目覚ましい進歩と同時に残された限界を浮き彫りにしました。特に、DeepSeek R1、ChatGPT o3-mini-high、Claude 3.7 Sonnet extended thinking といった推論に最適化されたモデルは、問題の性質を分析し、適切な数値手法やニューラルネットワークアーキテクチャを選択する能力において、汎用モデルを一貫して上回る性能を示しました。彼らの意思決定プロセスは、多くの場合、人間の科学者が同様の問題を解決する際に取るアプローチと類似しており、LLM が単なる情報検索ツールから、推論に基づいたタスクを実行できる自動エージェントへと進化していることを示唆しています。

しかしながら、これらの最先端 LLM でさえ、いくつかの重要な限界を露呈しました。例えば、JAX の`grad`関数の誤った使用、DeepONet の入力テンソルの誤った定式化、積分の範囲の誤り、非効率なテンソル操作など、高度な計算タスクにおいては、依然として実行時エラーや論理的誤りを引き起こすコードを生成することがありました。これらのバグは、対象分野に精通していない研究者にとっては、診断が困難で混乱を招く可能性があります。さらに、一部のモデルは、ユーザーの指定（例：任意分数次数での訓練）を十分に考慮しなかったり、最適な性能を発揮するために人間の介入とハイパーパラメータチューニングが依然として必要であることを示しました。

本研究は、科学研究における LLM 活用の実用性が高まっていることを示しており、特に複雑な問題の解決において、これらのモデルが人間の研究者を支援・補完する大きな可能性を秘めていることを強調しています。同時に、数学、コーディング、科学計算のタスクに特化してモデルの改良を続ける DeepSeek、OpenAI、Anthropic 間の激しい競争が、さらなる進歩を促すであろうことも示されています。

今後の研究課題としては、本研究で用いたベンチマーク以外にも、より多様な科学計算タスクにおける LLM の能力を評価することが挙げられます。特に、現実世界の計算課題は、プロジェクトの異なる段階で一連の意思決定と複雑な相互作用を要求するため、そうした状況下での LLM の評価が不可欠です。これにより、研究者は、日々の業務において LLM アシスタントをいつ、どのように効果的かつ責任を持って活用するかについて、より情報に基づいた意思決定を行えるようになるでしょう。最終的には、LLM が科学的発見とイノベーションを加速させるための、信頼性の高い強力なツールとなるよう、継続的な改善と厳格な評価が求められます。
