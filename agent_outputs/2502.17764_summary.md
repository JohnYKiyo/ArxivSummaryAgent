# DeepSeek vs. ChatGPT vs. Claude: A Comparative Study for Scientific Computing and Scientific Machine Learning Tasks

URL: http://arxiv.org/abs/2502.17764v2

発表年: 2025

著者:
Qile Jiang, Zhiwei Gao, George Em Karniadakis

著者の所属機関:
Brown University

## 要約

本研究は、最近リリースされた大規模言語モデル（LLM）である DeepSeek（DeepSeek V3、DeepSeek R1）、OpenAI（ChatGPT 4o、ChatGPT o3-mini-high）、Anthropic（Claude 3.7 Sonnet、拡張思考を備えた Claude 3.7 Sonnet）の性能を、科学計算および科学機械学習タスクにおいて比較評価することを目的としています。研究チームは、数値積分、有限差分法（FDM）、有限要素法（FEM）などの高度な数学的推論を要する従来の数値計算法、および画像認識、物理情報ニューラルネットワーク（PINN）、深層作用素ネットワーク（DeepONet）などの科学機械学習タスクに焦点を当て、LLM が適切な手法を選択し、Python で正確に実装する能力を評価しました。

**主要な内容と結果:**
実験を通じて、推論に特化したモデル（DeepSeek R1、ChatGPT o3-mini-high、拡張思考を備えた Claude 3.7 Sonnet）は、問題の性質（例: ODE のスティッフ性）を認識し、それに応じた適切な意思決定を行う点で一貫して優れた性能を示しました。これらのモデルの選択するアプローチは、人間科学者が同様の問題を解決する際のアプローチと類似していることが多く見られました。対照的に、汎用モデル（DeepSeek V3、ChatGPT 4o）は、問題の特定の特性やユーザーの指示（例: ゼロからの実装）を考慮しない傾向があり、その結果、不正確な解を生成することがありました。ただし、全てのモデルにおいて、バグや非効率性、最適な性能を発揮するために手動での修正やハイパーパラメータ調整が必要となる限界も露呈しました。

**結論:**
本研究は、科学研究における LLM の利用の現実性が高まっていることを示唆するとともに、数学、コーディング、科学計算のタスクにおいて、主要な LLM 開発者間の競争が激化していることを浮き彫りにしています。推論モデルは汎用モデルよりも優れているものの、主題に不慣れな研究者を混乱させる可能性のある曖昧または不正確な応答を生成する根本的な限界も依然として存在します。これらの知見は、科学的問題解決のための LLM の継続的な改善の必要性を強調しています。

## レビュー/サーベイ項目

本論文で評価されたレビュー/サーベイ項目は以下の通りです。

- **従来の数値計算法:**
  - スティッフ常微分方程式（ODE）の数値解法
  - ポアソン方程式に対する有限差分法（FDM）の実装
  - 振動梁方程式に対する有限要素法（FEM）の実装
  - 特異点を持つ積分の求積法による数値計算
- **科学的機械学習:**
  - MNIST データセットにおける画像認識モデル（CNN）の学習
  - 物理情報ニューラルネットワーク（PINN）による偏微分方程式（PDE）の解法
  - Deep Operator Network（DeepONet）による逆導関数作用素の学習
  - Deep Operator Network（DeepONet）による Caputo 分数微分作用素の学習

## 比較

各レビュー/サーベイ項目における LLM の比較は以下の通りです。

**1. スティッフ ODE の数値解法 (ロバートソン問題)**

- **推論モデル (DeepSeek R1, ChatGPT o3-mini-high, Claude 3.7 Sonnet 拡張推論):**
  - すべて ODE システムのスティッフ性を認識し、陰的解法（後退オイラー法）を選択。
  - DeepSeek R1 と Claude 3.7 Sonnet 拡張推論は非常に低い誤差を達成し、参照解に近い結果。
  - ChatGPT o3-mini-high は適応的時間刻み付き後退オイラー法を使用し、短い推論時間で満足のいく解を生成。
- **非推論モデル (DeepSeek V3, ChatGPT 4o, Claude 3.7 Sonnet):**
  - DeepSeek V3 と ChatGPT 4o は陽的 RK4 スキームを選択し、大きなステップサイズのため問題を解けず、指数関数的に増大する解を生成。
  - ハイブリッド推論の Claude 3.7 Sonnet は適応的時間刻み付き RK4 を実装し、他の 2 つの非推論モデルよりはるかに優れた精度を示したが、$y$種に関する誤差は残った。

| モデル                     | 推論時間 (秒) | 手法                              | ステップサイズ          | $L_2$誤差 ($x$)              | $L_2$誤差 ($y$)              | $L_2$誤差 ($z$)              |
| -------------------------- | ------------- | --------------------------------- | ----------------------- | ---------------------------- | ---------------------------- | ---------------------------- |
| DeepSeek V3                | N/A           | RK4                               | 0.01                    | N/A                          | N/A                          | N/A                          |
| DeepSeek R1                | 249.0         | 後退オイラー法                    | 0.1                     | **$7.86 \times 10^{-6} \%$** | **$7.61 \times 10^{-5} \%$** | **$1.96 \times 10^{-4} \%$** |
| ChatGPT 4o                 | N/A           | RK4                               | 0.1                     | N/A                          | N/A                          | N/A                          |
| ChatGPT o3-mini-high       | 88.0          | 適応的時間刻み付き 後退オイラー法 | 適応的 ($10^{-6}$ 初期) | $3.93 \times 10^{-6} \%$     | $9.40 \times 10^{-4} \%$     | $0.14 \%$                    |
| Claude 3.7 Sonnet          | N/A           | 適応的時間刻み付き RK4            | 適応的 ($10^{-4}$ 初期) | **$1.24 \times 10^{-6} \%$** | $0.05 \%$                    | $4.89 \times 10^{-4} \%$     |
| Claude 3.7 Sonnet 拡張推論 | 115.0         | 後退オイラー法                    | 0.1                     | $7.74\times 10^{-6} \%$      | **$7.53 \times 10^{-5} \%$** | **$1.94 \times 10^{-4} \%$** |

**2. ポアソン方程式に対する有限差分法**

- **Claude 3.7 Sonnet:** 唯一正しい結果を示し、誤差 4.54%。
- **DeepSeek V3:** 反復法を使用し、CPU 時間が大幅に長い（9.5 秒）。
- **他のモデル:** DeepSeek R1, ChatGPT 4o, ChatGPT o3-mini-high, Claude 3.7 Sonnet 拡張推論は、解の符号を間違えるか、スケールを誤るなど、200%以上の高い誤差を示した。
- **推論時間:** ChatGPT o3-mini-high は DeepSeek R1 や Claude 3.7 Sonnet 拡張思考よりもはるかに速く応答。

| モデル                              | 推論時間 (s) | 手法   | グリッド      | CPU 時間 (s) | $L_2$誤差 |
| ----------------------------------- | ------------ | ------ | ------------- | ------------ | --------- |
| DeepSeek V3                         | N/A          | 反復法 | $50\times 50$ | 9.5          | 201%      |
| DeepSeek R1                         | 476.0        | FDM    | $50\times 50$ | 0.6          | 203%      |
| ChatGPT 4o                          | N/A          | FDM    | $50\times 50$ | 0.6          | 203%      |
| ChatGPT o3-mini-high                | 32.0         | FDM    | $41\times 41$ | 0.5          | 207%      |
| Claude 3.7 Sonnet                   | N/A          | FDM    | $50\times 50$ | 0.6          | **4.54%** |
| Claude 3.7 Sonnet extended thinking | 125.0        | FDM    | $60\times 60$ | 0.7          | 202%      |

**3. 振動梁方程式に対する有限要素法**

- **全モデル:** いずれの LLM も有限要素法を正確に適用して非常に高精度な解を得ることはできなかった。弱形式の導出で誤った試行空間を選択した。
- **推論モデル:** 非推論モデルより性能が良く、より小さい$L_2$誤差を示した。Claude 3.7 Sonnet 拡張思考が最も小さい誤差（13.7%）。
- **推論時間:** ChatGPT o3-mini-high と Claude 3.7 Sonnet 拡張思考は DeepSeek R1 よりはるかに速く応答。
- **Claude Sonnet モデル:** 収束率テストのための異なる基底関数による追加テストを提供し、人間科学者に近い技術的推論を示した。

| モデル                              | 推論時間 (s) | 基底       | グリッド | $L_2$誤差 |
| ----------------------------------- | ------------ | ---------- | -------- | --------- |
| DeepSeek V3                         | N/A          | エルミート | 100      | 276300%   |
| DeepSeek R1                         | 790.0        | エルミート | 10       | 15.3%     |
| ChatGPT 4o                          | N/A          | エルミート | 50       | 205%      |
| ChatGPT o3-mini-high                | 31.0         | エルミート | 100      | 19.4%     |
| Claude 3.7 Sonnet                   | N/A          | エルミート | 100      | 957%      |
| Claude 3.7 Sonnet extended thinking | 9.0          | エルミート | 20       | **13.7%** |

**4. 積分における求積法**

- **DeepSeek V3:** `scipy.integrate`モジュールを直接使用。
- **他のモデル:** 特異点を除去するための変数変換（$x=t^3$）を適用し、その後ガウス求積法で計算し、高い精度を達成。
- **Claude モデル:** 台形則、シンプソン則、直接ガウス求積法、変数変換など、より広範な積分技術を調査し、収束率を評価した。

| モデル                              | 推論時間 (秒) | 手法           | ノード数 | $L_2$誤差  |
| :---------------------------------- | :-----------: | :------------- | :------: | :--------: |
| DeepSeek V3                         |      N/A      | Scipy          |   N/A    |    N/A     |
| DeepSeek R1                         |     584.0     | Gauss-Legendre |    10    |  3.74e-12  |
| ChatGPT 4o                          |      N/A      | Gauss-Legendre |    20    |  5.15e-13  |
| ChatGPT o3-mini-high                |     74.0      | Gauss-Legendre |    50    |  5.21e-14  |
| Claude 3.7 Sonnet                   |      N/A      | Gauss-Legendre |   1000   | マシン精度 |
| Claude 3.7 Sonnet extended thinking |     37.0      | Gauss-Legendre |   1000   | マシン精度 |

**5. MNIST 数字予測**

- **全モデル:** この標準的な問題に対して、すべてのモデルが同等の学習時間（約 21 秒）と 98%以上の高いテスト精度を達成。
- **早期停止:** Claude モデルと DeepSeek R1 は早期停止基準を実装し、過学習を防いだ。
- **推論時間:** 推論モデルの中で、ChatGPT o3-mini-high が最も速い推論時間（8 秒）。

| モデル                              | 推論時間 (秒) | アーキテクチャ                                                                                  | エポック数 | 時間 (秒) | テスト精度 | 早期停止 |
| :---------------------------------- | :-----------: | :---------------------------------------------------------------------------------------------- | :--------: | :-------: | :--------: | :------: |
| DeepSeek V3                         |      N/A      | Convolution(32), MaxPooling, Convolution(64), MaxPooling, Convolution(64), Dense(64), Dense(10) |     5      |   21.30   |   98.96%   |   N/A    |
| DeepSeek R1                         |     129.0     | Convolution(32), MaxPooling, Convolution(64), MaxPooling, Dense(128), Dropout(0.5), Dense(10)   |     20     |   21.23   |   99.11%   |   Yes    |
| ChatGPT 4o                          |      N/A      | Convolution(32), MaxPooling, Convolution(64), MaxPooling, Dropout(0.5), Dense(128), Dense(10)   |     10     |   21.85   | **99.31%** |   N/A    |
| ChatGPT o3-mini-high                |      8.0      | Convolution(32), Convolution(64), MaxPooling, Dense(128), Dense(10)                             |     10     |   21.18   |   98.84%   |   N/A    |
| Claude 3.7 Sonnet                   |      N/A      | Convolution(32), MaxPooling, Convolution(64), MaxPooling, Dense(64), Dropout(0.5), Dense(10)    |     10     |   21.30   |   98.98%   |   Yes    |
| Claude 3.7 Sonnet extended thinking |     38.0      | Convolution(32), MaxPooling, Convolution(64), MaxPooling, Dense(64), Dropout(0.5), Dense(10)    |     10     |   21.33   |   99.14%   |   Yes    |

**6. 物理情報ニューラルネットワーク (PINN)**

- **初期バグ:** 全てのモデルが JAX の`grad`関数の誤用によるエラーを生成し、手動で修正が必要だった。
- **精度:** ChatGPT o3-mini-high (5.31%) と Claude 3.7 Sonnet (4.25%) が最も低い$L_2$誤差を達成し、正確な予測を提供。
- **推論モデルの優位性:** 推論モデルは L 字型領域におけるポアソン方程式の複雑な挙動をより正確に捉え、非自明な修正に適応できた。DeepSeek R1 も L 字型境界を認識する能力を示した。
- **推論時間:** ChatGPT o3-mini-high は 15 秒と最も速く、DeepSeek R1 (417 秒) と Claude 3.7 Sonnet 拡張思考 (38 秒) を大幅に上回った。
- **学習時間:** ChatGPT o3-mini-high はエポックごとに新しいサンプルを生成するため、1740 秒という長い学習時間を要したが、その精度は高かった。

| モデル                              | 推論時間 (s) | ネットワーク           | 学習データ       | エポック | 学習時間 (s) | 活性化関数 | $L_{2}$誤差 |
| ----------------------------------- | ------------ | ---------------------- | ---------------- | -------- | ------------ | ---------- | ----------- |
| DeepSeek V3                         | N/A          | [2, 20, 20, 20, 1]     | 1000             | 5000     | 7.90         | Tanh       | 929%        |
| DeepSeek R1                         | 417.0        | [2, 50, 50, 50,50, 1]  | 512              | 10000    | 13.80        | Tanh       | 54.7%       |
| ChatGPT 4o                          | N/A          | [2, 64, 64, 64, 64, 1] | 5000             | 5000     | 15.23        | Tanh       | 169%        |
| ChatGPT o3-mini-high                | 15.0         | [2, 64, 64, 64, 1]     | 200 (毎エポック) | 5000     | 1740.00      | Tanh       | 5.31%       |
| Claude 3.7 Sonnet                   | N/A          | [2, 32, 32, 32, 32,1]  | 2000             | 10000    | 12.10        | Tanh       | **4.25%**   |
| Claude 3.7 Sonnet extended thinking | 38.0         | [2, 32, 32, 32, 1]     | 5000             | 1000     | 19.00        | Tanh       | 322%        |

**7. DeepONet による逆導関数作用素の学習**

- **データ生成の多様性:** DeepSeek R1 が最も多様な関数タイプ（多項式、三角関数、指数関数、混合関数）からトレーニングデータを生成し、ほとんどを解析的に計算。Claude モデルも多様な関数タイプを生成。
- **バグ:** ほとんどのモデルで実装バグが見られた（テンソル次元不一致、誤った入力次元、Keras/TensorFlow 関数の誤用など）ため、手動修正が必要。Claude モデルは特に非自明なバグを多く含んでいた。
- **性能:** DeepSeek R1 が GRF テストデータセットにおいて最も低い相対$L_2$誤差（0.0008%〜5.7%）を達成し、最良の結果を示した。
- **高度な手法:** Claude モデルは Swish 活性化、$L^2$重み正則化、学習率スケジューリング、ドロップアウトといった高度なトレーニング手法を使用したが、これらの要素がなくても ChatGPT モデルと同等の性能を発揮したことから、ハイパーパラメータの調整が重要であることが示唆された。

| モデル                              | 推論時間 (s) | バグなし ? | Branch Net              | Trunk Net           | データ数 | 活性化関数 | バッチサイズ | エポック数 | 早期停止 ? |
| ----------------------------------- | ------------ | ---------- | ----------------------- | ------------------- | -------- | ---------- | ------------ | ---------- | ---------- |
| DeekSeek V3                         | N/A          | No         | [100, 128, 128, 128]    | [1, 128, 128, 128]  | 10,000   | ReLu       | 32           | 100        | No         |
| DeepSeek R1                         | 214.0        | Yes        | [100,100,100,50]        | [1,100,100,50]      | 5,000    | ReLu       | 32           | 200        | Yes        |
| ChatGPT 4o                          | N/A          | No         | [100, 64, 64, 64, 64]   | [1, 64, 64, 64, 64] | 10,000   | ReLu       | 32           | 100        | No         |
| ChatGPT o3-mini-high                | 11.0         | Yes        | [100,100,100,100]       | [1,100,100,100]     | 1,000    | ReLu       | 64           | 50         | No         |
| Claude 3.7 Sonnet                   | N/A          | No         | [100, 64, 128, 64, 32]  | [1, 32, 64, 32, 32] | 800      | Swish      | 64           | 50         | Yes        |
| Claude 3.7 Sonnet extended thinking | 79.0         | No         | [100, 256, 128, 64, 50] | [1, 64, 64, 50]     | 2,000    | Swish      | 128          | 150        | Yes        |

**8. Caputo 分数微分作用素の学習のための DeepONet**

- **分数階数$\alpha$のエンコード:** 全ての LLM が$\alpha$をトランクネットワークに正しく配置した。
- **初期バグ:** DeepSeek および ChatGPT モデルはトランクネットワークへの入力テンソル構築で誤り（各評価点$y$を異なる$\alpha$と誤ってペアリング）を犯し、手動修正が必要。Claude モデルは正しい定式化だが、不必要なテンソルタイリングにより訓練が遅延。
- **訓練データ生成の誤り:** DeepSeek V3 は固定された$\alpha=0.5$で、Claude 3.7 Sonnet 拡張思考は少数の固定された$\alpha$値で訓練を行い、未見の$\alpha$への一般化能力が低下した。これは LLM の意思決定の一部として修正されなかった。
- **性能:** バグ修正後、ハイブリッド推論モデルである Claude 3.7 Sonnet が最も低いテスト$L_2$誤差（5.59%）を達成したが、非効率なテンソル操作により訓練が遅かった。DeepSeek V3 は固定$\alpha$訓練のため一般化に失敗し、非常に高い誤差。

| モデル                              | 推論時間 (秒) | バグなし ? | ブランチネット           | トランクネット         | エポック数 | 訓練データ数 | 活性化関数 | 訓練時間 (秒) | テスト $L_2$ 誤差 |
| ----------------------------------- | ------------- | ---------- | ------------------------ | ---------------------- | ---------- | ------------ | ---------- | ------------- | ----------------- |
| DeepSeek V3                         | N/A           | No         | [100, 128, 128, 128]     | [2, 128, 128, 128]     | 100        | 1000         | ReLu       | 11.87         | 177.19%           |
| DeepSeek R1                         | 426.0         | No         | [100, 128, 128, 128]     | [2, 128, 128, 128]     | 50         | 1000         | ReLu       | 6.58          | 26.82%            |
| ChatGPT 4o                          | N/A           | No         | [100, 50, 50, 50, 100]   | [2, 50, 50, 50, 100]   | 100        | 1000         | ReLu       | 13.54         | 19.49%            |
| ChatGPT o3-mini-high                | 23.0          | No         | [100, 128, 128, 100]     | [2, 128, 128, 100]     | 100        | 1000         | ReLu       | 10.91         | 18.41%            |
| Claude 3.7 Sonnet                   | N/A           | No         | [100, 128, 128, 40]      | [2, 128, 128, 40]      | 200        | 900          | ReLu       | 41.74         | **5.59**%         |
| Claude 3.7 Sonnet extended thinking | 109.0         | No         | [100, 128, 128, 128, 50] | [2, 128, 128, 128, 50] | 50         | 4500         | ReLu       | 1943.14       | 16.24%            |

## 議論

本研究の成果は、科学計算および科学機械学習タスクにおいて、推論に最適化された LLM が汎用 LLM よりも一貫して優れた性能を発揮することを示しています。これらの推論モデルは、問題の特性を認識し、適切な数学的または計算的手法を選択する点で、人間科学者のアプローチに類似した振る舞いを見せました。特に、スティッフ ODE の解法において陰的スキームを選択したり、PINN の L 字型領域のような非自明な境界条件に適応したりする能力は顕著でした。

しかし、これらの最先端 LLM にも限界があることが明らかになりました。多くのモデルは、特定のタスクにおいてコード生成にバグを含んでいたり、非効率的な実装をしたり、最適な性能を発揮するためには人間による修正やハイパーパラメータ調整が必要であることが判明しました。例えば、DeepONet のタスクでは、Claude モデルが高度な訓練戦略を提案したものの、その実装に繰り返しバグが見られたり、非効率なテンソル操作により訓練が遅延したりしました。また、一部のモデルは、Caputo 分数微分作用素の学習において、訓練データの生成方法に誤りがあり、未見の分数階数への一般化能力が低下しました。これらの課題は、LLM が流暢で一貫性のある会話を生成できる一方で、科学・工学分野で求められる厳密な精度と論理的一貫性を常に満たせるわけではないことを示しています。特に、ハルシネーション、数学的推論能力の低さ、自己矛盾といった問題は依然として存在し、高リスクな科学アプリケーションへの導入には慎重な評価が求められます。

今後の研究課題として、以下の点が挙げられます。

1.  **ベンチマーク手法の拡充:** 本研究で用いた課題に加え、さらに多様で複雑な科学計算および科学機械学習のベンチマーク問題を探求し、LLM の能力を多角的に評価する必要がある。
2.  **実世界問題への適用:** プロジェクトの異なる段階で一連の意思決定が必要とされる、より複雑な実世界の計算課題において LLM を評価することで、その応用可能性と限界を深く理解する。
3.  **信頼性と堅牢性の向上:** LLM が生成する解の正確性、信頼性、汎化能力を向上させるための研究を継続し、科学研究における「信頼できる」パートナーとしての LLM の発展を目指す。
4.  **人間と LLM の協調:** 研究者が日常業務において LLM アシスタントをいつ、どのように効果的かつ責任を持って使用するかについて、より情報に基づいた意思決定を行えるよう、具体的なガイダンスやツールの開発を進める。

本研究は、科学的発見を加速する LLM の大きな可能性を示す一方で、その限界と、科学コミュニティがこれらの強力なツールを効果的かつ安全に統合するために取り組むべき重要な課題を明確にしました。
