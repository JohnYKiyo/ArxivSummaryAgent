# DeepSeek vs. ChatGPT vs. Claude: A Comparative Study for Scientific Computing and Scientific Machine Learning Tasks

URL: http://arxiv.org/abs/2502.17764v2

発表年: 2025

著者:
Qile Jiang, Zhiwei Gao, George Em Karniadakis

---

## 導入

ChatGPT \cite{openai_gpt_4o_2024, openai_o3_mini_2025, openai_o3_mini_system_card_2024}、Claude \cite{anthropicclaude3.7sonnet}、そして最近ではDeepSeek \cite{deepseekai2024deepseekv3technicalreport}のような大規模言語モデル（LLM）は、トランスフォーマーアーキテクチャ\cite{waswani2017attention}に基づいた汎用人工知能（AI）チャットボットであり、インターネットからの大量のデータで訓練され、ユーザーの要求に基づいて会話を行うことを学習してきました。その多くの応用の中でも、科学研究、特にコーディング、数学、問題解決においてLLMを活用することへの関心が高まっています。この関心は、LLM開発における最近の急速な進歩を促しています。例えば、2025年1月31日、OpenAIはChatGPT o3-mini \cite{openai_o3_mini_2025}をリリースしました。これは、科学、数学、コーディングにおいて特に強みを発揮するとされる最新の推論モデルです。これは、DeepSeekが数学、コーディング、推論タスクにも特化した独自の推論モデルDeepSeek-R1 \cite{deepseekai2025deepseekr1incentivizingreasoningcapability}を発表したわずか数日後のことでした。ごく最近では、2025年2月24日、AnthropicもClaude 3.7 Sonnetを発表しました。これは、数学、物理学、指示に従うこと、コーディングにおけるパフォーマンスを向上させるための拡張思考モードを備えています\cite{anthropicclaude3.7sonnet}。これらのモデルは、ChatGPT-4o \cite{openai_gpt_4o_2024}、DeepSeek V3 \cite{deepseekai2024deepseekv3technicalreport}、Claude 3.5 Sonnet \cite{anthropicclaude3.5sonnet}などの以前の進歩の上に構築されており、科学分野でのパフォーマンス最適化を目指すLLM開発者間の新たな競争段階を示しています。

LLMは、情報合成\cite{antu2023using, li2024chatcite}やコーディングアシスタント\cite{nam2024using, liu2024exploring, chew2023llm}としてだけでなく、材料科学\cite{zhang2024honeycomb, hong2023chatgpt, cheng2023challenges}、遺伝学\cite{chatterjee2023can, mcgrath2024comparative}、医用画像処理\cite{srivastav2023chatgpt, hu2024advancing, yang2023impact}、計算流体力学\cite{chen2024metaopenfoam, sawada2011llm, herzog2002llm}を含む複雑なドメイン固有の問題を解決するためにも利用されるなど、科学研究の様々な領域で既にその可能性を示しています。LLMの科学ワークフローへの統合は、単なる情報検索ツールから、推論に基づくタスクを実行して人間の研究者を支援・補完できる自動エージェントへとその役割を拡大しました。しかし、これらの有望な応用にもかかわらず、LLMは依然として根本的な限界を示すことがあり、科学研究や計算における信頼性について懸念を引き起こしています\cite{hadi2023survey, rossi2024problems, rane2023contribution, pal2024ai, kunz2024properties}。特に、複雑な科学的問題を解決するよう指示された場合、幻覚的な推論\cite{li2023deceptive}、低い数学的認知レベル\cite{evans2024evaluating}、さらには自己矛盾\cite{mundler2023self}を生じることがあります。流暢さや一貫性が主要な評価基準である会話型AIタスクとは異なり、科学および工学の問題は精度、論理的一貫性、厳密な推論を要求します。LLMの限界は、そのため、高リスクな応用には不向きとなっています。

これらの課題を踏まえ、研究者たちは、例えば数学的推論\cite{liu2024mathbench, chernyshev2024u}、科学レビュー\cite{wu2023gpt, cai2024sciassess}、工学文書\cite{doris2025designqa}におけるLLMのスキルをベンチマークするなど、科学的および計算タスクにおけるLLMの能力を評価するための実験を設計してきました。一般的な言語モデルのベンチマークのみに頼るのではなく、LLMの正確性だけでなく、推論の深さ、信頼性、および研究レベルの科学的問題への汎化能力を評価するためには、ドメイン固有のモデルテストと評価が不可欠です。

LLM開発者間の競争が激化する中、本研究では、計算数学および科学的機械学習におけるモデルの比較テストを実施します。DeepSeek、ChatGPT、およびClaudeのLLMファミリーから、推論モデルと非推論モデルの両方に対して、意図的に巧妙な問題を作成し提示します。まず、数値積分、有限差分法（FDM）、有限要素法（FEM）を含む数値計算能力をテストします。機械学習手法が従来の数値手法に代わるものとして人気を集めているため\cite{thiyagalingam2022scientific, karniadakis2021physics}、画像認識、物理情報ニューラルネットワーク（PINN）\cite{raissi2019physics}を用いた物理情報学習、Deep Operator Network（DeepONet）\cite{deeponet}などのオペレーター学習手法を含む科学的機械学習タスクにおけるLLMの性能も評価します。様々なベンチマーク問題におけるモデルの性能と推論の決定を比較することで、本研究は、これらの人気のあるLLMが計算数学においてどの程度の性能を発揮するか、そしてそれらを研究に導入することのリスクと利点について洞察を提供します。

## 実験

本セクションでは、DeepSeek、OpenAI、Anthropicによって開発された6つの異なるLLMを、数値アルゴリズムと科学的機械学習における様々な困難なベンチマーク問題でテストすることにより評価します。検討対象のモデルは以下の通りです。

1.  DeepSeek V3 \cite{deepseekai2024deepseekv3technicalreport}: DeepSeekが開発した汎用モデルで、複数のドメインをカバーする広範なデータセットで訓練されています。科学タスクに明示的に特化しているわけではありませんが、その訓練には数学および工学関連データへの広範な露出が含まれています。
2.  DeepSeek R1 \cite{deepseekai2025deepseekr1incentivizingreasoningcapability}: DeepSeekが特に推論タスク、特に数学とコーディング向けに設計したモデルです。DeepSeek V3と比較して、R1は論理的一貫性と構造化された問題解決能力を向上させるために、追加の強化学習戦略でファインチューニングされています。OpenAIの推論モデルへの直接の競合として位置づけられています。
3.  ChatGPT 4o \cite{openai_gpt_4o_2024}: OpenAIの現在の主力モデルで、テキスト、コード、画像処理を含む汎用推論およびマルチモーダル機能向けに設計されています。最適化されたトランスフォーマーアーキテクチャを採用し、コーディング、数学、論理的推論におけるパフォーマンスを維持しながら、効率の向上とレイテンシの削減に重点を置いています。
4.  ChatGPT o3-mini-high \cite{openai_o3_mini_2025}: OpenAIのo3-miniモデルのバリアントで、コーディング、数学、科学における集中的な推論を必要とするタスク向けに最適化されています。「High」はより高い知能を意味します。そのより小さなサイズにもかかわらず、o3-mini-highは高度な推論技術を採用することで、より大きなモデルに匹敵するパフォーマンスを提供するとされています。
5.  Claude 3.7 Sonnet \cite{anthropicclaude3.7sonnet}: Anthropicの高性能モデルで、多用途なテキスト処理、コード生成、分析タスク向けに設計されています。強化された文脈理解能力を持つ最適化されたトランスフォーマーアーキテクチャを採用し、創作、プログラミング、知識集約型アプリケーションを含む様々なドメインで信頼性の高いパフォーマンスを提供するとされています。市場初の「ハイブリッド推論モデル」であると主張しています。
6.  Claude 3.7 Sonnet extended thinking \cite{anthropicclaude3.7sonnet}: AnthropicのSonnetモデルの強化版で、より深い分析的思考を可能にする追加の推論層を備えています。この拡張バージョンは、より徹底的な複雑な問題の評価を可能にする特殊な処理モードを組み込んでおり、多段階推論、数学的問題解決、論理的演繹を必要とするタスクのパフォーマンスを向上させながら、ベースモデルの多様性を維持します。

公平性を確保するため、すべてのチャットメモリとユーザーパーソナライズ設定は無効にされています。これにより、モデルが以前のコンテキストから恩恵を受けることを防ぎ、各クエリが独立して扱われることを保証します。さらに、LLMの応答時間は実際の評価速度ではなくサーバーのレイテンシに影響される可能性があるため、非推論モデル（ハイブリッド推論モデルであるClaude 3.7 Sonnetを含む）の応答時間は比較または報告しません。その代わりに、本稿では推論LLMの自己報告された推論時間のみを提示します。本評価の焦点は、生成された解の質、そして推論モデルについては、その推論プロセスと意思決定にあります。モデルの性能を区別するため、選択されたテスト問題は巧妙でありながら、LLMがその解法に用いるメソッドやパラメータに関して自身の決定を下す十分な柔軟性を残しています。ほとんどの問題は高度であり、通常は博士号レベルのもので、計算数学に対する深い理解と最近の研究の進歩への精通が求められます。テストされるコーディング言語は、科学的機械学習コミュニティで頻繁に使用されるフレームワークであるPythonのTensorFlow \cite{tensorflow2015-whitepaper}とJax \cite{jax2018github}が選択されました。

本セクションは2つの部分に分かれます。最初の部分では、応用数学における伝統的な数値計算法、特に有限差分法や有限要素法のような常微分方程式および偏微分方程式（PDE）の解法におけるモデルの知識をテストするための実験を実施します。2番目の部分では、MNISTデータセットからの数字学習、および異なる問題に対するPINNとDeepONetの実装を含む科学的機械学習タスクでモデルをテストします。
## 従来の数値計算法

本節では、従来の数値計算法や微分方程式の解法における様々な問題に取り組む、検討対象の6つの大規模言語モデル（LLM）について紹介します。これらのLLMが生成した解の性能を比較し、LLMが下した決定について議論します。

### スティッフODEの数値解法

ロバートソン問題（式\ref{Robertson ODE}）は、H. H. Robertsonによる化学反応を記述する、よく知られたスティッフな常微分方程式（ODE）系の例です\cite{robertson1966solution}。

$$
\frac{dx}{dt} = -0.04x + 10^4 yz, \\
\frac{dy}{dt} = 0.04x - 10^4 yz - 3 \times 10^7 y^2, \\
\frac{dz}{dt} = 3 \times 10^7 y^2.
$$

この問題は、初期条件 $x=1, y=z=0$ のもとで、3種類の物質 $x(t), y(t), z(t)$ の時間経過に伴う濃度をモデル化しています。特に $y(t)$ に関して、反応は非常に異なる時間スケールを持っています。このようなスティッフODEを陽的積分法で解くと、極めて小さな時間刻みを使用しない限り、不安定な挙動を示すことになります。陰解法（例：陰的ルンゲ＝クッタ法や後退差分公式（BDF））は、通常、これらの問題を解くのに適しています。

LLMがこの非常にスティッフな系を解くために適切な数値スキームを実装できるかを評価するため、以下のプロンプトを与えました。

```
以下のODE系をPythonでゼロから適切な数値計算法を実装して解いてください。
$$
\frac{dx}{dt} = -0.04x + 10^4 yz, \quad 
\frac{dy}{dt} = 0.04x - 10^4 yz - 3 \times 10^7 y^2,\quad
\frac{dz}{dt} = 3 \times 10^7 y^2. \quad
$$
時間区間 $t \in [0, 500]$、初期条件 $x=1, y=z=0$ です。
```

LLMの応答を**表\ref{tab:ODE_responses}**にまとめ、計算された解を**図\ref{fig:ODE_solution}**にプロットしました。参考として、ODE系は`scipy`のRadau IIA族5次陰的ルンゲ＝クッタ法（Radau）\cite{hairer1991ii}を用いて解かれました。

| モデル | 推論時間 (秒) | 手法 | 時間刻み | $L_2$誤差 ($x$) | $L_2$誤差 ($y$) | $L_2$誤差 ($z$) |
|---|---|---|---|---|---|---|
| DeepSeek V3 | N/A | RK4 | 0.01 | N/A | N/A | N/A |
| DeepSeek R1 | 249.0 | 後退オイラー法 | 0.1 | **$7.86 \times 10^{-6} \%$** | **$7.61 \times 10^{-5} \%$** | **$1.96 \times 10^{-4} \%$** |
| ChatGPT 4o | N/A | RK4 | 0.1 | N/A | N/A | N/A |
| ChatGPT o3-mini-high | 88.0 | 適応的時間刻み付き後退オイラー法 | 適応的 ($10^{-6}$ 初期) | $3.93 \times 10^{-6} \%$ | $9.40 \times 10^{-4} \%$ | $0.14 \%$ |
| Claude 3.7 Sonnet | N/A | 適応的時間刻み付きRK4 | 適応的 ($10^{-4}$ 初期) | **$1.24 \times 10^{-6} \%$** | $0.05 \%$ | $4.89 \times 10^{-4} \%$ |
| Claude 3.7 Sonnet extended thinking | 115.0 | 後退オイラー法 | 0.1 | $7.74\times 10^{-6} \%$ | **$7.53 \times 10^{-5} \%$** | **$1.94 \times 10^{-4}} \%$ |

*表: 各LLMがロバートソンODE系を解くために選択した数値計算法とパラメータ。誤差は、LLMの解と`scipy`のRadau法実装による参照解との相対差を示す。*

![ODE_solution.png](figures/ODE_solution.png)
*図: 各LLMが選択した数値スキームを用いて計算されたロバートソンODEの解。参考として、ODE系は`scipy`のRadau法を用いて解かれている。視覚化を向上させるため、解が収束するプロットでは$y$種の濃度は$10^4$倍にスケールされている。*

推論機能を持たないすべてのモデルは、4次ルンゲ＝クッタ（RK4）スキームを実装しました。DeepSeek V3とChatGPT 4oのバージョンは比較的大きな時間刻みを選択し、問題の解決に失敗して指数関数的に増大する解を出力しました。対照的に、ハイブリッド推論型のClaude 3.7 Sonnetは、時間刻み$\Delta t$の1ステップと、その半分の時間刻み（それぞれ$\Delta t/2$）の2つのハーフステップを比較して局所打ち切り誤差を推定する、適応的時間刻み付きRK4スキームを実装しました。推定された誤差が所定の許容範囲を下回る場合、ステップは受け入れられ、そうでない場合は拒否され、新しい（より小さな）時間刻みが計算されます。Claude 3.7 Sonnetの適応的手法は、他の2つの非推論型モデルよりもはるかに優れた精度をもたらしましたが、$y$種に関する誤差は依然として見られました。一方、すべての完全推論型モデルは後退オイラー法を実装しました。特に、ChatGPT o3-mini-highは同様の適応的時間刻み法を使用しました。全体として、Claude 3.7 Sonnet extended thinkingが最良の結果を達成しました。ChatGPT o3-mini-highは、最短の推論時間で満足のいく解を出力しました。

DeepSeek R1、ChatGPT o3-mini-high、Claude 3.7 Sonnet extended thinkingという3つの推論モデルすべてが、ODE系のスティッフ性を認識し、陰解法を選択したのに対し、非推論モデルはどれもそうしなかったことに注目します。推論プロセスの間、DeepSeek R1は次のように報告しました。

```
時間間隔が500まであり、方程式には1e4や3e7のようなかなり大きな係数の項があることを考えると、これはスティッフなシステムかもしれません。システムがスティッフである場合、後退オイラー法やRosenbrock法のようなスティッフシステム用に設計されたソルバーのような陰解法を使用する方が良いでしょう。
```

ChatGPT o3-mini-highは次のように報告しました。

```
スティッフなので、オイラー法やRK4のような陽的解法はうまく機能しないでしょう。陰的オイラー法のような陰解法、あるいは適応型ルンゲ＝クッタ法のような修正された陽的解法が必要になると思います。
```

同様に、Claude 3.7 Sonnet extended thinkingは次のように報告しました。

```
これはスティッフなODE系であり、係数が大きく異なることで特徴付けられます...スティッフな問題のために特別に設計された後退差分公式（BDF）メソッドを実装します。
```

この実験は、推論型LLMが問題を最初に分析し、実装する適切な方法を選択できるという点で、人間の科学者のアプローチに似ており、非推論型LLMに対する優れた性能を示しています。
### ポアソン方程式の有限差分法

この実験では、ポアソン方程式の偏微分方程式に対する有限差分法を実装するDeepSeek、ChatGPT、およびClaudeモデルの能力をテストします。以下のポアソン方程式を考察します \cite{buzbee1970direct}。

$$
    \left\{ \begin{array}{l}
          -\Delta u = f, \quad x \in \Omega  \\
          u|_{\partial \Omega} = 0,
    \end{array}
    \right.
$$

ここで、$\Omega = [-1,1]^{2}/[0,1]^{2}$ をL字型領域と設定します。右辺関数は $f(x, y) = 1$ とします。特に、LLMが非標準領域での方程式を解くことができるかをテストすることに興味があります。以下の質問がすべてのLLMに投げかけられました。

`有限差分法を用いて、L字型領域 $[-1,1]^{2}/[0, 1]^{2}$ における2Dポアソン方程式を、ゼロ境界条件と右辺 $f(x,y) = 1$ のもとで解いてください。コーディング言語は `Python` とします。`

ChatGPTを除いて、他のすべてのモデルはエラーのない実行可能なコードを提供しました。特に、DeepSeekは問題を解くために最も高度な反復法を採用しましたが、他のモデルは離散化と線形システムの解法に従来の有限差分法に依存しました。予測された解は*図1*にプロットされています。

*図1: ポアソン方程式に対する異なるモデルによる予測解。*

各LLMが使用した結果と方法は*表1*に示されています。全6モデルの中で、Claude 3.7 Sonnetだけが正しい結果を示しました。DeepSeek V3の実装は、反復法を使用しているため、結果を得るまでにかなりのCPU時間を要しました。DeepSeek-R1は、解の符号を間違えただけでなく、スケールも誤っており、性能が著しく悪くなっています。正しいClaude 3.7 Sonnetを除く他のすべてのモデルは、解の符号のみを誤っています。さらに、3つの推論モデルの中で、ChatGPT o3-mini-highはDeepSeek R1および拡張思考付きClaude 3.7 Sonnetよりもはるかに速く要求に応答しました。

*表1: ポアソン方程式の解法における異なるモデルの性能の要約。*

| | 推論時間 (s) | 方法 | グリッド | CPU時間 (s) | $L_2$誤差 |
|:---|:---|:---|:---|:---|:---|
| DeepSeek V3 | N/A | 反復法 | $50\times 50$ | 9.5 | 201% |
| DeepSeek R1 | 476.0 | FDM | $50\times 50$ | 0.6 | 203% |
| ChatGPT 4o | N/A | FDM | $50\times 50$ | 0.6 | 203% |
| ChatGPT o3-mini-high | 32.0 | FDM | $41\times 41$ | 0.5 | 207% |
| Claude 3.7 Sonnet | N/A | FDM | $50\times 50$ | 0.6 | **4.54%** |
| Claude 3.7 Sonnet extended thinking | 125.0 | FDM | $60\times 60$ | 0.7 | 202% |

### 振動梁方程式の有限要素法

この実験では、以下の梁方程式を考察します \cite{eliasson2016kam}。

$$
EI \frac{d^4 u}{dx^4} = \pi^4 x \sin \pi x - 4\pi^3 \cos \pi x, \quad 0 \leq x \leq L,
$$

対応する非同次境界条件は以下の通りです。

$$
\begin{aligned}
&u(0) = 0, \quad u''(0) = 2\pi,\\
&u(L) = 0, \quad u''(L) = -2\pi. 
\end{aligned}
$$

ここで、$EI = 1N/m^{2}$ は定数である曲げ剛性です。簡略化のため、$L = 1$ とします。*図2*にプロットされている真の解は、常微分方程式を解くことで得られ、次のようになります。

$$
    u(x) = x\sin(\pi x).
$$

*図2: 梁方程式の真の解。*

考慮中のすべてのLLMに、以下の質問が投げかけられました。

`ゼロから有限要素法を用いて、梁方程式を解いてください。
$$
\left\{\begin{array}{l}
    \frac{d^4 u}{dx^4} = \pi^4 x \sin \pi x - 4\pi^3 \cos \pi x, \quad 0 \leq x \leq 1,\\ 
    u(0) = 0, \quad u''(0) = 2\pi,\\ 
    u(1) = 0, \quad u''(1) = -2\pi.
\end{array}\right.
$$
コーディング言語は Python とします。`

実装の結果と詳細は*表2*に記載されています。各LLMによって予測された解は*図3*にプロットされています。我々の結果は、どのLLMも有限要素法を正確に適用して非常に正確な解を得ることができなかったことを示しています。

*表2: 梁方程式の解法における異なるモデルの性能の要約。*

| | 推論時間 (s) | 基底 | グリッド | $L_2$誤差 |
|:---|:---|:---|:---|:---|
| DeepSeek V3 | N/A | エルミート | 100 | 276300% |
| DeepSeek R1 | 790.0 | エルミート | 10 | 15.3% |
| ChatGPT 4o | N/A | エルミート | 50 | 205% |
| ChatGPT o3-mini-high | 31.0 | エルミート | 100 | 19.4% |
| Claude 3.7 Sonnet | N/A | エルミート | 100 | 957% |
| Claude 3.7 Sonnet extended thinking | 9.0 | エルミート | 20 | **13.7%** |

すべてのLLMがエルミート基底関数を用いて解を近似していることがわかります。さらに、弱形式を導出し、ガラーキン法を適用できることを認識しています。しかし、いずれも弱形式を導出するためのテスト空間を誤って選択しており、それが最終的に誤った結果につながっています。これらのモデルの中で、非推論モデルは推論モデルよりもはるかに性能が劣っており、著しく大きな$L_2$誤差を示しています。対照的に、他の実験の結果と一致して、推論モデルは問題をより効果的に解決し、Claude 3.7 Sonnet extended thinkingが最小の$L_2$誤差を達成しました。推論モデル間の応答時間では、ChatGPT o3-mini-highと拡張思考付きClaude 3.7 SonnetはDeepSeek R1よりもはるかに速く応答しました。

さらに、Claudeによる実装では、異なる数の基底関数を使用して手法の収束率をテストしました。結果として、Claude Sonnetモデルは数学的問題に対して人間科学者により近い技術的な推論を行い、どの手法が優れているかを検証するための包括的な結果を提供することが判明しました。

*図3: 梁方程式に対する異なるLLMによる予測解。*
### 積分に対する求積法
次に、特異点を持つ積分を数値的に計算するために、LLMが求積法を正しく適用する能力を評価します。以下の積分を考えます。

$$
I = \int_{0}^{1}\frac{e^{-x}}{x^{\frac{2}{3}}}dx.
$$

すべてのモデルに与えられた質問は次の通りです。

`特異点を持つ積分 $\int_{0}^{1}\frac{e^{-x}}{x^{\frac{2}{3}}}dx$ を、Pythonを使ってゼロから求積法で計算しなさい。`

すべてのLLMはエラーのない実装を提供しましたが、モデルによってアプローチは大きく異なりました。DeepSeek V3は`scipy.integrate`モジュールを直接使用して積分を計算しましたが、他のモデルは最初に特異点を除去するための変換を適用しました。具体的には、$x = t^{3}$ と置くと、次のようになります。

$$
I = \int_{0}^{1} e^{-t^3} \cdot \frac{3t^2}{(t^3)^{2/3}} dt
= \int_{0}^{1} 3e^{-t^3} t^{-2+2} dt
= 3 \int_{0}^{1} e^{-t^3} dt.
$$

この変換を適用した後、ほとんどのLLMは積分を近似するためにガウス求積法を用いました。特に、Claudeモデルは、収束率を評価するために、台形公式、シンプソン公式、直接ガウス求積法、および前述の変数変換を含む、より広範な積分技術を調査しました。図\ref{fig:comparison}に示すように、これらのアプローチの中で変数変換が最も速い収束を達成し、それらの性能を徹底的に比較しています。

さらに、拡張推論を用いたClaude 3.7 Sonnetの場合、変数変換に続いていくつかの求積法（ガウス求積法、適応シンプソン則、ロンバーグ積分など）がテストされ、異なる数値積分戦略の有効性に関する追加の洞察を提供しています。選択された手法とそれに関連する誤差の詳細な要約は、表\ref{tab:integral}にあります。

*図\ref{fig:comparison}: 積分に対してテストされた異なる手法の収束率*

| | 推論時間 (秒) | 手法 | ノード数 | $L_2$誤差 |
|---|---|---|---|---|
| DeepSeek V3 | N/A | Scipy | N/A | N/A |
| DeepSeek R1 | 584.0 | Gauss-Legendre | 10 | 3.74e-12 |
| ChatGPT 4o | N/A | Gauss-Legendre | 20 | 5.15e-13 |
| ChatGPT o3-mini-high | 74.0 | Gauss-Legendre | 50 | 5.21e-14 |
| Claude 3.7 Sonnet | N/A | Gauss-Legendre | 1000 | 機械精度 |
| Claude 3.7 Sonnet extended thinking | 37.0 | Gauss-Legendre | 1000 | 機械精度 |
*表\ref{tab:integral}: 積分における異なるモデルの性能の概要*

全体として、DeepSeek V3を除いて、すべてのモデルが同等の高い性能を達成し、ユーザーの要求に正しく従うことができました。これらは特異点を特定し、求積法を使用する前に正しく変換を適用することができました。Claudeモデルは、異なる手法のより包括的な比較を提供し、このような科学計算タスクの分析においてより洗練されています。

## 科学機械学習

このセクションでは、画像認識、物理情報機械学習、オペレータ学習手法など、科学機械学習における様々なタスクでLLMをテストします。

### MNIST数字予測

科学技術における多くの問題は、画像データの分析と分類を必要とします。MNIST \cite{deng2012mnist}データセットは、画像認識モデルの評価における確立されたベンチマークであるため、テスト問題として選択されました。この実験では、すべてのLLMに次のプロンプトが与えられました。

`MNISTデータセットを学習するためのCNNをTensorFlowで実装しなさい。高い精度と計算効率の両方を目指して、適切なアーキテクチャとハイパーパラメータを選択しなさい。`

目標は、LLMがどのようにして高い精度を達成することと計算コストを節約することの間のトレードオフをバランスさせるかを評価することです。生成された応答は表\ref{tab:MNIST}にまとめられています。すべてのテストはQuadro RTX 6000 GPUで実施されました。

| モデル | 推論時間 (秒) | アーキテクチャ | エポック数 | 時間 (秒) | テスト精度 | 早期停止 |
|---|---|---|---|---|---|---|
| DeekSeek V3 | N/A | 畳み込み層(32)<br>最大プーリング層<br>畳み込み層(64)<br>最大プーリング層<br>畳み込み層(64)<br>全結合層(64)<br>全結合層(10) | 5 | 21.30 | 98.96% | N/A |
| DeepSeek R1 | 129.0 | 畳み込み層(32)<br>最大プーリング層<br>畳み込み層(64)<br>最大プーリング層<br>全結合層(128)<br>ドロップアウト層(0.5)<br>全結合層(10) | 20 | 21.23 | 99.11% | はい |
| ChatGPT 4o | N/A | 畳み込み層(32)<br>最大プーリング層<br>畳み込み層(64)<br>最大プーリング層<br>ドロップアウト層(0.5)<br>全結合層(128)<br>全結合層(10) | 10 | 21.85 | **99.31%** | N/A |
| ChatGPT o3-mini-high | 8.0 | 畳み込み層(32)<br>畳み込み層(64)<br>最大プーリング層<br>全結合層(128)<br>全結合層(10) | 10 | 21.18 | 98.84% | N/A |
| Claude 3.7 Sonnet | N/A | 畳み込み層(32)<br>最大プーリング層<br>畳み込み層(64)<br>最大プーリング層<br>全結合層(64)<br>ドロップアウト層(0.5)<br>全結合層(10) | 10 | 21.30 | 98.98% | はい |
| Claude 3.7 Sonnet extended thinking | 38.0 | 畳み込み層(32)<br>最大プーリング層<br>畳み込み層(64)<br>最大プーリング層<br>全結合層(64)<br>ドロップアウト層(0.5)<br>全結合層(10) | 10 | 21.33 | 99.14% | はい |
*表\ref{tab:MNIST}: MNISTデータセット学習のためにDeekSeek、ChatGPT、Claudeによって生成されたモデルの比較。「畳み込み層($n$)」は$n$チャネルの2D畳み込み層を意味し、「全結合層($n$)」は$n$個のニューロンを持つ全結合層を意味し、「ドロップアウト層($p$)」は確率$p$のドロップアウトを意味します。*

結果は、この比較的標準的で単純な問題に対して、すべてのモデルが同等の訓練時間と高いテスト精度を達成できることを示しています。ClaudeモデルとDeepSeek R1の両方は、過学習を防ぐために検証損失の変化に応じてモデルの訓練を早期に停止させる可能性がある早期停止基準を実装しました。推論モデルの中で、ChatGPT o3-mini-highが最も速い推論時間を示しました。
### 物理情報ニューラルネットワーク
本セクションでは、ニューラルネットワークの能力を用いてPDEを解くフレームワークである物理情報ニューラルネットワーク（PINNs）~\cite{raissi2019physics} を用いたPDEの求解におけるLLMの性能を検証します。解くべきポアソン方程式は次式で与えられます。

$$
-\Delta u(x,y) = 1, \quad (x, y)\in [-1,1]^{2}/[0,1]^{2}
$$

これはゼロディリクレ境界条件を伴います。全てのモデルに課された質問は以下の通りです。

`PINNを用いて、L字型領域 $[-1,1]^{2}/[0, 1]^{2}$ における2次元ポアソン方程式を、ゼロ境界条件および右辺 $f(x,y) = 1$ で解きなさい。コーディング言語はJaxを用いること。`

全てのモデルがエラーのあるコードを生成しました。問題は、JAXにおける出力の入力に対する勾配を計算するための`grad`関数の使用にありました。`grad`関数はスカラー出力関数にのみ有効であるため、誤って使用するとエラーを引き起こす可能性があります。これを修正した後、全てのコードはスムーズに動作しました。異なるモデルが生成したコードの性能は、表 \ref{tab:PINNs}にまとめられています。

| | 推論時間 (s) | ネットワーク | 学習データ | エポック | 学習時間 (s) | 活性化関数 | $L_{2}$ 誤差 |
|---|---|---|---|---|---|---|---|
| DeepSeek V3 | N/A | [2, 20, 20, 20, 1] | 1000 | 5000 | 7.90 | Tanh | 929% |
| DeepSeek R1 | 417.0 | [2, 50, 50, 50, 50, 1] | 512 | 10000 | 13.80 | Tanh | 54.7% |
| ChatGPT 4o | N/A | [2, 64, 64, 64, 64, 1] | 5000 | 5000 | 15.23 | Tanh | 169% |
| ChatGPT o3-mini-high | 15.0 | [2, 64, 64, 64, 1] | 200 (毎エポック) | 5000 | 1740.00 | Tanh | 5.31% |
| Claude 3.7 Sonnet | N/A | [2, 32, 32, 32, 32,1] | 2000 | 10000 | 12.10 | Tanh | **4.25%** |
| Claude 3.7 Sonnet extended thinking | 38.0 | [2, 32, 32, 32, 1] | 5000 | 1000 | 19.00 | Tanh | 322% |

*表: ポアソン方程式を解く6つのPINNモデルのネットワークアーキテクチャ、ハイパーパラメータ、および$L_2$予測誤差。アーキテクチャ[2,20,20,20,1]は、3つの隠れ層（各20ニューロン）、入力次元2、出力次元1を持つ全結合ニューラルネットワークを表します。*

*図: L字型領域におけるポアソン方程式を解くために異なるLLMによって生成されたPINNからの予測解。*

表 \ref{tab:PINNs}にまとめられた結果に基づくと、フル推論モデルであるChatGPT o3-mini-highとハイブリッド推論モデルであるClaude 3.7 Sonnetは、他のモデルと比較して正しい予測を提供し、著しく低い$L_2$誤差を達成しています。これらの結果は、L字型領域でポアソン方程式を解く際に、推論モデルが解の複雑な振る舞いをより正確に捉えるだけでなく、問題領域における自明でない変更にもより柔軟に適応することを示しています。

通常、元の問題領域内で学習する非推論モデルとは対照的に、DeepSeek R1もまた、適切な境界点を生成することでL字型境界を認識し、適応する能力を示しています。この適応戦略は、モデルに推論能力を組み込むことで得られる汎化性能と応答性の向上を強調しています。

さらに注目すべきは、推論時間の違いです。表 \ref{tab:PINNs}に示すように、DeepSeek R1が417秒というかなりの推論時間を要する一方で、他の2つの推論ベースモデルははるかに高速に反応しています。ChatGPT o3-mini-highはわずか15秒、Claude 3.7 Sonnet extended thinkingは38秒の推論時間で動作しています。

さらに、ChatGPT o3-mini-highは、エポックごとに新しいサンプルを生成する必要があるため、1000秒を超える学習時間を必要としますが、それが達成する優れた精度は追加の計算努力を正当化します。全体として、表 \ref{tab:PINNs}の発見は、推論LLMによって生成されたPINNが問題領域の複雑さに対し、より柔軟な応答を提供し、非推論モデルを大幅に上回るという強力な証拠を提供します。
### 原始関数演算子を学習するためのDeepONet

Deep Operator Network (DeepONet) \cite{deeponet} は、演算子の普遍近似定理 \cite{chen_universal_thm_neural_operator} に基づき、データを用いて関数空間間のマッピングを学習するために設計されたニューラル演算子です。ドメイン $D \subset \mathbb{R}^n$ で定義された入力関数 $u: x \mapsto u(x)$ と、ドメイン $\Omega \subset \mathbb{R}^m$ で定義された出力関数 $v: y \mapsto v(y)$ が与えられたとき、目標は以下の演算子を近似することです。

$$
    \mathcal{G}: \mathcal{U} \ni u \mapsto v \in \mathcal{V}.
$$

DeepONetのアーキテクチャは2つのコンポーネントで構成されます。1つは座標 $y \in \Omega$ を入力とするトランクネットワーク、もう1つは $m$ 個の任意のセンサー位置 $ \{x_1, x_2, \dots, x_m\} $ でサンプリングされた入力関数 $u$ の離散化バージョンを入力とするブランチネットワークです。DeepONetの出力は $v(y) = \sum_{i = 1}^r b_i(\boldsymbol{u}) t_i(y) + b_0 \approx \mathcal{G}(u)(y) $ で与えられます。ここで、$b_i$ と $t_i$ はそれぞれブランチネットワークとトランクネットワークの出力であり、$b_0$ は学習可能なバイアス項です。

![DeepONet_diagram.png](figures/DeepONet_diagram.png)
*図1: DeepONetのアーキテクチャ: ブランチネットワークは入力関数 $u$ をエンコードし、トランクネットワークは出力関数 $v$ が評価される座標 $y$ をエンコードする。*

演算子学習におけるLLMの知識を最初にテストするため、私たちは $[0,1]$ のドメインで一般的な原始関数演算子 $G(u): u(x) \mapsto s(x) = \int_0^x u(\tau) d\tau$ を学習するタスクを検討します。すべての6つのLLMに対して、以下のプロンプトが与えられました。

```
Deep Operator Network (DeepONet) をTensorflowで実装し、原始関数演算子を学習しなさい。高い精度と低い計算コストの両方を目指すために、適切なアーキテクチャとハイパーパラメータを選択しなさい。モデルが幅広い種類の関数に汎化できるようにしなさい。
```

なお、プロンプトでは入力関数空間の選択は意図的に曖昧に残されています。したがって、LLMは関数空間から戦略的にサンプリングし、これらの関数の原始関数をDeepONetのトレーニングターゲットとして使用するために生成する必要があります。データ生成タスクに対するモデルの応答は非常に異なりました。

1.  DeepSeek V3: 入力関数は、NumPyで一様乱数として点ごとに単純に生成されます。その後、NumPyの累積和 (`cumsum`) を使用して関数が数値的に積分されます。
2.  DeepSeek R1: 入力関数は以下の4つの種類からランダムに生成されます。
    1.  6次多項式 $u(x) = c_0 + c_1x + \cdots c_6 x^6$ で、係数は $[-2,2]$ の範囲でランダムに選択されます。
    2.  三角関数 $u(x) = A \sin(\omega x) + B \cos (\omega x)$ で、$A, B$ は $[-2,2]$ からランダムに選択され、$\omega$ は $[1,5]$ からランダムに選択されます。
    3.  指数関数 $u(x) = A \exp(Bx)$ で、$A, B$ は $[-1,1]$ からランダムに選択されます。
    4.  1、2、3の混合関数 $u(x) = c_1 x^2 + c_2 \sin(\omega x) + c_3 \exp(x)$ で、$c_i$ は $[-1,1]$ からランダムに選択され、$\omega$ は $[1,5]$ からランダムに選択されます。すべての原始関数は解析的に計算されます。
3.  ChatGPT 4o: 入力関数は、定数項のない5次多項式 $u(x) = c_1x + \cdots c_5 x^5$ として生成され、係数 $c_1$ は $[-1,1]$ からランダムに選択されます。原始関数は解析的に計算されます。
4.  ChatGPT o3-mini-high: 入力関数は、3つのモードを持つフーリエ級数 $u(x) = \sum_{i=1}^3 A_i \sin(2\pi i x) + B_i \cos(2 \pi i x)$ として生成され、$A_i, B_i$ は $[-1,1]$ からランダムに選択されます。原始関数は `scipy.integrate.cumtrapz` を使用した累積台形則により数値的に計算されます。
5.  Claude 3.7 Sonnet: DeepSeek R1と同様に、入力関数は以下のいずれかとして生成されます。
    1.  フーリエ級数 $u(x) = \sum_{i=1}^N A_i \sin(2\pi i x) + B_i \cos(2 \pi i x)$ で、$A, B$ は $[-1,1]$ からランダムに選択され、$N$ は $\{2,3,4,5,6\}$ からランダムに選択されます。
    2.  次数 $d$ が $\{2,3,4,5\}$ からランダムに選択され、係数が $[-1,1]$ からランダムに選択される多項式。
    3.  三角関数 $u(x) = A \sin(B x) + C \cos(2x)$ で、$A, B, C$ は $[0.5, 2]$ からランダムに選択されます。すべての原始関数は解析的に計算されます。
6.  Claude 3.7 Sonnet with extended thinking: 同様に、入力関数は以下のいずれかとして生成されます。
    1.  次数 $d$ が $\{0, 1, 2,3,4,5\}$ からランダムに選択され、係数が $[-2,2]$ からランダムに選択される多項式。
    2.  正弦関数 $u(x) = A \sin(B x)$ で、$A, B$ は $[0.5, 3]$ からランダムに選択されます。
    3.  指数関数 $u(x) = A \exp(Bx)$ で、$A, B$ は $[0.5,2]$ からランダムに選択されます。
    4.  混合関数 $u(x) = A \sin( x) + B x^2$ で、$A, B$ は $[0.5,2]$ からランダムに選択されます。
    5.  ガウス関数 $u(x) = a \exp\left(-\left(\frac{x - \mu}{\sigma}\right)^2\right)$ で、$a \sim \text{Unif}[1, 3]$、$\mu \sim \text{Unif}[-0.5, 0.5]$、$\sigma \sim \text{Unif}[0.2, 0.5]$。ガウス関数の原始関数は `scipy.integrate.quad` を使用して数値的に計算されます。
    6.  有理関数 $u(x) = \frac{A}{1 + B x^2}$ で、$a, b$ は $[0.5,2]$ からランダムに選択されます。ガウス関数以外の関数の原始関数は解析的に計算されます。

Claude 3.7 Sonnet with extended thinkingは、多様な関数タイプを混合した最も複雑なトレーニングデータセットを生成していることがわかります。驚くべきことに、元のDeepONetの論文 \cite{deeponet} で採用されている戦略であるガウス過程 (GRF) を使用してトレーニング関数を生成することを検討したモデルはありませんでした。

トレーニングを進めるにあたり、LLMによって生成されたコードのいくつかのバグは手動で修正されました。経験的に、繰り返しの実験を通して、Claudeが生成したコードは、他のモデルと比較して、この特定のタスクにおいてより単純ではないバグが多いことがわかりました。いくつかの主要なバグは以下の通りです。

1.  DeepSeek V3のコードには、ブランチネットワークとトランクネットワークの出力間のドット積におけるテンソル次元の不一致によるエラーがあり、これは手動で修正されました。
2.  ChatGPT 4oのコードは、トランクネットワークの入力次元を1（従属変数の次元）ではなく100（評価点の数）に誤って設定していました。正しい次元が手動で設定され、それに合わせてテンソル形状が修正されました。
3.  Claude 3.7 Sonnetは、`KerasTensor` がKeras操作ではなくTensorFlow関数 (`tf.reshape`) に渡されるバグを繰り返し出力しました。これはKerasの関数型APIのルールに違反していました。このバグは、関数をカスタムKerasレイヤーでラップすることで修正されました。
4.  Claude 3.7 Sonnet with extended thinkingは、Claude 3.7 Sonnetと同じ間違いを犯しました。

モデルのアーキテクチャとトレーニング結果を以下の表にまとめます。両方のClaudeモデルは、より伝統的なReLU活性化関数ではなく、$\text{Swish}(x) = x \cdot \frac{1}{1 + e^{-x}}$ と定義されるSwish活性化関数の使用を採用しており、滑らかさや非単調性などの利点を挙げてその選択を正当化しています。Claudeモデルは、$L^2$重み正則化、学習率スケジューリング、ドロップアウト学習などの高度なトレーニング手法も使用しました。

| モデル | 推論時間 (s) | バグなし？ | ブランチネットワーク | トランクネットワーク | データ数 | 活性化関数 | バッチサイズ | エポック数 | 早期停止？ |
|---|---|---|---|---|---|---|---|---|---|
| DeekSeek V3 | N/A | No | [100, 128, 128, 128] | [1, 128, 128, 128] | 10,000 | ReLu | 32 | 100 | No |
| DeepSeek R1 | 214.0 | Yes | [100,100,100,50] | [1,100,100,50] | 5,000 | ReLu | 32 | 200 | Yes |
| ChatGPT 4o | N/A | No | [100, 64, 64, 64, 64] | [1, 64, 64, 64, 64] | 10,000 | ReLu | 32 | 100 | No |
| ChatGPT o3-mini-high | 11.0 | Yes | [100,100,100,100] | [1,100,100,100] | 1,000 | ReLu | 64 | 50 | No |
| Claude 3.7 Sonnet | N/A | No | [100, 64, 128, 64, 32] | [1, 32, 64, 32, 32] | 800 | Swish | 64 | 50 | Yes |
| Claude 3.7 Sonnet extended thinking | 79.0 | No | [100, 256, 128, 64, 50] | [1, 64, 64, 50] | 2,000 | Swish | 128 | 150 | Yes |
*表1: 原始関数演算子を学習するDeepONetモデルのネットワークアーキテクチャ、ハイパーパラメータ、および$L_2$予測誤差。ネットワークアーキテクチャ表記は、表\ref{tab:PINNs}と同じ規則に従う。*

モデルが異なるデータセットでトレーニングされているため、私たちはそのパフォーマンスを評価するために、普遍的で一般的なテストセットを構築しました。テストセットは、長さスケールが $0.05, 0.1, 0.2, 0.5$ のガウス過程 (GRF) によって生成された関数で構成されています。データの例を図\ref{fig:anti-derivatives}に示します。各モデルの結果を以下の表に示します。長さスケールが小さい関数は、ほとんどのモデルにとって予測がより困難です。DeepSeek R1が最良の結果を示し、DeepSeek V3はすべての長さスケールで意味のある予測を行うことができませんでした。Claudeが生成したDeepONetのテストパフォーマンスが低いのは、トレーニングデータではなく、ハイパーパラメータの選択によるものです。Claude 3.7 Sonnet with extended thinkingからの同じデータを使用し、正則化、学習率スケジューラー、ドロップアウト層を削除し、ReLU活性化関数に切り替え、ChatGPT o3-mini-highに合わせて各層のニューロンを100に増やしました。これらの変更により、簡素化されたモデルは両方のChatGPTモデルに匹敵するパフォーマンスを示しました。これは、Claudeが優れた戦略を生成する一方で、最適なパフォーマンスのためにはその実装が人間の介入とハイパーパラメータチューニングを依然として必要とすることを示しています。

![Derivative_plots.png](figures/Derivative_plots.png)
*図2: 原始関数演算子を学習するDeepONetのテストデータ。異なる長さスケールのガウス過程 (GRF) で生成されたもの。*

| モデル | 長さスケール $0.5$ | 長さスケール $0.2$ | 長さスケール $0.1$ | 長さスケール $0.05$ |
|---|---|---|---|---|
| DeekSeek V3 | 49.4% | 50.6% | 51.6% | 47.5% |
| DeepSeek R1 | **0.0008**% | **0.2**% | **1.9**% | **5.7**% |
| ChatGPT 4o | 0.05% | 1.0% | 3.4% | 6.1% |
| ChatGPT o3-mini-high | 0.06% | 1.0% | 3.5% | 6.2% |
| Claude 3.7 Sonnet | 0.35% | 4.17% | 12.69% | 180.41% |
| Claude 3.7 Sonnet extended thinking | 0.22% | 2.05% | 5.0% | 7.04% |
*表2: 異なる長さスケールのGRFから生成されたテストデータセットにおけるDeepONetモデルの相対$L_2$誤差。多様なトレーニングデータとエラーのない実装により、DeepSeek R1が最良の結果を達成した。Claudeモデルは高度なドロップアウト手法、正則化、学習率スケジューリング、Swish活性化関数を使用したものの、これらがなければ、モデルはより良いパフォーマンスを示し、ChatGPTの結果に匹敵したであろう。*
### DeepONetによるCaputo分数微分演算子の学習

より高度なテスト問題として、任意の分数次数を持つCaputo分数微分演算子の学習タスクを提示します。1次元Caputo分数微分演算子$G(u)(y,\alpha)$は、以下のように定義されます。
$$
G(u)(y,\alpha) : \; u(x) \mapsto s(y,\alpha) = \frac{1}{\Gamma(1-\alpha)} \int_{0}^{y} (y-\tau)^{-\alpha} u'(\tau) d\tau, \\
y \in [0,1], \, \alpha \in (0,1)
$$
ここで、$\alpha$は任意の分数次数であり、$u'$は$u$の1階微分を表します。

全てのLLMには、以下のプロンプトが提示されました。

```
TensorflowでDeep Operator Network (DeepONet) を実装し、1次元Caputo分数微分演算子G(u)(y,α)を学習してください。この演算子は以下のように定義されます。
$$
G(u)(y,\alpha) : u(x) \mapsto s(y,\alpha) = \frac{1}{\Gamma(1-\alpha)} \int_{0}^{y} (y-\tau)^{-\alpha} u'(\tau) d\tau, \\
y \in [0,1], \, \alpha \in (0,1)
$$
ここで、$\alpha$は任意の分数次数であり、$u'$は$u$の1階微分を表します。関数$u$は長さスケール0.2のガウス過程からサンプリングされます。
```

このテストでは、入力関数空間は指定されていますが、LLMは自身の訓練用およびテスト用データセットを生成する責任を負います。データ生成のためには、入力関数を数値的に微分および積分する必要があります。各LLMが微分と積分に使用した手法を表1にまとめます。ほとんどのモデルは有効な数値スキームを実装しましたが、ChatGPT 4oとClaude 3.7 Sonnetの両方が、積分ステップで同様の誤りを犯したことに注意してください。具体的には、正しい積分領域$[0,y]$ではなく、誤って$[0,1]$で積分を計算していました。これにより、$y=\tau$のときに項$(y-\tau)^{-\alpha}$が特異点となるため、ゼロ除算エラーが発生しました。このバグは手動で修正され、台形則が積分に採用されました。

| モデル                        | $u'$の微分                 | 積分                                |
| :---------------------------- | :--------------------------- | :---------------------------------- |
| DeepSeek V3                 | 1次有限差分                  | 台形則 (\texttt{numpy})             |
| DeepSeek R1                 | 1次有限差分                  | 左リーマン和 (ゼロから実装)         |
| ChatGPT 4o                  | 1次有限差分                  | 不正確な範囲                        |
| ChatGPT o3-mini-high        | 中心差分                     | 台形則 (\texttt{numpy})             |
| Claude 3.7 Sonnet           | 中心差分                     | 不正確な範囲                        |
| Claude 3.7 Sonnet extended thinking | 中心差分                     | 台形則 (\texttt{numpy})             |

*表1: 訓練用およびテスト用データの生成のために、各LLMが1次元Caputo分数微分を計算するために使用した手法。*

私たちは特に、LLMが分数次数$\alpha$をDeepONetに正しくエンコードする方法を知っているかどうかに注目しています。分数次数$\alpha$は通常、他のDeepONetアプリケーションには現れず、この特定のタスクにおけるLLMの知識は限られている可能性があります。オリジナルのDeepONet論文[deeponet]では、次数$\alpha$は評価座標$y$とともにトランクネットワークに入れられています。注目すべきは、6つのLLMすべてが$\alpha$をトランクに正しく配置したことです。しかし、繰り返しの実験において、DeepSeekとChatGPTのモデルはすべて、入力テンソルの定式化で同じ間違いを一貫して犯しました。具体的には、各評価点$y$を異なる$\alpha$と誤ってペアリングし、入力を次のように構造化しました。
$$
\text{Trunk net input} = \begin{bmatrix} 
y_1 & \alpha_1 \\ 
y_2 & \alpha_2 \\ 
\vdots & \vdots \\ 
y_N & \alpha_N 
\end{bmatrix}
$$
しかし、各分数微分次数$\alpha$に対して、出力関数が計算される複数の評価点$\{y_1, y_2, \ldots, y_n\}$が存在するべきです。$(y_i, \alpha_i)$の異なるペアを使用すると、各$\alpha_i$に対して1つの点$y_i$で分数微分を評価することになり、DeepONetが$[0,1]$ドメイン全体での微分の完全な表現を学習するのを妨げます。その結果、DeepSeekまたはChatGPTが生成した元の実装で、人間の介入なしに訓練されたDeepONetは、テスト時に150%以上の$l^2$相対誤差を生じました。このような不正確な定式化での比較は意味のある洞察を提供しないため、DeepSeekおよびChatGPTのコードを手動で修正し、トランクネットワークへの空間入力$y$が、区間$[0.1, 0.9]$からランダムに選択された分数次数$\alpha$ごとに100の異なる点で評価されるようにしました。

両方のClaudeモデルは、全ての実験においてトランクネットワークの入力を正しく定式化しました。しかし、彼らはネットワークに渡す前に、ブランチネットワークとトランクネットワークの入力テンソルの最初の次元を一致させるために一貫してタイル化していました。これにより、2つのブランチを通過した後、それらのドット積を直接計算できることは保証されましたが、このタイル化は不必要でコストがかかるものでした。なぜなら、ドット積はTensorFlowの\texttt{einsum}や行列乗算で簡単に実装できるからです。過剰なタイル化は非常に大きなテンソルサイズにつながり、訓練を遅らせました。

さらに、DeepSeek V3は、ユーザーの要求が$\alpha \in (0,1)$を任意として指定しているにもかかわらず、固定された分数次数$\alpha = 0.5$のみを使用してDeepONetを誤って訓練しました。同様に、拡張思考を持つClaude 3.7 Sonnetは、全ての900の訓練関数に対して5つの固定された分数次数、$\alpha = 0.17, 0.25, 0.34, 0.65, 0.73$を使用し、合計で4500の訓練サンプルサイズとなりました。訓練データで分数次数を固定すると、DeepONetが見知らぬ分数次数に対して汎化する能力が低下しました。正しいアプローチは、各訓練サンプルに対して$\alpha$をランダムにサンプリングすることです。しかし、これらの間違いはLLMの意思決定の一部であるため、手動で修正されませんでした。

最後に、GRF生成関数（長さスケール0.2、ランダムな次数$\alpha \in [0.1, 0.9]$）で全てのDeepONetを訓練およびテストしました。結果は、モデルアーキテクチャおよびハイパーパラメータとともに表2に報告されています。

| モデル                                 | 推論時間 (秒) | バグなし？ | ブランチネットワーク         | トランクネットワーク          | エポック数 | 訓練データ数 | 活性化関数 | 訓練時間 (秒) | テスト$L_2$誤差 |
| :------------------------------------- | :---------- | :--------- | :-------------------------- | :--------------------------- | :------- | :--------- | :--------- | :---------- | :------------ |
| DeepSeek V3                          | N/A         | いいえ     | [100, 128, 128, 128]        | [2, 128, 128, 128]          | 100      | 1000       | ReLu       | 11.87       | 177.19%       |
| DeepSeek R1                          | 426.0       | いいえ     | [100, 128, 128, 128]        | [2, 128, 128, 128]          | 50       | 1000       | ReLu       | 6.58        | 26.82%        |
| ChatGPT 4o                           | N/A         | いいえ     | [100, 50, 50, 50, 100]      | [2, 50, 50, 50, 100]        | 100      | 1000       | ReLu       | 13.54       | 19.49%        |
| ChatGPT o3-mini-high                 | 23.0        | いいえ     | [100, 128, 128, 100]        | [2, 128, 128, 100]          | 100      | 1000       | ReLu       | 10.91       | 18.41%        |
| Claude 3.7 Sonnet                    | N/A         | いいえ     | [100, 128, 128, 40]         | [2, 128, 128, 40]           | 200      | 900        | ReLu       | 41.74       | **5.59**%     |
| Claude 3.7 Sonnet extended thinking | 109.0       | いいえ     | [100, 128, 128, 128, 50]    | [2, 128, 128, 128, 50]      | 50       | 4500       | ReLu       | 1943.14     | 16.24%        |

*表2: 1次元Caputo分数微分を学習するDeepONetモデルのネットワークアーキテクチャ、ハイパーパラメータ、および$L_2$予測誤差。表記は表[PINNs]に従う。この表に報告されているテスト$L_2$誤差は、元のコードのバグを手動で修正した後の修正を反映している。Claude 3.7 Sonnetは最良の結果を達成したが、コード内の非効率なテンソル操作により遅い。DeepSeek V3および拡張思考を持つClaude 3.7 Sonnetのパフォーマンスは、異なる訓練サンプル全体で分数次数$\alpha$を固定して使用することにより妨げられている。*

この表に報告されているテスト$L_2$誤差は、元のコードのバグを手動で修正した後の修正を反映しています。DeepSeek V3のテスト誤差は非常に高く、これは単一の分数次数で訓練されているため、汎化に失敗していることを示しています。拡張思考を持つClaude 3.7 Sonnetも同じ間違いを犯していますが、そのより大きなサンプルサイズと5つの異なる$\alpha$の選択により、より良いパフォーマンスに貢献しています。全体として、ハイブリッド推論モデルであるClaude 3.7 Sonnetが最良の結果を達成しましたが、コード内の非効率なテンソル操作により遅いです。さらに、以前の実験結果と同様に、ほとんどのモデルは100エポック以下しか訓練されておらず、適切な収束には不十分です。実際、私たちの実験では、エポック数を1000に増やすだけで、まったく同じモデルで相対誤差が1桁に減少しました。
# Summary
本研究では、DeepSeek (DeepSeek V3, DeepSeek R1)、OpenAI (ChatGPT 4o, ChatGPT o3-mini-high)、Anthropic (Claude 3.7 Sonnet, Claude 3.7 Sonnet with extended thinking) から最近公開された大規模言語モデルの性能を、科学計算および科学機械学習における多様なタスクで評価・比較しました。我々は、数値積分、有限差分法 (FDM)、有限要素法 (FEM) などの高度な数学的推論とドメイン固有の知識を必要とする困難な問題、および画像認識、物理情報ニューラルネットワーク (PINN)、深層作用素ネットワーク (DeepONet) などの科学機械学習タスクを設計しました。私たちの焦点は、適切な数値手法またはニューラルネットワークアーキテクチャを選択し、それらをPythonで正しく実装するモデルの能力を評価することにありました。結果として、推論最適化モデルであるDeepSeek R1、ChatGPT o3-mini-high、および拡張思考機能を備えたClaudeは、問題の性質を認識し、それに応じて意思決定する能力において一貫して優れた性能を示しました。実際、これらのモデルの選択の多くは、科学計算と科学機械学習の両方において、我々がこれらの問題を解決する際に行うであろう選択と類似していました。対照的に、汎用モデルであるDeepSeek V3およびChatGPT 4oは、問題の特定の特性（例えば剛性）やユーザーからの指示（例えばゼロから実装すること）を考慮しないことがあり、その結果、不正確な解を生成しました。

本研究は、科学研究におけるLLM活用の実用性の高まりと、数学、コーディング、科学計算のタスク向けにモデルの改良を続けるDeepSeek、OpenAI、Anthropic間の競争激化を浮き彫りにしています。また、本研究の知見は、これらの最先端LLMの限界も露呈しました。これは、対象分野に不慣れな人間の研究者を混乱させる可能性のある、あいまいな、または不正確な応答によって示されました。本研究の知見は、科学的問題解決のためのLLMの継続的な改善の必要性を強調しています。今後の研究では、追加のベンチマーク手法を検討し、プロジェクトの異なる段階で一連の意思決定が要求される、より複雑な現実世界の計算課題においてLLMを評価するべきです。そうすることで、研究者は、日々の業務でLLMアシスタントをいつ、どのように効果的かつ責任を持って使用するかについて、より情報に基づいた意思決定を行えるようになるでしょう。

## Acknowledgments
この研究は、ONR Vannevar Bush Faculty Fellowship (N00014-22-1-2795) の支援を受けました。ブラウン大学Crunch Groupのメンバーの皆様には、彼らのご提案と見識に感謝いたします。
