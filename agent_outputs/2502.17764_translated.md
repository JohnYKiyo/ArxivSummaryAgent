# DeepSeek vs. ChatGPT vs. Claude: A Comparative Study for Scientific Computing and Scientific Machine Learning Tasks

URL: http://arxiv.org/abs/2502.17764v2

発表年: 2025

著者:
Qile Jiang, Zhiwei Gao, George Em Karniadakis

---

\section{はじめに}

ChatGPT \cite{openai_gpt_4o_2024, openai_o3_mini_2025, openai_o3_mini_system_card_2024}、Claude \cite{anthropicclaude3.7sonnet}、そして最近では DeepSeek \cite{deepseekai2024deepseekv3technicalreport} のような大規模言語モデル（LLM）は、Transformer アーキテクチャ \cite{waswani2017attention} に基づく汎用人工知能（AI）チャットボットであり、インターネットから大量のデータを用いて学習され、ユーザーの要求に基づいて会話を行うことを学習してきました。その数多くの応用の中でも、科学研究、特にコーディング、数学、問題解決において LLM を活用することへの関心が高まっています。この関心は、LLM 開発における近年の急速な進歩を牽引してきました。例えば、2025 年 1 月 31 日には、OpenAI が最新の推論モデルである ChatGPT o3-mini \cite{openai_o3_mini_2025} をリリースしました。これは、科学、数学、コーディングにおいて特に優れた能力を発揮するとされています。これに先立つ数日前には、DeepSeek が独自の推論モデルである DeepSeek-R1 \cite{deepseekai2025deepseekr1incentivizingreasoningcapability} を発表し、これもまた数学、コーディング、推論タスクに特化しています。ごく最近では、2025 年 2 月 24 日に Anthropic も Claude 3.7 Sonnet を発表しました。これは、数学、物理学、指示に従うタスク、コーディングにおけるパフォーマンスを向上させるための拡張思考モードを備えています \cite{anthropicclaude3.7sonnet}。
これらのモデルは、ChatGPT-4o \cite{openai_gpt_4o_2024}、DeepSeek V3 \cite{deepseekai2024deepseekv3technicalreport}、Claude 3.5 Sonnet \cite{anthropicclaude3.5sonnet} などのこれまでの進歩を基盤としており、科学分野での性能最適化を目指す LLM 開発者間の新たな競争段階を示しています。

LLM はすでに、情報の統合 \cite{antu2023using, li2024chatcite} やコーディングアシスタント \cite{nam2024using, liu2024exploring, chew2023llm} としてだけでなく、材料科学 \cite{zhang2024honeycomb, hong2023chatgpt, cheng2023challenges}、遺伝学 \cite{chatterjee2023can, mcgrath2024comparative}、医用画像処理 \cite{srivastav2023chatgpt, hu2024advancing, yang2023impact}、計算流体力学 \cite{chen2024metaopenfoam, sawada2011llm, herzog2002llm} を含む複雑なドメイン固有の問題解決にも利用されるなど、科学研究の様々な領域で可能性を示してきました。科学的なワークフローへの LLM の統合は、その役割を単なる情報検索ツールから、人間の研究者を支援し補完するために推論ベースのタスクを実行できる自動エージェントへと拡大させました。しかし、これらの有望な応用にもかかわらず、LLM は科学研究と計算における信頼性に関する懸念を引き起こす根本的な限界を依然として示すことがあります \cite{hadi2023survey, rossi2024problems, rane2023contribution, pal2024ai, kunz2024properties}。特に、複雑な科学的問題を解決するよう求められた場合、ハルシネーション（幻覚）による推論 \cite{li2023deceptive}、数学的認識能力の低さ \cite{evans2024evaluating}、さらには自己矛盾 \cite{mundler2023self} を生じることがあります。流暢さと一貫性が主要な評価基準となる会話型 AI タスクとは異なり、科学および工学の問題には精度、論理的一貫性、厳密な推論が求められます。したがって、LLM の限界は、高リスクなアプリケーションには不適格であるという結果をもたらしています。

これらの課題を考慮し、研究者たちは LLM の科学的および計算タスクにおける能力を評価するための実験を設計してきました。例えば、数学的推論 \cite{liu2024mathbench, chernyshev2024u}、科学論文レビュー \cite{wu2023gpt, cai2024sciassess}、および工学文書作成 \cite{doris2025designqa} における LLM のスキルをベンチマークしています。一般的な言語モデルのベンチマークのみに頼るのではなく、LLM の正確性だけでなく、推論の深さ、信頼性、および研究レベルの科学問題への汎化能力を評価するためには、ドメイン固有のモデルテストと評価が不可欠です。

LLM 開発者間の競争が激化する中、本研究では、計算数学および科学機械学習におけるモデルの比較テストを実施します。DeepSeek、ChatGPT、Claude の LLM ファミリーの推論モデルと非推論モデルの両方に対して、意図的に難しい問題を策定し、提示します。まず、数値積分、有限差分法（FDM）、有限要素法（FEM）を含む数値計算法における LLM の能力をテストします。機械学習手法が従来の数値的アプローチの代替手段として普及しているため \cite{thiyagalingam2022scientific, karniadakis2021physics}、画像認識、物理情報ニューラルネットワーク（PINN） \cite{raissi2019physics} による物理情報学習、および Deep Operator Network（DeepONet） \cite{deeponet} のような演算子学習手法を含む科学機械学習タスクにおける LLM の性能も評価します。様々なベンチマーク問題におけるモデルの性能と推論の決定を比較することで、本研究は、これらの一般的な LLM が計算数学においてどれほど優れた性能を発揮するか、また研究においてそれらを導入する際のリスクと利点についての洞察を提供します。

\section{実験}

本セクションでは、DeepSeek、OpenAI、および Anthropic によって開発された 6 つの異なる LLM を、数値アルゴリズムおよび科学機械学習における一連の挑戦的なベンチマーク問題でテストすることにより評価します。検討対象のモデルは以下の通りです。

1.  DeepSeek V3 \cite{deepseekai2024deepseekv3technicalreport}: DeepSeek によって開発された汎用モデルで、複数のドメインをカバーする広範なデータセットで訓練されています。科学タスクに明示的に特化しているわけではありませんが、その訓練には数学および工学関連のデータへの広範な曝露が含まれています。
2.  DeepSeek R1 \cite{deepseekai2025deepseekr1incentivizingreasoningcapability}: 数学やコーディングを含む推論タスクのために特別に設計された DeepSeek によって開発されたモデルです。DeepSeek V3 と比較して、R1 は論理的一貫性と構造化された問題解決能力を向上させるために、追加の強化学習戦略を用いて微調整されています。OpenAI の推論モデルに対する直接の競合として位置づけられています。
3.  ChatGPT 4o \cite{openai_gpt_4o_2024}: OpenAI の現在の主力モデルであり、テキスト、コード、画像処理を含む汎用的な推論およびマルチモーダル機能を備えています。最適化された Transformer アーキテクチャを採用し、コーディング、数学、論理推論における性能を維持しながら、効率の向上とレイテンシの削減に重点を置いています。
4.  ChatGPT o3-mini-high \cite{openai_o3_mini_2025}: ChatGPT o3-mini-high は、OpenAI の o3-mini モデルのバリアントであり、コーディング、数学、科学における集中的な推論を必要とするタスク向けに最適化されています。「High」はより高い知能を意味します。そのサイズが小さいにもかかわらず、o3-mini-high は高度な推論技術を採用することにより、より大きなモデルに匹敵する性能を提供するとされています。
5.  Claude 3.7 Sonnet \cite{anthropicclaude3.7sonnet}: Anthropic の高性能モデルであり、多目的なテキスト処理、コード生成、分析タスクのために設計されています。強化された文脈理解能力を備えた最適化された Transformer アーキテクチャを採用しており、クリエイティブライティング、プログラミング、知識集約型アプリケーションなど、様々なドメインで信頼性の高い性能を提供するとされています。市場初の「ハイブリッド推論モデル」であると主張されています。
6.  Claude 3.7 Sonnet extended thinking \cite{anthropicclaude3.7sonnet}: Anthropic の Sonnet モデルの強化版であり、より深い分析的思考を可能にする追加の推論レイヤーを備えています。この拡張バージョンは、多段階推論、数学的問題解決、論理的演繹を必要とするタスクのパフォーマンスを向上させるために、複雑な問題をより徹底的に評価できる特殊な処理モードを組み込んでおり、基本モデルの汎用性を維持しています。

公平性を確保するため、すべてのチャット履歴およびユーザーによるパーソナライズ設定は無効にされました。これにより、モデルが以前の文脈から恩恵を受けることを防ぎ、各クエリが独立して扱われることが保証されます。さらに、LLM の応答時間は、実際の評価速度よりもサーバーのレイテンシに影響される可能性があるため、非推論モデル（ハイブリッド推論の Claude 3.7 Sonnet を含む）の応答時間の比較や報告は行いません。その代わりに、本稿では推論 LLM の自己報告された推論時間のみを提示します。本評価の焦点は、生成された解答の質、そして推論モデルについては、その推論プロセスと意思決定です。モデルの性能を差別化するため、選択されたテスト問題は難解である一方で、LLM がその解答においてどのような手法とパラメータを使用するかについて、独自の決定を下す十分な柔軟性を残しています。ほとんどの問題は高度であり、通常は博士課程レベルであり、計算数学に関する深い理解と、最近の研究の進歩に関する知識が求められます。テストされるコーディング言語は、科学機械学習コミュニティで頻繁に使用されるフレームワークである Python の TensorFlow \cite{tensorflow2015-whitepaper} および Jax \cite{jax2018github} が選択されました。

本セクションは 2 つのパートに分かれています。最初のパートでは、応用数学における従来の数値計算法、特に有限差分法や有限要素法などの常微分方程式および偏微分方程式（PDE）の解法を実装するモデルの知識をテストするための実験を行います。2 番目のパートでは、MNIST データセットからの数字学習、および異なる問題に対する PINN と DeepONet の実装を含む科学機械学習タスクでモデルをテストします。

## 従来の数値計算法

このセクションでは、従来の数値計算法や微分方程式の解法における様々な問題に取り組む、検討中の 6 つの LLM を紹介します。それらが生成した解の性能を比較し、LLM が下した決定について議論します。

### スティッフ ODE の数値解法

ロバートソン問題（式\ref{Robertson ODE}）は、H. H. ロバートソンによる化学反応を記述するスティッフな ODE 系のよく知られた例です\cite{robertson1966solution}。

$$
\begin{align}
    \frac{dx}{dt} & = -0.04x + 10^4 yz, \\
\frac{dy}{dt} & = 0.04x - 10^4 yz - 3 \times 10^7 y^2, \\
\frac{dz}{dt} & = 3 \times 10^7 y^2.
\end{align}
$$

この問題は、初期条件 $x=1, y=z=0$ のもとで、3 つの化学種 $x(t), y(t), z(t)$ の時間経過に伴う濃度をモデル化しています。反応には非常に異なる時間スケールがあり、特に $y(t)$ について顕著です。このようなスティッフな ODE を陽的積分法で解くと、極めて小さなステップサイズを用いない限り不安定な挙動を示します。陰的ルンゲ＝クッタ法や後退差分式（BDF）などの陰的解法は、通常これらの問題を解くのに適しています。

LLM がこの非常にスティッフなシステムを解くために適切な数値スキームを実装できるかを評価するため、以下のプロンプトを与えました。

```
以下のODEシステムをPythonでスクラッチから解くための適切な数値手法を実装してください。
$$
\frac{dx}{dt} = -0.04x + 10^4 yz, \quad
\frac{dy}{dt} = 0.04x - 10^4 yz - 3 \times 10^7 y^2,\quad
\frac{dz}{dt} = 3 \times 10^7 y^2. \quad
$$
時間区間 $t \in [0, 500]$、初期条件 $x=1, y=z=0$ で解いてください。
```

LLM の応答は表\ref{tab:ODE_responses}にまとめられ、計算された解は図\ref{fig:ODE_solution}にプロットされています。参考のために、この ODE システムは`scipy`を用いて、5 次の Radau IIA 族の陰的ルンゲ＝クッタ法（Radau）で解かれています\cite{hairer1991ii}。

| モデル                     | 推論時間 (秒) | 手法                              | ステップサイズ          | $L_2$誤差 ($x$)              | $L_2$誤差 ($y$)              | $L_2$誤差 ($z$)              |
| -------------------------- | ------------- | --------------------------------- | ----------------------- | ---------------------------- | ---------------------------- | ---------------------------- |
| DeepSeek V3                | N/A           | RK4                               | 0.01                    | N/A                          | N/A                          | N/A                          |
| DeepSeek R1                | 249.0         | 後退オイラー法                    | 0.1                     | **$7.86 \times 10^{-6} \%$** | **$7.61 \times 10^{-5} \%$** | **$1.96 \times 10^{-4} \%$** |
| ChatGPT 4o                 | N/A           | RK4                               | 0.1                     | N/A                          | N/A                          | N/A                          |
| ChatGPT o3-mini-high       | 88.0          | 適応的時間刻み付き 後退オイラー法 | 適応的 ($10^{-6}$ 初期) | $3.93 \times 10^{-6} \%$     | $9.40 \times 10^{-4} \%$     | $0.14 \%$                    |
| Claude 3.7 Sonnet          | N/A           | 適応的時間刻み付き RK4            | 適応的 ($10^{-4}$ 初期) | **$1.24 \times 10^{-6} \%$** | $0.05 \%$                    | $4.89 \times 10^{-4} \%$     |
| Claude 3.7 Sonnet 拡張推論 | 115.0         | 後退オイラー法                    | 0.1                     | $7.74\times 10^{-6} \%$      | **$7.53 \times 10^{-5} \%$** | **$1.94 \times 10^{-4} \%$** |

_表: 各 LLM がロバートソン ODE 系を解くために選択した数値手法とパラメータ。誤差は、LLM の解と`scipy`の Radau 法による参照解との相対差を表す。_

![ODE_solution.png](figures/ODE_solution.png)
_図: 各 LLM が選択した数値スキームを用いて計算されたロバートソン ODE の解。参考として、ODE システムは`scipy`を用いて Radau 法でも解かれている。視認性を高めるため、$y$種の濃度は解が収束するプロットでは$10^4$倍されている。_

全ての非推論モデルは、4 次ルンゲ＝クッタ（RK4）スキームを実装しました。DeepSeek V3 と ChatGPT 4o のバージョンは比較的大きなステップサイズを選択したため、問題を解くことができず、指数関数的に増大する解を生成しました。対照的に、ハイブリッド推論の Claude 3.7 Sonnet は、ステップサイズ$\Delta t$の完全な 1 ステップと 2 つの半ステップ（それぞれ$\Delta t/2$のサイズ）を比較して局所打ち切り誤差を推定する、適応的時間刻み付き RK4 スキームを実装しました。推定された誤差が所定の許容誤差以下であれば、ステップは受け入れられ、そうでなければ拒否され、新しい（より小さな）時間ステップが計算されます。Claude 3.7 Sonnet の適応的手法は、他の 2 つの非推論モデルよりもはるかに優れた精度を示しましたが、$y$種に関する誤差はまだ見られました。一方、全ての完全推論モデルは後退オイラー法を実装しました。特に、ChatGPT o3-mini-high は同様の適応的時間刻み手法を使用しました。全体として、Claude 3.7 Sonnet の拡張推論が最良の結果を達成しました。ChatGPT o3-mini-high は最短の推論時間で満足のいく解を生成しました。

DeepSeek R1、ChatGPT o3-mini-high、Claude 3.7 Sonnet の拡張推論の 3 つの推論モデルは全て、ODE システムのスティッフ性を認識し、陰的解法を選択したのに対し、全ての非推論モデルはこれに失敗したことを特筆すべきです。推論プロセス中に、DeepSeek R1 は次のように報告しました。

```
時間区間が500までで、方程式には1e4や3e7のようなかなり大きな係数の項があるため、これはスティッフシステムかもしれません。システムがスティッフである場合、後退オイラー法のような陰的解法や、Rosenbrock法のようなスティッフシステム用に設計されたソルバーを使用する方が良いでしょう。
```

ChatGPT o3-mini-high は次のように報告しました。

```
スティッフなので、オイラー法やRK4のような陽的解法はうまく機能しません。陰的オイラー法のような陰的解法か、適応的ルンゲ＝クッタ法のような修正された陽的解法が必要になると思います。
```

同様に、Claude 3.7 Sonnet の拡張推論は次のように報告しました。

```
これはスティッフなODE系であり、係数の桁違いの差によって特徴付けられます...スティッフ問題のために特別に設計された後退差分式（BDF）を実装します。
```

この実験は、推論 LLM がまず問題を分析し、適切な実装方法を選択することで、人間科学者のアプローチに似た方法を取るため、非推論 LLM よりも優れた性能を示すことを実証しています。

### ポアソン方程式に対する有限差分法

この実験では、ポアソン方程式に対する有限差分法を実装する DeepSeek、ChatGPT、および Claude モデルの能力をテストします。以下のポアソン方程式を考慮します\cite{buzbee1970direct}。

$$
    \left\{ \begin{array}{l}
          -\Delta u = f, \quad x \in \Omega  \\
          u|_{\partial \Omega} = 0,
    \end{array}
    \right.
$$

ここで、$\Omega = [-1,1]^{2}/[0,1]^{2}$ を L 字型領域と設定します。右辺関数は $f(x, y) = 1$ とします。我々は、LLM が非標準領域上の問題を解くことができるかを特にテストすることに関心があります。以下の質問がすべての LLM に投げかけられました。

`ゼロ境界条件および右辺 $f(x,y) = 1$ を持つL字型領域 $[-1,1]^{2}/[0, 1]^{2}$ における2Dポアソン方程式を有限差分法を用いて解いてください。コーディング言語は `Python` です。`

ChatGPT を除いて、他のすべてのモデルはエラーなく実行可能なコードを提供しました。特筆すべきは、DeepSeek が問題を解くために最も高度な反復法を採用したのに対し、他のモデルは離散化と線形システムの解法に従来の有限差分法に依拠した点です。予測された解は*図\ref{fig:poisson_solution}*にプロットされています。

_図\ref{fig:poisson_solution}: ポアソン方程式に対する異なるモデルによる予測解。_

各 LLM が使用した結果と手法は*表\ref{tab:possion}*に示されています。全 6 つのモデルのうち、唯一正しい結果を示したのは Claude 3.7 Sonnet でした。DeepSeek V3 の実装は、反復法を使用しているため、結果を得るまでに CPU 時間が大幅に長くなりました。DeepSeek-R1 は、解の符号を間違えているだけでなく、スケールも誤っており、より悪い性能につながっています。正しい Claude 3.7 Sonnet を除く他のすべてのモデルは、解の符号を間違えているだけです。さらに、3 つの推論モデルの中で、ChatGPT o3-mini-high は DeepSeek R1 および Claude 3.7 Sonnet（拡張思考）よりもはるかに速く要求に応答しました。

_表\ref{tab:possion}: ポアソン方程式を解く際の異なるモデルの性能概要。_

|                                     | 推論時間 (s) | 手法   | グリッド      | CPU 時間 (s) | $L_2$誤差 |
| ----------------------------------- | ------------ | ------ | ------------- | ------------ | --------- |
| DeepSeek V3                         | N/A          | 反復法 | $50\times 50$ | 9.5          | 201%      |
| DeepSeek R1                         | 476.0        | FDM    | $50\times 50$ | 0.6          | 203%      |
| ChatGPT 4o                          | N/A          | FDM    | $50\times 50$ | 0.6          | 203%      |
| ChatGPT o3-mini-high                | 32.0         | FDM    | $41\times 41$ | 0.5          | 207%      |
| Claude 3.7 Sonnet                   | N/A          | FDM    | $50\times 50$ | 0.6          | **4.54%** |
| Claude 3.7 Sonnet extended thinking | 125.0        | FDM    | $60\times 60$ | 0.7          | 202%      |

### 振動梁方程式に対する有限要素法

この実験では、梁方程式を考慮します\cite{eliasson2016kam}。

$$
EI \frac{d^4 u}{dx^4} = \pi^4 x \sin \pi x - 4\pi^3 \cos \pi x, \quad 0 \leq x \leq L,
$$

対応する非同次境界条件は以下の通りです。

$$
\begin{align*}
&u(0) = 0, \quad u''(0) = 2\pi,\\
&u(L) = 0, \quad u''(L) = -2\pi.
\end{align*}
$$

ここで、$EI = 1N/m^{2}$ は定数の曲げ剛性です。簡略化のため、$L = 1$ とします。*図\ref{fig:beam_true_solution}*にプロットされている真の解は、常微分方程式を解くことにより得られ、以下の通り与えられます。

$$
    u(x) = x\sin(\pi x).
$$

_図\ref{fig:beam_true_solution}: 梁方程式の真の解。_

検討中のすべての LLM には以下の質問が投げかけられました。

`ゼロから有限要素法を用いて梁方程式を解いてください。

$$
\left\{\begin{array}{l}
    \frac{d^4 u}{dx^4} = \pi^4 x \sin \pi x - 4\pi^3 \cos \pi x, \quad 0 \leq x \leq 1,\\
    u(0) = 0, \quad u''(0) = 2\pi,\\
    u(1) = 0, \quad u''(1) = -2\pi.
\end{array}\right.
$$

コーディング言語は Python です。
`

実装の詳細と結果は*表\ref{tab:beam}*に示す通りです。各 LLM によって予測された解は*図\ref{fig:fem_solution}*にプロットされています。我々の結果は、いずれの LLM も有限要素法を正確に適用して非常に高精度な解を得ることはできなかったことを示しています。

_表\ref{tab:beam}: 梁方程式を解く際の異なるモデルの性能概要。_

|                                     | 推論時間 (s) | 基底       | グリッド | $L_2$誤差 |
| ----------------------------------- | ------------ | ---------- | -------- | --------- |
| DeepSeek V3                         | N/A          | エルミート | 100      | 276300%   |
| DeepSeek R1                         | 790.0        | エルミート | 10       | 15.3%     |
| ChatGPT 4o                          | N/A          | エルミート | 50       | 205%      |
| ChatGPT o3-mini-high                | 31.0         | エルミート | 100      | 19.4%     |
| Claude 3.7 Sonnet                   | N/A          | エルミート | 100      | 957%      |
| Claude 3.7 Sonnet extended thinking | 9.0          | エルミート | 20       | **13.7%** |

我々は、すべての LLM が解を近似するためにエルミート基底関数を使用していることを観測しました。さらに、それらは弱形式を導出し、ガラーキン法を適用できることを認識しています。しかし、いずれのモデルも弱形式を導出するために誤った試行空間を選択しており、それが最終的な誤った結果につながっています。これらのモデルの中で、非推論モデルは推論モデルよりもはるかに性能が悪く、著しく大きな$L_2$誤差を示しています。対照的に、他の実験結果と一致して、推論モデルはより効果的に問題を解決し、Claude 3.7 Sonnet（拡張思考）が最も小さい$L_2$誤差を達成しました。推論モデル間の応答時間では、ChatGPT o3-mini-high と Claude 3.7 Sonnet（拡張思考）は DeepSeek R1 よりもはるかに速く応答しました。

さらに、Claude による実装は、異なる数の基底関数を用いた手法の収束率をさらにテストしました。Claude Sonnet モデルは、数学的な問題に対して人間科学者により近い技術的な推論を行い、どの手法が優れているかを検証するための包括的な結果を提供することが判明しました。

_図\ref{fig:fem_solution}: 梁方程式に対する異なる LLM からの予測解。_

### 積分における求積法

次に、特異点を持つ積分の数値計算において、LLM が求積法を正確に適用する能力を評価します。以下の積分を考えます。

$$
    I = \int_{0}^{1}\frac{e^{-x}}{x^{\frac{2}{3}}}dx.
$$

すべてのモデルに提示された質問は以下の通りです。

`バックグラウンドからPythonを用いて積分 $\int_{0}^{1}\frac{e^{-x}}{x^{\frac{2}{3}}}dx$ を求積法で計算しなさい。`

すべての LLM がエラーのない実装を提供しましたが、異なるモデルのアプローチは大きく異なりました。DeepSeek V3 は`scipy.integrate`モジュールを直接使用して積分を計算しましたが、他のモデルは最初に特異点を除去するための変換を適用しました。具体的には、$x = t^{3}$と設定すると、以下が得られます。

$$
    I = \int_{0}^{1} e^{-t^3} \cdot \frac{3t^2}{(t^3)^{2/3}} dt
= \int_{0}^{1} 3e^{-t^3} t^{-2+2} dt
= 3 \int_{0}^{1} e^{-t^3} dt.
$$

この変換を適用した後、ほとんどの LLM は積分を近似するためにガウス求積法を使用しました。特に、Claude モデルは、台形則、シンプソン則、直接ガウス求積法、そして前述の変数変換を含む、より広範な積分技術を調査し、収束率を評価しました。図\ref{fig:comparison}に示すように、これらのアプローチの中で変数変換が最速の収束を達成し、それらの性能の徹底的な比較を提供しました。

さらに、Claude 3.7 Sonnet の拡張推論の場合、変数変換に続いていくつかの求積法、すなわちガウス求積法、適応シンプソン則、ロンバーグ積分がテストされ、異なる数値積分戦略の有効性に関する追加の洞察が得られました。選択された手法とその関連誤差の詳細は、表\ref{tab:integral}で確認できます。

<br>

_図: 積分でテストされた異なる手法の収束率_

<br>

_表: 積分における異なるモデルの性能の要約_

|                                     | 推論時間 (秒) | 手法           | ノード数 | $L_2$誤差  |
| :---------------------------------- | :-----------: | :------------- | :------: | :--------: |
| DeepSeek V3                         |      N/A      | Scipy          |   N/A    |    N/A     |
| DeepSeek R1                         |     584.0     | Gauss-Legendre |    10    |  3.74e-12  |
| ChatGPT 4o                          |      N/A      | Gauss-Legendre |    20    |  5.15e-13  |
| ChatGPT o3-mini-high                |     74.0      | Gauss-Legendre |    50    |  5.21e-14  |
| Claude 3.7 Sonnet                   |      N/A      | Gauss-Legendre |   1000   | マシン精度 |
| Claude 3.7 Sonnet extended thinking |     37.0      | Gauss-Legendre |   1000   | マシン精度 |

<br>

全体として、DeepSeek V3 を除いて、すべてのモデルは比較的に高い性能を達成し、ユーザーのリクエストに正確に従うことができました。これらは特異点を特定し、求積法を使用する前に変換を正しく適用することができました。Claude モデルは異なる手法のより包括的な比較を提供し、このような科学計算タスクの分析においてより洗練されています。

## 科学的機械学習

このセクションでは、画像認識、物理情報機械学習、およびオペレータ学習手法における科学的機械学習の様々なタスクで LLM をテストします。

### MNIST 数字予測

科学および工学における多くの問題は、画像データの分析と分類を必要とします。MNIST \cite{deng2012mnist}データセットは、画像認識モデルを評価するための確立されたベンチマークであるため、テスト問題として選択されました。この実験のすべての LLM には、以下のプロンプトが与えられました。

`TensorFlowでCNNを実装し、MNISTデータセットを学習させなさい。高い精度と計算効率の両方を目標に、適切なアーキテクチャとハイパーパラメータを選択しなさい。`

目標は、LLM がどのようにして高精度を達成することと計算コストを節約することのトレードオフをバランスさせるかを評価することです。生成された応答は表\ref{tab:MNIST}にまとめられています。すべてのテストは Quadro RTX 6000 GPU で実施されました。

<br>

_表: MNIST データセット学習のために DeepSeek、ChatGPT、Claude が生成したモデルの比較。「Convolution($n$)」は$n$チャンネルの 2 次元畳み込み層を意味し、「Dense($n$)」は$n$個のニューロンを持つ全結合層を意味し、「Dropout($p$)」は確率$p$のドロップアウトを意味する。_

| モデル                              | 推論時間 (秒) | アーキテクチャ                                                                                              | エポック数 | 時間 (秒) | テスト精度 | 早期停止 |
| :---------------------------------- | :-----------: | :---------------------------------------------------------------------------------------------------------- | :--------: | :-------: | :--------: | :------: |
| DeepSeek V3                         |      N/A      | Convolution(32)<br>MaxPooling<br>Convolution(64)<br>MaxPooling<br>Convolution(64)<br>Dense(64)<br>Dense(10) |     5      |   21.30   |   98.96%   |   N/A    |
| DeepSeek R1                         |     129.0     | Convolution(32)<br>MaxPooling<br>Convolution(64)<br>MaxPooling<br>Dense(128)<br>Dropout(0.5)<br>Dense(10)   |     20     |   21.23   |   99.11%   |   Yes    |
| ChatGPT 4o                          |      N/A      | Convolution(32)<br>MaxPooling<br>Convolution(64)<br>MaxPooling<br>Dropout(0.5)<br>Dense(128)<br>Dense(10)   |     10     |   21.85   | **99.31%** |   N/A    |
| ChatGPT o3-mini-high                |      8.0      | Convolution(32)<br>Convolution(64)<br>MaxPooling<br>Dense(128)<br>Dense(10)                                 |     10     |   21.18   |   98.84%   |   N/A    |
| Claude 3.7 Sonnet                   |      N/A      | Convolution(32)<br>MaxPooling<br>Convolution(64)<br>MaxPooling<br>Dense(64)<br>Dropout(0.5)<br>Dense(10)    |     10     |   21.30   |   98.98%   |   Yes    |
| Claude 3.7 Sonnet extended thinking |     38.0      | Convolution(32)<br>MaxPooling<br>Convolution(64)<br>MaxPooling<br>Dense(64)<br>Dropout(0.5)<br>Dense(10)    |     10     |   21.33   |   99.14%   |   Yes    |

<br>

結果は、この比較的標準的で単純な問題に対して、すべてのモデルが同等の学習時間と高いテスト精度を達成できることを示しています。Claude モデルと DeepSeek R1 の両方が早期停止基準を実装しており、これは過学習を防ぐために検証損失の変化に応じてモデルの学習を早期に停止する可能性があります。推論モデルの中で、ChatGPT o3-mini-high が最も速い推論時間を示しました。

### 物理情報ニューラルネットワーク

本節では、ニューラルネットワークの能力を用いて偏微分方程式（PDEs）を解くためのフレームワークである物理情報ニューラルネットワーク（PINNs）\cite{raissi2019physics}における LLM の性能を検証します。解くべきポアソン方程式は、次式で与えられます。

$$
-\Delta u(x,y) = 1, \quad (x, y)\in [-1,1]^{2}/[0,1]^{2}
$$

ゼロディリクレ境界条件を伴います。すべてのモデルに課された質問は以下の通りです。

`PINNsを用いて、L字型領域$[-1,1]^{2}/[0, 1]^{2}$における2Dポアソン方程式を、ゼロ境界条件と右辺$f(x,y) = 1$で解きなさい。プログラミング言語はJaxです。`

すべてのモデルがエラーのあるコードを生成しました。問題は、JAX の`grad`関数が入力に対する出力の勾配を計算するために使用されたことにあり、`grad`はスカラー出力関数に対してのみ有効であるため、誤って使用するとエラーを引き起こす可能性がありました。これを修正した後、すべてのコードはスムーズに動作しました。異なるモデルによって与えられたコードの性能は、表\ref{tab:PINNs}に要約されています。

|                                     | 推論時間 (s) | ネットワーク           | 学習データ       | エポック | 学習時間 (s) | 活性化関数 | $L_{2}$誤差 |
| ----------------------------------- | ------------ | ---------------------- | ---------------- | -------- | ------------ | ---------- | ----------- |
| DeepSeek V3                         | N/A          | [2, 20, 20, 20, 1]     | 1000             | 5000     | 7.90         | Tanh       | 929%        |
| DeepSeek R1                         | 417.0        | [2, 50, 50, 50,50, 1]  | 512              | 10000    | 13.80        | Tanh       | 54.7%       |
| ChatGPT 4o                          | N/A          | [2, 64, 64, 64, 64, 1] | 5000             | 5000     | 15.23        | Tanh       | 169%        |
| ChatGPT o3-mini-high                | 15.0         | [2, 64, 64, 64, 1]     | 200 (毎エポック) | 5000     | 1740.00      | Tanh       | 5.31%       |
| Claude 3.7 Sonnet                   | N/A          | [2, 32, 32, 32, 32,1]  | 2000             | 10000    | 12.10        | Tanh       | **4.25%**   |
| Claude 3.7 Sonnet extended thinking | 38.0         | [2, 32, 32, 32, 1]     | 5000             | 1000     | 19.00        | Tanh       | 322%        |

_表: ポアソン方程式を解く 6 つの PINN モデルのネットワークアーキテクチャ、ハイパーパラメータ、および$L_2$予測誤差。アーキテクチャ[2,20,20,20,1]は、3 つの隠れ層を持ち、各層に 20 個のニューロン、入力次元 2、出力次元 1 を持つ全結合ニューラルネットワークを表す。_

_図: L 字型領域上のポアソン方程式を解くために、異なる LLM によって生成された PINN からの予測解。_

表\ref{tab:PINNs}に要約された結果に基づくと、完全推論モデルである ChatGPT o3-mini-high とハイブリッド推論モデルである Claude 3.7 Sonnet は、他のモデルと比較して、正確な予測を提供し、著しく低い$L_{2}$誤差を達成できます。これらの結果は、L 字型領域上のポアソン方程式を解く際に、推論モデルが解の複雑な振る舞いをより正確に捉えるだけでなく、問題領域の非自明な修正にもより柔軟に適応できることを示しています。

通常、元の問題領域内で学習する非推論モデルとは対照的に、DeepSeek R1 も適切な境界点を生成することで L 字型境界を認識し、適応する能力を示しています。この適応戦略は、モデルに推論能力を組み込むことで得られる汎化能力と応答性の向上を強調しています。

さらに注目すべきは、推論時間の違いです。表\ref{tab:PINNs}に示されているように、DeepSeek R1 は 417 秒というかなりの推論時間を必要とする一方で、他の 2 つの推論ベースのモデルははるかに速く応答します。ChatGPT o3-mini-high はわずか 15 秒の推論時間で動作し、Claude 3.7 Sonnet with extended thinking は 38 秒です。

さらに、ChatGPT o3-mini-high は、エポックごとに新しいサンプルを生成する必要があるため、1000 秒以上の学習時間を必要としますが、それが達成する優れた精度は、追加の計算労力を正当化します。全体として、表\ref{tab:PINNs}の調査結果は、推論 LLM によって生成された PINN が、問題領域の複雑さに対してより柔軟な応答を提供し、非推論モデルを大幅に上回るという説得力のある証拠を提供しています。

### DeepONet による逆導関数作用素の学習

Deep Operator Network (DeepONet) \cite{deeponet} は、作用素の汎用近似定理 \cite{chen_universal_thm_neural_operator} に基づき、データを用いて関数空間間のマッピングを学習するように設計されたニューラル作用素です。定義域 $D \subset \mathbb{R}^n$ 上で定義された入力関数 $u: x \mapsto u(x)$ と、定義域 $\Omega \subset \mathbb{R}^m$ 上で定義された出力関数 $v: y \mapsto v(y)$ が与えられたとき、目標は以下の作用素を近似することです。

$$
\mathcal{G}: \mathcal{U} \ni u \mapsto v \in \mathcal{V}.
$$

DeepONet のアーキテクチャは 2 つのコンポーネントで構成されます。1 つは座標 $y \in \Omega$ を入力とするトランクネットワーク、もう 1 つは $m$ 個の任意のセンサー位置 $\{x_1, x_2, \dots, x_m\}$ でサンプリングされた、入力関数 $u$ の離散化バージョンを入力とするブランチネットワークです。DeepONet の出力は $v(y) = \sum_{i = 1}^r b_i(\boldsymbol{u}) t_i(y) + b_0 \approx \mathcal{G}(u)(y) $ として与えられます。ここで、$b_i$ と $t_i$ はそれぞれブランチネットワークとトランクネットワークの出力であり、$b_0$ は学習可能なバイアス項です。

![DeepONet_diagram.png](figures/DeepONet_diagram.png)
_図 1: DeepONet のアーキテクチャ: ブランチネットワークは入力関数 $u$ をエンコードし、トランクネットワークは出力関数 $v$ が評価される座標 $y$ をエンコードします。_

作用素学習における LLM の知識を最初にテストするために、我々は $[0,1]$ の領域における一般的な逆導関数作用素 $G(u): u(x) \mapsto s(x) = \int_0^x u(\tau) d\tau$ の学習タスクを検討します。6 つの LLM すべてに以下のプロンプトが与えられました。

```
TensorflowでDeep Operator Network (DeepONet) を実装し、逆導関数作用素を学習させなさい。高い精度と低い計算コストの両方を目標とする適切なアーキテクチャとハイパーパラメータを選択しなさい。モデルが様々な種類の関数に一般化できることを確認しなさい。
```

入力関数空間の選択は、プロンプト内で意図的に曖昧にされています。そのため、LLM は関数空間から戦略的にサンプリングし、これらの関数の逆導関数を生成して DeepONet のトレーニングのターゲットとして使用する必要があります。データ生成タスクに対するモデルの応答は非常に異なっています。

1.  DeepSeek V3: 入力関数は、`numpy` で一様乱数として単純に点ごとに生成されます。その後、関数は `numpy` の累積和 (`cumsum`) を用いて数値積分されます。
2.  DeepSeek R1: 入力関数は以下の 4 つのタイプからランダムに生成されます。
    1.  6 次多項式 $u(x) = c_0 + c_1x + \cdots c_6 x^6$ で、ランダムな係数は $[-2,2]$ の範囲です。
    2.  三角関数 $u(x) = A \sin(\omega x) + B \cos (\omega x)$ で、$A, B$ は $[-2,2]$ から、$ \omega$ は $[1,5]$ からランダムに選択されます。
    3.  指数関数 $u(x) = A \exp(Bx)$ で、$A, B$ は $[-1,1]$ からランダムに選択されます。
    4.  1、2、3 の混合関数 $u(x) = c_1 x^2 + c_2 \sin(\omega x) + c_3 \exp(x)$ で、$c_i$ は $[-1,1]$ から、$ \omega$ は $[1,5]$ からランダムに選択されます。すべての逆導関数は解析的に計算されます。
3.  ChatGPT 4o: 入力関数は、定数項を持たない 5 次多項式 $u(x) = c_1x + \cdots c_5 x^5$ として生成され、係数 $c_1$ は $[-1,1]$ からランダムに選択されます。逆導関数は解析的に計算されます。
4.  ChatGPT o3-mini-high: 入力関数は 3 モードのフーリエ級数 $u(x) = \sum_{i=1}^3 A_i \sin(2\pi i x) + B_i \cos(2 \pi i x)$ として生成され、$A_i, B_i$ は $[-1,1]$ からランダムに選択されます。逆導関数は `scipy.integrate.cumtrapz` を用いた累積台形則により数値的に計算されます。
5.  Claude 3.7 Sonnet: DeepSeek R1 と同様に、入力関数は以下のいずれかとして生成されます。
    1.  フーリエ級数 $u(x) = \sum_{i=1}^N A_i \sin(2\pi i x) + B_i \cos(2 \pi i x)$ で、$A, B$ は $[-1,1]$ から、$N$ は $\{2,3,4,5,6\}$ からランダムに選択されます。
    2.  次数 $d$ が $\{2,3,4,5\}$ からランダムに選択され、係数が $[-1,1]$ からランダムな多項式。
    3.  三角関数 $u(x) = A \sin(B x) + C \cos(2x)$ で、$A, B, C$ は $[0.5, 2]$ からランダムに選択されます。すべての逆導関数は解析的に計算されます。
6.  Claude 3.7 Sonnet with extended thinking: 同様に、入力関数は以下のいずれかとして生成されます。
    1.  次数 $d$ が $\{0, 1, 2,3,4,5\}$ からランダムに選択され、係数が $[-2,2]$ からランダムな多項式。
    2.  サイン関数 $u(x) = A \sin(B x)$ で、$A, B$ は $[0.5, 3]$ からランダムに選択されます。
    3.  指数関数 $u(x) = A \exp(Bx)$ で、$A, B$ は $[0.5,2]$ からランダムに選択されます。
    4.  混合関数 $u(x) = A \sin( x) + B x^2$ で、$A, B$ は $[0.5,2]$ からランダムに選択されます。
    5.  ガウス関数 $u(x) = a \exp\left(-\left(\frac{x - \mu}{\sigma}\right)^2\right)$ で、$a \sim \text{Unif}[1, 3]$、$ \mu \sim \text{Unif}[-0.5, 0.5]$、$ \sigma \sim \text{Unif}[0.2, 0.5]$ です。ガウス関数の逆導関数は `scipy.integrate.quad` を用いて数値的に計算されます。
    6.  有理関数 $u(x) = \frac{A}{1 + B x^2}$ で、$a, b$ は $[0.5,2]$ からランダムに選択されます。ガウス関数以外の関数の逆導関数は解析的に計算されます。

Claude 3.7 Sonnet with extended thinking は、多様な関数タイプから最も複雑なトレーニングデータセットを生成していることがわかります。驚くべきことに、どのモデルも、元の DeepONet 論文 \cite{deeponet} で使用された戦略であるガウスランダム場 (GRF) をトレーニング関数生成に用いることを検討していません。

トレーニングを進めるため、LLM が生成したコードのいくつかのバグは手動で修正されました。経験的に、繰り返しの実験を通じて、この特定のタスクでは Claude が生成したコードが他のモデルと比較して非自明なバグをより多く含んでいることがわかりました。いくつかの主要なバグは以下の通りです。

1.  DeepSeek V3 のコードには、ブランチネットとトランクネットの出力間のドット積でテンソル次元の不一致によるエラーがあり、これは手動で修正されました。
2.  ChatGPT 4o のコードは、トランクネットの入力次元を誤って 100（評価点の数）に設定しており、1（従属変数の次元）ではありませんでした。正しい次元は手動で設定され、それに合わせてテンソルの形状が修正されました。
3.  Claude 3.7 Sonnet は、`KerasTensor` が Keras の操作ではなく TensorFlow 関数 (`tf.reshape`) に渡されるバグを繰り返し出力しました。これは Keras の Functional API ルールに違反していました。このバグは、関数をカスタム Keras レイヤーでラップすることで修正されました。
4.  Claude 3.7 Sonnet with extended thinking は、Claude 3.7 Sonnet と同じ間違いを犯しました。

モデルのアーキテクチャとトレーニング結果を以下の表にまとめます。両方の Claude モデルは、より伝統的な ReLu 活性化ではなく、$\text{Swish}(x) = x \cdot \frac{1}{1 + e^{-x}}$ と定義される Swish 活性化を使用しており、その選択を滑らかさや非単調性などの利点を挙げて正当化しています。Claude モデルはまた、$L^2$ 重み正則化、学習率スケジューリング、ドロップアウトトレーニングといった高度なトレーニング手法も使用しました。

| モデル                              | 推論時間 (s) | バグなし ? | Branch Net              | Trunk Net           | データ数 | 活性化関数 | バッチサイズ | エポック数 | 早期停止 ? |
| ----------------------------------- | ------------ | ---------- | ----------------------- | ------------------- | -------- | ---------- | ------------ | ---------- | ---------- |
| DeekSeek V3                         | N/A          | No         | [100, 128, 128, 128]    | [1, 128, 128, 128]  | 10,000   | ReLu       | 32           | 100        | No         |
| DeepSeek R1                         | 214.0        | Yes        | [100,100,100,50]        | [1,100,100,50]      | 5,000    | ReLu       | 32           | 200        | Yes        |
| ChatGPT 4o                          | N/A          | No         | [100, 64, 64, 64, 64]   | [1, 64, 64, 64, 64] | 10,000   | ReLu       | 32           | 100        | No         |
| ChatGPT o3-mini-high                | 11.0         | Yes        | [100,100,100,100]       | [1,100,100,100]     | 1,000    | ReLu       | 64           | 50         | No         |
| Claude 3.7 Sonnet                   | N/A          | No         | [100, 64, 128, 64, 32]  | [1, 32, 64, 32, 32] | 800      | Swish      | 64           | 50         | Yes        |
| Claude 3.7 Sonnet extended thinking | 79.0         | No         | [100, 256, 128, 64, 50] | [1, 64, 64, 50]     | 2,000    | Swish      | 128          | 150        | Yes        |

_表: 逆導関数作用素を学習する DeepONet モデルのネットワークアーキテクチャ、ハイパーパラメータ、および$L_2$予測誤差。ネットワークアーキテクチャの表記は、表 \ref{tab:PINNs} と同じ規則に従います。_

モデルが異なるデータセットでトレーニングされているため、それらのパフォーマンスを評価するために普遍的で一般的なテストセットを構築しました。テストセットは、長さスケール $0.05, 0.1, 0.2, 0.5$ のガウスランダム場 (GRF) によって生成された関数で構成されています。データの例を以下の図に示します。各モデルの結果は以下の表に示されています。長さスケールの小さい関数は、ほとんどのモデルにとって予測がより困難です。DeepSeek R1 が最良の結果を示し、DeepSeek V3 はすべての長さスケールで意味のある予測をできませんでした。Claude が生成した DeepONet のテスト性能が低いのは、トレーニングデータではなくハイパーパラメータの選択によるものであることに注意してください。Claude 3.7 Sonnet with extended thinking の同じデータを使用し、正則化器、学習率スケジューラ、ドロップアウト層を削除し、ReLU 活性化に切り替え、ChatGPT o3-mini-high に合わせて各層のニューロン数を 100 に増やしました。これらの変更により、単純化されたモデルは両方の ChatGPT モデルと同等の性能を発揮しました。これは、Claude が良い戦略を生成する一方で、その実装は最適なパフォーマンスのために人間の介入とハイパーパラメータの調整を依然として必要とすることを示しています。

![Derivative_plots.png](figures/Derivative_plots.png)
_図 2: DeepONet が逆導関数作用素を学習するためのテストデータ。ガウスランダム場（GRF）によって異なる長さスケールで生成されました。_

| モデル                              | 長さスケール $0.5$ | 長さスケール $0.2$ | 長さスケール $0.1$ | 長さスケール $0.05$ |
| ----------------------------------- | ------------------ | ------------------ | ------------------ | ------------------- |
| DeekSeek V3                         | 49.4\%             | 50.6\%             | 51.6\%             | 47.5\%              |
| DeepSeek R1                         | **0.0008**\%       | **0.2**\%          | **1.9**\%          | **5.7**\%           |
| ChatGPT 4o                          | 0.05\%             | 1.0\%              | 3.4\%              | 6.1\%               |
| ChatGPT o3-mini-high                | 0.06\%             | 1.0\%              | 3.5\%              | 6.2\%               |
| Claude 3.7 Sonnet                   | 0.35\%             | 4.17\%             | 12.69\%            | 180.41\%            |
| Claude 3.7 Sonnet extended thinking | 0.22\%             | 2.05\%             | 5.0\%              | 7.04\%              |

_表: DeepONet モデルの GRF から生成されたテストデータセットにおける相対$L_2$誤差。多様なトレーニングデータとエラーのない実装を持つ DeepSeek R1 が最良の結果を達成しました。Claude モデルは高度なドロップアウト技術、正則化、学習率スケジューリング、および Swish 活性化を使用しましたが、これらがない場合、モデルはより良い性能を発揮し、ChatGPT の結果と同等であったでしょう。_

### Caputo 分数微分作用素の学習のための DeepONet

より高度なテスト問題として、任意の分数階数を持つ Caputo 分数微分作用素の学習を取り上げます。1 次元の Caputo 分数微分作用素$G(u)(y,\alpha)$は次のように定義されます。

$$
G(u)(y,\alpha) : \; u(x) \mapsto s(y,\alpha) = \frac{1}{\Gamma(1-\alpha)} \int_{0}^{y} (y-\tau)^{-\alpha} u'(\tau) d\tau, \\
y \in [0,1], \, \alpha \in (0,1)
$$

ここで、$\alpha$は任意の分数階数、$u'$は$u$の 1 階微分を表します。

すべての LLM には以下のプロンプトが与えられました。

`Tensorflowで1次元Caputo分数微分作用素$G(u)(y,\alpha)$を学習するDeep Operator Network (DeepONet)を実装せよ。Caputo分数微分作用素は次のように定義される。`
`$$`
`G(u)(y,\alpha) : u(x) \mapsto s(y,\alpha) = \frac{1}{\Gamma(1-\alpha)} \int_{0}^{y} (y-\tau)^{-\alpha} u'(\tau) d\tau, \\`
`y \in [0,1], \, \alpha \in (0,1)`
`$$`
`ここで、$\alpha$は任意の分数階数であり、$u'$は$u$の1階微分である。関数$u$は長さスケール0.2のガウスランダム場からサンプリングされる。`

このテストでは入力関数空間が指定されていますが、LLM は自身の訓練およびテストデータセットを生成する責任を負います。データ生成のためには、入力関数を数値的に微分および積分する必要があります。各 LLM が微分と積分に使用した方法は、表 1 にまとめられています。ほとんどのモデルは有効な数値スキームを実装しましたが、ChatGPT 4o と Claude 3.7 Sonnet は、積分ステップで同様の誤りを犯しました。具体的には、正しい領域$[0,y]$で積分を計算する代わりに、誤って$[0,1]$で計算しました。これにより、$(y-\tau)^{-\alpha}$の項が$y=\tau$で特異点を持つため、ゼロ除算エラーが発生しました。このバグは手動で修正され、積分には台形公式が採用されました。

_表 1: 訓練およびテストデータを生成するために、各 LLM が 1 次元 Caputo 分数微分を計算する際に使用した方法。_

| モデル                              | $u'$の微分   | 積分                |
| ----------------------------------- | ------------ | ------------------- |
| DeepSeek V3                         | 1 次有限差分 | 台形公式 (`numpy`)  |
| DeepSeek R1                         | 1 次有限差分 | 左リーマン和 (自作) |
| ChatGPT 4o                          | 1 次有限差分 | 不正確な境界        |
| ChatGPT o3-mini-high                | 中心差分     | 台形公式 (`numpy`)  |
| Claude 3.7 Sonnet                   | 中心差分     | 不正確な境界        |
| Claude 3.7 Sonnet extended thinking | 中心差分     | 台形公式 (`numpy`)  |

我々は、特に LLM が分数階数$\alpha$を DeepONet に正しくエンコードする方法を知っているかどうかに注目しています。というのも、分数階数$\alpha$は通常、他の DeepONet アプリケーションには現れず、この特定のタスクにおける LLM の知識は限られている可能性があるからです。オリジナルの DeepONet 論文[deeponet]では、階数$\alpha$は評価座標$y$とともにトランクネットワークに入れられています。注目すべきは、6 つの LLM すべてが$\alpha$をトランクに正しく配置したことです。しかし、繰り返しの実験において、すべての DeepSeek および ChatGPT モデルは、入力テンソルの構築において一貫して同じ誤りを犯しました。具体的には、各評価点$y$を異なる$\alpha$と誤ってペアリングし、入力を次のように構成しました。

$$
\text{Trunk net input} = \begin{bmatrix}
y_1 & \alpha_1 \\
y_2 & \alpha_2 \\
\vdots & \vdots \\
y_N & \alpha_N
\end{bmatrix}
$$

しかし、各分数微分階数$\alpha$に対して、出力関数が計算される複数の評価点$\{y_1, y_2, \ldots, y_n\}$が存在すべきです。$(y_i, \alpha_i)$の異なるペアを使用すると、分数微分が$\alpha_i$ごとに単一の点$y_i$で評価されることになり、DeepONet が領域$[0,1]$全体での導関数の完全な表現を学習するのを妨げます。結果として、DeepSeek または ChatGPT が生成したオリジナルの実装で、人間の介入なしに訓練された DeepONet は、テスト時に 150%を超える$L_2$相対誤差を生じます。このような不正確な定式化の下での比較は意味のある洞察を提供しないため、DeepSeek と ChatGPT のコードを手動で修正し、トランクネットワークへの空間入力$y$が、ランダムに区間$[0.1, 0.9]$から選択された分数階数$\alpha$ごとに 100 個の異なる点で評価されるようにしました。

両方の Claude モデルは、すべての実験でトランクネットの入力を正しく定式化しました。しかし、それらはネットワークに渡す前に、ブランチネットとトランクネットの入力テンソルをその第 1 次元に一致させるように一貫してタイル化していました。これにより、2 つのブランチを通過した後、それらの内積が直接計算されることが保証されましたが、このタイル化は不必要でコストがかかりました。というのも、内積は TensorFlow の`einsum`や行列乗算で簡単に実装できるからです。過剰なタイル化は非常に大きなテンソルサイズにつながり、訓練を遅らせました。

加えて、DeepSeek V3 は、ユーザーが$\alpha \in (0,1)$を任意として要求したにもかかわらず、DeepONet を固定された分数階数$\alpha = 0.5$のみを使用して誤って訓練しました。同様に、拡張思考を持つ Claude 3.7 Sonnet は、すべての 900 の訓練関数にわたって 5 つの固定された分数階数、$\alpha = 0.17, 0.25, 0.34, 0.65, 0.73$を使用し、合計訓練サンプルサイズは 4500 となりました。訓練データにおいて分数階数を固定することは、DeepONet がテスト中に未見の分数階数に一般化する能力を低下させました。正しいアプローチは、各訓練サンプルに対して$\alpha$をランダムにサンプリングすることです。しかし、これらの誤りは LLM の意思決定の一部であるため、手動で修正されませんでした。

最後に、我々はすべての DeepONet を、長さスケール 0.2 の GRF 生成関数とランダムな階数$\alpha \in [0.1, 0.9]$で訓練およびテストしました。結果は、モデルアーキテクチャとハイパーパラメータとともに、表 2 に報告されています。

_表 2: 1 次元 Caputo 分数微分を学習する DeepONet モデルのネットワークアーキテクチャ、ハイパーパラメータ、および$L_2$予測誤差。表記は表[参照番号]に従う。この表に報告されているテスト$L_2$誤差は、元のコードのバグを手動で修正した後の修正を反映している。Claude 3.7 Sonnet は最良の結果を達成しているが、コード内の非効率なテンソル操作により遅い。DeepSeek V3 および拡張思考を持つ Claude 3.7 Sonnet の性能は、異なる訓練サンプル間で固定分数階数$\alpha$を使用したことによって妨げられている。_

| モデル                              | 推論時間 (秒) | バグなし ? | ブランチネット           | トランクネット         | エポック数 | 訓練データ数 | 活性化関数 | 訓練時間 (秒) | テスト $L_2$ 誤差 |
| ----------------------------------- | ------------- | ---------- | ------------------------ | ---------------------- | ---------- | ------------ | ---------- | ------------- | ----------------- |
| DeepSeek V3                         | N/A           | No         | [100, 128, 128, 128]     | [2, 128, 128, 128]     | 100        | 1000         | ReLu       | 11.87         | 177.19%           |
| DeepSeek R1                         | 426.0         | No         | [100, 128, 128, 128]     | [2, 128, 128, 128]     | 50         | 1000         | ReLu       | 6.58          | 26.82%            |
| ChatGPT 4o                          | N/A           | No         | [100, 50, 50, 50, 100]   | [2, 50, 50, 50, 100]   | 100        | 1000         | ReLu       | 13.54         | 19.49%            |
| ChatGPT o3-mini-high                | 23.0          | No         | [100, 128, 128, 100]     | [2, 128, 128, 100]     | 100        | 1000         | ReLu       | 10.91         | 18.41%            |
| Claude 3.7 Sonnet                   | N/A           | No         | [100, 128, 128, 40]      | [2, 128, 128, 40]      | 200        | 900          | ReLu       | 41.74         | **5.59**%         |
| Claude 3.7 Sonnet extended thinking | 109.0         | No         | [100, 128, 128, 128, 50] | [2, 128, 128, 128, 50] | 50         | 4500         | ReLu       | 1943.14       | 16.24%            |

この表に報告されているテスト$L_2$誤差は、元のコードのバグを手動で修正した後の修正を反映しています。DeepSeek V3 のテスト誤差は非常に高く、単一の分数階数で訓練されているため、一般化に失敗していることに注意してください。拡張思考を持つ Claude 3.7 Sonnet も同じ誤りを犯していますが、より大きなサンプルサイズと 5 つの異なる$\alpha$の選択により、より良い性能に貢献しています。全体として、ハイブリッド推論モデルである Claude 3.7 Sonnet は最良の結果を達成しましたが、コード内の非効率なテンソル操作により速度が遅くなっています。さらに、以前の実験結果と同様に、ほとんどのモデルは 100 エポック以下でしか訓練されておらず、適切な収束には不十分です。実際、我々の実験中、エポック数を単純に 1000 に増やすだけで、まったく同じモデルでも相対誤差が 1 桁に減少しました。

# 要約

本研究では、DeepSeek（DeepSeek V3、DeepSeek R1）、OpenAI（ChatGPT 4o、ChatGPT o3-mini-high）、Anthropic（Claude 3.7 Sonnet、拡張思考を備えた Claude 3.7 Sonnet）から最近リリースされた大規模言語モデルの性能を、科学計算および科学機械学習における多様なタスクについて評価・比較しました。我々は、数値積分、有限差分法（FDM）、有限要素法（FEM）などの高度な数学的推論とドメイン固有の知識を必要とする挑戦的な問題、および画像認識、物理情報ニューラルネットワーク（PINN）、深層作用素ネットワーク（DeepONet）などの科学機械学習タスクを設計しました。我々の焦点は、モデルが適切な数値手法またはニューラルネットワークアーキテクチャを選択し、それらを Python で正しく実装する能力を評価することにありました。結果として、推論に最適化されたモデルである DeepSeek R1、ChatGPT o3-mini-high、および拡張思考を備えた Claude は、問題の性質を認識し、それに応じて意思決定を行う点で一貫して優れた性能を示しました。実際、それらの選択の多くは、科学計算と科学機械学習の両方において、我々がこれらの問題を解決する際に行うであろうことと類似していました。対照的に、汎用モデルである DeepSeek V3 および ChatGPT 4o は、問題の特定の特性（剛性など）やユーザーからの指示（ゼロから実装するなど）を考慮しないことがあり、結果として誤った解を生成しました。

本研究は、科学研究における LLM の使用の現実性が高まっていること、および数学、コーディング、科学計算のタスクにおいて、主要な開発者である DeepSeek、OpenAI、Anthropic が引き続きモデルを改良していることで、競争が激化していることを浮き彫りにしています。我々の知見はまた、これらの最先端 LLM の限界を露呈しており、主題に不慣れな人間研究者を混乱させる可能性のある曖昧または不正確な応答によって示されました。我々の知見は、科学的問題解決のための LLM の継続的な改善の必要性を強調しています。今後の研究では、追加のベンチマーク手法を探求し、プロジェクトの異なる段階で一連の意思決定が必要とされる、より複雑な実世界の計算課題において LLM を評価する必要があります。これにより、研究者は日常業務において LLM アシスタントをいつ、どのように効果的かつ責任を持って使用するかについて、より情報に基づいた意思決定を行うことができるようになります。

# 謝辞

本研究は、ONR Vannevar Bush Faculty Fellowship (N00014-22-1-2795) の支援を受けました。Brown University の Crunch Group のメンバーの皆様の示唆と洞察に感謝いたします。
